\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage{amsmath,amsfonts,fancyhdr,bbm,graphicx,tikz}
\usetikzlibrary{automata,positioning}
\graphicspath{ {img/} }
\usepackage[section,nohyphen]{DomH}
\headertitle{Financial Mathematics - Reviewed Notes}

\begin{document}

\title{Financial Mathematics - Reviewed Notes}
\author{Dom Hutchinson}
\date{\today}
\maketitle

\tableofcontents\newpage

\section{General}\label{sec_general}

  \begin{definition}{Modelling}
    TODO
  \end{definition}

  \begin{definition}{Risk-Free}
    An activity is said to be ``\textit{Risk-Free}'' if the potential profits \& losses are completely known.\footnote{It does not refer to whether there no chance of making a loss.}
  \end{definition}

\section{Probability}\label{sec_probability}

\subsection{General Probability}

  \begin{definition}{Sample Space $\Omega$}
    The \textit{Sample Space} $\Omega$ is the set consisting of all elementary outcomes from a (series of) event(s).
  \end{definition}

  \begin{definition}{Random Variable $X$}
    A \textit{Random Variable} $X$ is a function from the \textit{Sample Space} $\Omega$ to the real numbers $\reals$.
    \[ X:\Omega\to\reals \]
  \end{definition}

\subsection{Information Structures}

  \begin{definition}{Partition $\mathcal{P}$}
    Let $\mathcal{P}:=\{A_1,\dots,A_N\}$ be a set (of sets) and $\Omega$ be a \textit{Sample Space}.
    \par $\mathcal{P}$ is a \textit{Partition} of $\Omega$ if it has the following properties
    \begin{enumerate}
      \item All elements in $\mathcal{P}$ are mutually disjoint
      \[ A_i\cap A_j=\emptyset\ \forall\ A_i,A_j\in\mathcal{P} \]
      \item The union of the elements form the \textit{Sample Space} $\Omega$.
      \[ \bigcup_{i=1}^NA_i=\Omega \]
    \end{enumerate}
  \end{definition}

  \begin{remark}{Flow of Information}
    At time $t=0$ every state $\omega\in\Omega$ is a possible outcome at time $t=T$. And, at time $t=T$ we know for certain which outcome has occurred.
    \par At each time in-between $t\in(0,T)$ our information about the world increases\footnote{or, at least, does not decrease.} meaning the set of possible outcomes at time $t=T$ may decrease. Let $A_t$ denote the possible set of outcomes given we are at time $t$, then
    \[\begin{array}{rcl}
      A_0&=&\Omega\\
      A_T&=&\{\omega\}\\
      A_0&\supseteq&A_1\supseteq\dots\supseteq A_T
    \end{array}\]
    Flipping a coin 3 times is a motivating example. Before we start flipping ($t=0$) it is possible that we will flip three tails, but if the first flip ($t=1$) is heads then this is no longer possible.
  \end{remark}

  \begin{definition}{Information Sequence $\{\mathcal{P}_0,\dots,\mathcal{P}_T\}$}
    An \textit{Information Sequence} is a set of \textit{Partitions} $\{\mathcal{P}_0,\dots,\mathcal{P}_T\}$ of the \textit{Sample Space} $\Omega$, which fulfil the following criteria
    \begin{enumerate}
      \item $\mathcal{P}_0=\big\{\Omega\big\}$.
      \item For $t\in[1,T)$ each $A\in\mathcal{P}_t$ is equal to the union of a subset of elements in $\mathcal{P}_{t+1}$.
      \item $\mathcal{P}_T=\big\{\{\omega_1\},\dots,\{\omega_N\}\big\}$.
    \end{enumerate}
    \textit{Information Sequences} show the set of possible events, at each time point $t$, which could still occur.\footnote{An \textit{Information Sequence} is a sequence of \textit{$\sigma$-Algebras}.}
  \end{definition}

  \begin{remark}{Visualising Information Structures}
    TODO
  \end{remark}

  \begin{definition}{$\sigma$-Algebra $\mathcal{F}$}
    A \textit{$\sigma$-Algebra} $\mathcal{F}$ is a set of subsets of the \textit{Sample Space} $\Omega$ which satisfy the following conditions
    \begin{enumerate}
      \item $\Omega\in\mathcal{F}$.
      \item $\forall\ A\in\mathcal{F},\ A^c\in\mathcal{F}$.
      \item $\forall\ A,B\in\mathcal{F},\ (A\cup B)\in\mathcal{F}$.
    \end{enumerate}
  \end{definition}

  \begin{definition}{Filtration $\{\mathcal{F}_0,\dots,\mathcal{F}_T\}$}
    A \textit{Filtration} is a sequence of \textit{$\sigma$-Algebras} $\{\mathcal{F}_t:t=0,1,\dots,T\}$ where
    \begin{enumerate}
      \item $\mathcal{F}_0=\{\emptyset,\Omega\}$.
      \item $\forall\ n<T,\ \mathcal{F}_n\subset\mathcal{F}_{n+1}$ (Meaning each subset of $\mathcal{F}_n$ must be an element of $\mathcal{F}_{n+1}$).
      \item $\mathcal{F}_T=2^\Omega$.\footnote{The set of all subsets of the sample space $\Omega$.}
    \end{enumerate}
    A \textit{Filtration} represents our understanding of available information at each time point.
  \end{definition}

  \begin{definition}{Measurable Function}
    Consider a random variable $X:\Omega\to\reals$ and a \textit{$\sigma$-Algebra} $\mathcal{F}$.
    \par $X$ is \textit{Measurable} wrt $\mathcal{F}$ if
    \[ \forall\ x\in\reals, X^{-1}(x)\subset\mathcal{F}\text{ where }X^{-1}(x):=\{\omega\in\Omega:X(\omega)=x\} \]
    This can be interpreted to mean that, if we known which set of $\mathcal{F}$ $\omega$ is in, then we know the values of $X(\omega)$.
  \end{definition}

  \begin{proposition}{Measurability and Filtrations}
    Consider a \textit{Filtration} $\{\mathcal{F}_1,\dots,\mathcal{F}_T\}$ and a random variable $X:\Omega\to\reals$.
    \par If $X$ is \textit{Measurable} wrt $\mathcal{F}_t$ then it is \textit{Measurable} wrt $\mathcal{F}_{t+1}$ since $\mathcal{F}_t\subseteq\mathcal{F}_{t+1}$.
  \end{proposition}

  \begin{proposition}{How to generate $\sigma$-Algebras}\label{prop_generate_sigma_algebras}
    Let $\mathcal{P}$ be a \textit{Partition} of the \textit{Sample Space} $\Omega$.
    \par We can generate a \textit{$\sigma$-Algebra} $\mathcal{F}$ from $\mathcal{P}$ be defining $\mathcal{F}$ to be the set of all possible unions from elements in $\mathcal{P}$ \underline{as well as} the compliments of all these unions.
  \end{proposition}

\subsection{Conditional Expectation}

  \begin{definition}{Conditional Expectation $\expect[\cdot|\cdot]$}
    \everymath={\displaystyle}
    Let $\Omega$ be a finite sample space, $X$ be a discrete random variable and $A\subseteq\Omega$.
    \par The \textit{Conditional Expectation} of $X$ given $A$ has occurred is defined as
    \[ \expect[X|A]=\sum_xx\prob(X=x|A) \]
  \end{definition}

  \begin{remark}{Alternative Definitions of Conditional Expectation}
    \everymath={\displaystyle}
    Here are two restatements of the definition of \textit{Conditional Expectation}, both are consequences of \textit{Bayes Rule}.
    \[\begin{array}{rcl}
      \expect[X|A]&=&\sum_x\frac{\prob(X=x,A)}{\prob(A)}\\
      \expect[X|A]&=&\sum_{\omega\in A}X(\omega)\frac{\prob(\omega)}{\prob(A)}
    \end{array}\]
  \end{remark}

  \begin{definition}{Conditional Expectation \textbackslash{w} $\sigma$-Algebra $\expect[\cdot|\mathcal{F}]$}
    Let $\mathcal{F}$ be a \textit{$\sigma$-algebra}, $\mathcal{P}$ be the corresponding \textit{Partition} of the sample space $\Omega$ and $X$ be a discrete random variable.
    \par The \textit{Conditional Expectation} of $X$ given $\mathcal{F}$ is defined as
    \[ \expect[X|\mathcal{F}]:=\sum_{A\in\mathcal{P}}\expect[X|A]\indexed\{A\}\footnotemark \]
    \footnote{This is not really a summation as there is only \underline{one} event $A$ st $\indexed\{A\}=1$.}
    \underline{Note} - This is a random variable as its value depends on which random event $A$ occurs. Moreover, it is \textit{Measurable} wrt $\mathcal{F}$ and for a given $A\in\mathcal{P}$
    \[ \forall\ \omega\in A,\ \expect[X|\mathcal{F}](\omega)=\expect[X|A]\footnotemark \]
    \footnotetext{This is intuitive from the definition of $\expect[\cdot|\mathcal{F}]$.}
  \end{definition}

  \begin{theorem}{Tower Law}\label{the_tower_law}
    Let $X$ be a discrete random variable and $\mathcal{F}_1,\mathcal{F}_2$ be \textit{$\sigma$-Algebras} with $\mathcal{F}_1\subset\mathcal{F}_2$.
    \par The \textit{Tower Law} states that
    \[ \expect\big[\expect[X|\mathcal{F}]\big]=\expect[X] \]
    The \textit{Generalised Tower Law} states that
    \[ \expect\big[\expect[X|\mathcal{F}_2]\big|\mathcal{F}_1\big] = \expect[X|\mathcal{F}_1] = \expect\big[\expect[X|\mathcal{F}_1]\big|\mathcal{F}_2\big] \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_tower_law}} - Tower Law}
    \everymath={\displaystyle}
    Let $X$ be a discrete random variable, $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $\mathcal{P}$ be the partition of the sample space $\Omega$ associated with $\mathcal{F}$.
    \[\begin{array}{rcl}
      \expect\big[\expect[X|\mathcal{F}]\big]&=&\expect\left[\sum_{A\in\mathcal{P}}\expect[X|A]\indexed\{A\}\right]\text{ by def.}\\
      &=&\sum_{A\in\mathcal{P}}\expect\big[\expect[X|A]\indexed\{A\}\big]\text{ by linearity of expectation}\\
      &=&\sum_{A\in\mathcal{P}}\expect[X|A]\expect[\indexed\{A\}]\\
      &=&\sum_{A\in\mathcal{P}}\prob(A)\cdot\left(\sum_{\omega\in A}\frac{X(\omega)\prob(\omega)}{\prob(A)}\right)\text{ by alt def.}\\
      &=&\sum_{A\in\mathcal{P}}\sum_{\omega\in A}X(\omega)\prob(\omega)\text{ as }\sum \prob(A)=1\\
      &=&\expect[X]\text{ by def.}
    \end{array}\]\proved
  \end{proof}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_tower_law}} - Generalised Tower Law}
    \everymath={\displaystyle}
    Let $X$ be a discrete random variable, $\mathcal{F}_1,\mathcal{F}_2$ be \textit{$\sigma$-Algebras} with $\mathcal{F}_1\subset\mathcal{F}_2$ and $\mathcal{P}_1,\mathcal{P}_2$ be the partitions associated to $\mathcal{F}_1,\mathcal{F}_2$.
    \[\begin{array}{rcl}
      \expect\big[\expect[X|\mathcal{F}_2]\big|\mathcal{F}_1\big]&=&\expect\left[\sum_{B\in\mathcal{P}_2}\expect[X|B]\indexed\{B\}\bigg|\mathcal{F}_1\right]\\
      &=&\sum_{B\in\mathcal{P}_2}\expect[X|B]\expect[\indexed\{B\}|\mathcal{F}_1]\\
      &=&\sum_{B\in\mathcal{P_2}}\expect[X|B]\left(\sum_{A\in\mathcal{P}_1}\expect[\indexed\{B\}|A]\indexed\{A\}\right)\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2}}\expect[X|B]\expect[\indexed\{B\}|A]\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2}}\expect[X|B]\cdot\frac{\prob(A\cap B)}{\prob(A)}\cdot\indexed\{A\}
    \end{array}\]
    Since $\mathcal{P}_2$ is more refined than $\mathcal{P}_1$, either $B\subset A$ or $B\cap A=\emptyset$. Thus
    \[\begin{array}{rcl}
      \expect\big[\expect[X|\mathcal{F}_2]\big|\mathcal{F}_1\big]
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2},B\subset A}\expect[X|B]\cdot\frac{\prob(B)}{\prob(A)}\cdot\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2},B\subset A}\left(\sum_{\omega\in B}X(\omega)\frac{\prob(\omega)}{\prob(B)}\right)\cdot\frac{\prob(B)}{\prob(A)}\cdot\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{\omega\in B}X(\omega)\frac{\prob(\omega)}{\prob(A)}\cdot\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\expect[X|A]\indexed\{A\}\\
      &=&\expect[X|\mathcal{F}_1]
    \end{array}\]
    \proved
  \end{proof}

  \begin{theorem}{Conditional Expectation \& Measurable Random Variables}\label{the_cond_exp_and_measurable}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $X,Y$ be discrete random variables with $X$ being \textit{Measurable} wrt $\mathcal{F}$.
    \par Then
    \[\begin{array}{rcl}
      \expect[X|\mathcal{F}]&=&X\\
      \expect[XY|\mathcal{F}]&=&X\expect[Y|\mathcal{F}]
    \end{array}\]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}}}\label{proof_cond_exp_and_measurable}
    \everymath={\displaystyle}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra}, $\mathcal{P}$ be the partition associated with $\mathcal{F}$ and $X,Y$ be discrete random variables with $Y$ being \textit{Measurable} wrt $\mathcal{F}$.
    \par Since $Y$ is \textit{Measurable} it is constant on sets of $\mathcal{P}$ we write $X$ as
    \[ Y=\sum_{A\in\mathcal{P}}Y_A\indexed\{A\}\text{ with }Y_A\in\reals \]
    Thus
    \[\begin{array}{rcl}
      \expect[XY|\mathcal{F}]&=&\sum_{A\in\mathcal{P}}\expect[XY|A]\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}}\expect[XY_A|A]\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}}Y_A\expect[X|A]\indexed\{A\}\text{ as }Y_A\text{ is a scalar}\\
      &=&\sum_{A\in\mathcal{P}}Y\expect[X|A]\indexed\{A\}\footnotemark\\
      &=&Y\sum_{A\in\mathcal{P}}\expect[X|A]\indexed\{A\}\\
      &=&Y\expect[X|\mathcal{F}]
    \end{array}\]
    \proved
    \footnotetext{As there is only one event $A$ where $\indexed\{A\}=1$.}
  \end{proof}

  \begin{theorem}{Conditional Expectation \& Independent Random Variables}\label{the_cond_exp_and_independent}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $X$ be a discrete random variable which is independent of $\mathcal{F}$.
    \par Then
    \[ \expect[X|\mathcal{F}]=\expect[X] \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_independent}}}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $X$ be a discrete random variable which is independent of $\mathcal{F}$.
    \[\begin{array}{rcl}
      \expect[X|A]&=&\sum_x\prob(X=x|A)\\
      &=&\sum_x\prob(X=x)\text{ by independence}\\
      &=&\expect[X]
    \end{array}\]
    \proved
  \end{proof}

  \begin{theorem}{General Conditional Expectation}\label{the_general_conditional_expectation}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} of a general sample space\footnote{i.e. Not necessarily finite} $\Omega$ and $X$ be a discrete random variable.
    \par Then, the \textit{Conditional Expectation} $\expect[X|\mathcal{F}]$ is a \underline{unique} random variable with the following properties
    \begin{enumerate}
      \item $\expect[X|\mathcal{F}]$ is \textit{Measurable} wrt $\mathcal{F}$.
      \item $\forall\ A\in\mathcal{F},\ \expect\big[\expect[X|\mathcal{F}]\indexed\{A\}\big]=\expect[X\indexed\{A\}]$
    \end{enumerate}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_general_conditional_expectation}}}
    \everymath={\displaystyle}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} of a general sample space $\Omega$, $\mathcal{P}$ be the partition associated with $\mathcal{F}$ and $X$ be a discrete random variable.
    \begin{enumerate}
      \item
      Let $Y$ be a random variable which is \textit{Measurable} wrt $\mathcal{F}$ and satisfies
      \[ \expect[Y\indexed\{A\}]=\expect[X\indexed\{A\}]\ \forall\ A\in\mathcal{F} \]
      Consider the expression $\expect[X\indexed\{A\}]$
      \[\begin{array}{rcl}
        \expect[X\indexed\{A\}]&=&\sum_{\omega\in A}X(\omega)\prob(\omega)\\
        &=&\frac{\prob(A)}{\prob(A)}\sum_{\omega\in A}X(\omega)\prob(\omega)\\
        &=&\prob(A)\sum_{\omega\in A}\frac{X(\omega)\prob(\omega)}{\prob(A)}\\
        &=&\prob(A)\expect[X|A]
      \end{array}\]
      Now, Note that $Y=\sum_{A\in\mathcal{P}}Y_A\indexed\{A\}$ (As in \texttt{Proof \ref{sec_probability}.\ref{proof_cond_exp_and_measurable}}).
      \par It follows that
      \[ \forall\ A\in\mathcal{P},\ \expect[Y\indexed\{A\}]=Y_A\expect[\indexed\{A\}]=Y_A\prob(A) \]
      We now have that
      \[\begin{array}{rrcl}
        &\expect[X\indexed\{A\}]&=&\expect[Y\indexed\{A\}]\text{ by def. }Y\\
        \implies&\prob(A)\expect[X|A]&=&Y_A\prob(A)\\
        \implies&Y_A&=&\expect[X|A]\ \forall\ A\in\mathcal{P}\\
        \implies&Y&=&\expect[X|\mathcal{F}]
      \end{array}\]
      As we defined $Y$ to be \textit{Measurable} wrt $\mathcal{F}$, this means $\expect[X|\mathcal{F}]$ is \textit{Measurable} wrt $\mathcal{F}$.

      \item \par For any event $A\in\mathcal{F}$, the indicator function $\indexed\{A\}$ is \textit{$\mathcal{F}$-Measurable}.
      \par Thus, $\expect[X\indexed\{A\}|\mathcal{F}]=\indexed\{A\}\cdot\expect[X|\mathcal{F}]$ by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}}.
      \par Hence, by the Tower Law (\texttt{Theorem \ref{sec_probability}.\ref{the_tower_law}}).
      \[ \expect\big[\expect[X|\mathcal{F}]\cdot\indexed\{A\}\big]=\expect\big[\expect[X\indexed\{A\}|\mathcal{F}]\big]=\expect[X\indexed\{A\}] \]
    \end{enumerate}
    \proved
  \end{proof}

\subsection{Stochastic Processes in Discrete Time}

  \begin{definition}{Stochastic Process}
    A \textit{Stochastic Process} $S$ is a real-valued function $S(t)(\omega)$
    \[ S:[0,T]\times\Omega\to\reals \]
  \end{definition}

  \begin{proposition}{Fixing components of a Stochastic Process}
    Let a \textit{Stochastic Process} $S:[0,T]\times\Omega\to\reals$ and consider fixing different variables
    \begin{itemize}
      \item If we fix $t\in[0,T]$ then $S(t)(\cdot):\Omega\to\reals$\footnote{The event $\omega$ is the only variable} is a \textit{Random Variable}.
      \item If we fix $\omega\in\Omega$ then $S(\cdot)(\omega):[0,T]\to\reals$\footnote{The time-point $t$ is the only variable} is called a \textit{Sample Path}.
    \end{itemize}
  \end{proposition}

  \begin{definition}{Adapted Stochastic Process}
    Let $S:[0,T]\times\Omega\to\reals$ be a \textit{Stochastic Process} and $\{\mathcal{F}_t\}_{t\in[0,T]}$ be a \textit{Filtration}.
    \par $S$ is \textit{Adapted} to \textit{Filtration} $\{\mathcal{F}_t\}_{t\in[0,T]}$ if the \textit{Random Variable} $S(t)$ is \textit{Measurable} wrt $\sigma$-algebra $\mathcal{F}_t$, for all $t\in[0,T]$.\footnote{It is often easier to define a stochastic process first and then find a filtration for it (e.g. the \textit{Natural Filtration}).}
  \end{definition}

  \begin{definition}{Natural Filtration}
    Let $S:[0,T]\times\Omega\to\reals$ be a \textit{Stochastic Process}.
    \par We generate the \textit{Natural Filtration} $\{\mathcal{F}_t\}_{t\in[0,T]}$ for $S$ by doing the following for each $t=0,1,\dots,T$
    \begin{enumerate}
      \item Define $\mathcal{P}_t$ to be a partition of the \textit{Sample Space} $\Omega$ st $S(t)(\cdot)$ takes the same value for each element in each subset of $\mathcal{P}_t$.
      \[ \mathcal{P}_t:=\big\{A_1,\dots,A_m:S(t)(a)=S(t)(a')\ \forall\ a,a'\in A\big\}\text{ and }A_1,\dots,A_m\text{ form a partition.} \]
      \item Define $\mathcal{F}_t$ to be the \textit{$\sigma$-Algebra} generated by\footnote{See \texttt{Proposition \ref{sec_probability}.\ref{prop_generate_sigma_algebras}}.} partition $\mathcal{P}_t$.
    \end{enumerate}
  \end{definition}

  \begin{definition}{Random Walk}
    Let $Y_0,Y_1,\dots$ be IID random variables with finite variance $\sigma^2$ and finite mean $\mu$.
    \par A \textit{Random Walk} is the sequence $\{X_t\}_{t\geq0}$ where $X_t:=\sum_{i=1}^tY_i$.
  \end{definition}

  \begin{definition}{Simple Random Walk}
    Let $\{X_t\}_{t\geq0}$ be a \textit{Random Walk} with $X_t:=\sum_{i=1}^tY_i$ where $Y_0,Y_1,\dots$ are IID RVs.
    \par We say that $\{X_t\}_{t\geq0}$ is a \textit{Simple Random Walk} if
    \[ Y_t\in\{-1,1\}\quad\prob(Y_t=1)=p\quad\prob(Y_t=-1)=1-p \]
    A \textit{Simple Random Walk} can be thought of as a process where you only ever step forward or step backwards, with fixed probabilities.
  \end{definition}

  \begin{theorem}{Distribution of a Simple Random Walk}\label{the_distribution_of_simple_random_walk}
    Let $\{X_t\}_{t\geq0}$ be a \textit{Simple Random Walk}. Then
    \[ \prob(X_t=x)={t \choose {\frac{t+x}2}}p^{(t+x)/2}(1-p)^{(t-x)/2}\quad\ \forall\ t\geq0,\ x\in\{-t,-t+2,\dots,t\} \]
    Note that the set of possible $x$ values steps by 2.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_distribution_of_simple_random_walk}}}
    Note that $x=\frac12(2x+t-t)=(+1)\cdot\frac12(t+x)+(-1)\cdot\frac12(t-x)$.
    \par For $X_t=x$ we require exact $\frac12(t+x)$ of $Y_1,\dots,Y_t$ to take value 1, and then the remaining $\frac12(t-x)$ will take value -1. There are ${t\choose{\frac{t+x}2}}$ different ways this can occur.
    \par Note that each $Y_i$ takes its value independently and takes value 1 with probability $p$ and -1 with probability $1-p$. Thus
    \[ \prob(X_t=x)={t \choose {\frac{t+x}2}}p^{(t+x)/2}(1-p)^{(t-x)/2}\quad\ \forall\ t\geq0,\ x\in\{-t,-t+2,\dots,t\} \]
  \end{proof}

\subsection{Martingales}

  \begin{definition}{Martingale $\{Z_t\}_{t\in\nats_0}$}
    % super-, sub- martingale
    Let $\{Z_t\}_{t\in[0,T]}$ be an \textit{Adapted Stochastic Process} on a \textit{Sample Space} $\Omega$ with a \textit{Filtration} $\{\mathcal{F}_t\}_{t\in[0,T]}$.
    \begin{itemize}
      \item $\{Z_t\}_{t\in[0,T]}$ is a \textit{Martingale} if
      \[ \forall\ t\geq1,\ \expect[Z_t|\mathcal{F}_{t-1}]=Z_{t-1} \]
      This can be interpreted to mean that, given all available information $\mathcal{F}_{t-1}$, our present state $Z_{t-1}$ is the best indicator of the future state $Z_t$.
      \item $\{Z_t\}_{t\in[0,T]}$ is a \underline{Super}\textit{-Martingale} if
      \[ \forall\ t\geq1,\ \expect[Z_t|\mathcal{F}_{t-1}]\leq Z_{t-1} \]
      This can be interpreted to mean that, given all available information $\mathcal{F}_{t-1}$, our present state $Z_{t-1}$ provides an upper-bound on the future state $Z_t$.
      \item $\{Z_t\}_{t\in[0,T]}$ is a \underline{Sub}\textit{-Martingale} if
      \[ \forall\ t\geq1,\ \expect[Z_t|\mathcal{F}_{t-1}]\geq Z_{t-1} \]
      This can be interpreted to mean that, given all available information $\mathcal{F}_{t-1}$, our present state $Z_{t-1}$ provides a lower-bound on the future state $Z_t$.
    \end{itemize}
  \end{definition}

  \begin{proposition}{Notable Martingales}\label{prop_notable_martingales}
    Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$ and let $\mathcal{F}_t$ be the \textit{$\sigma$-Algebra} generated by $X_t$. Then
    \begin{enumerate}
      \item If $p=1/2$ $\{X_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \item If $p\leq1/2$ $\{X_t\}_{t\in\nats_0}$ is a \textit{Super-Martingale}.
      \item If $p\geq1/2$ $\{X_t\}_{t\in\nats_0}$ is a \textit{Sub-Martingale}.
      \item If $p=1/2$ then $\{Z_t\}_{t\in\nats_0}$ where $Z_t:=(X_t^2-t)$ is a \textit{Martingale}.
      \item If $p\neq1/2$ then $\{L_t\}_{t\in\nats_0}$ where $L_0:=1,L_t:=\left(\frac{1-p}p\right)^{X_t}$ is a \textit{Martingale} \textit{Martingale}.
      \item If $p\neq1/2$ then $\{M_t\}_{t\in\nats_0}$ where $M_t:=\big(X_t-t(2p-1)\big)$ is a \textit{Martingale}. \textit{Martingale}.
    \end{enumerate}
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} i)-iii)}
    Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$ and let $\mathcal{F}_t$ be the \textit{$\sigma$-Algebra} generated by $X_t$.
    \par Since $\{\mathcal{F}_t\}_{t\in\nats}$ is the \textit{Natural Filtration} of $\{X_t\}_{t\in\nats}$, then $\{X_t\}_{t\in\nats}$ is \mathit{Measurable} wrt $\mathcal{F}_t$ and $Y_t$\footnote{The $t^{th}$ step of the random walk.} is independent of $\mathcal{F}_{t-1}$.
    \par Then
    \[\begin{array}{rcl}
      \expect[X_t|\mathcal{F}_{t-1}]&=&\expect[X_{t-1}+Y_t|\mathcal{F}_{t-1}]\text{ by def. }X_t\\
      &=&\expect[X_{t-1}|\mathcal{F}_{t-1}]+\expect[Y_t|\mathcal{F}_{t-1}]\text{ by linearity of exp.}\\
      &=&X_{t-1}+\expect[Y_t]\text{ by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_independent}}}
    \end{array}\]
    Thus
    \begin{itemize}
      \item If $p=1/2$ then $\expect[Y_t]=0\implies\expect[X_t|\mathcal{F}_{t-1}]=X_{t-1}$. This is the definition of a \textit{Martingale}.
      \item If $p\leq1/2$ then $\expect[Y_t]\leq0\implies\expect[X_t|\mathcal{F}_{t-1}]\leq X_{t-1}$. This is the definition of a \textit{Super-Martingale}.
      \item If $p\geq1/2$ then $\expect[Y_t]\geq0\implies\expect[X_t|\mathcal{F}_{t-1}]\geq X_{t-1}$. This is the definition of a \textit{Sub-Martingale}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} iv)}
    Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$ and let $\mathcal{F}_t$ be the \textit{$\sigma$-Algebra} generated by $X_t$.
    \par As the definition of a \textit{Martingale} depends on the conditional expectation of $Z_t$ given $\mathcal{F}_{t-1}$ we consider its value
    \[\begin{array}{rcl}
      \expect[Z_t|\mathcal{F}_{t-1}]&=&\expect[X_t^2-t|\mathcal{F}_{t-1}]\text{ by def. }Z_t\\
      &=&\expect[(X_{t-1}+Y_t)^2-t|\mathcal{F}_{t-1}]\text{ by def. }X_t\\
      &=&\expect[(X_{t-1}+Y_t)^2|\mathcal{F}_{t-1}]-t\\
      &=&\expect[X_{t-1}^2+2X_{t-1}Y_t+Y_t^2|\mathcal{F}_{t-1}]-t\\
      &=&\expect[X_{t-1}^2|\mathcal{F}_{t-1}]+2\expect[X_tY_t|\mathcal{F}_{t-1}]+\expect[Y_t^2|\mathcal{F}_{t-1}]-t\\
      &=&X_{t-1}^2+2X_{t-1}\expect[Y_t|\mathcal{F}_{t-1}]+\expect[Y_t^2]-t\\
    \end{array}\]
    Since $p=1/2\implies \expect[Y_t]=0,\expect[Y_t^2=1]$.
    \[\begin{array}{rcl}
      \expect[Z_t|\mathcal{F}_{t-1}]&=&X_{t-1}^2+2X_{t-1}\expect[Y_t|\mathcal{F}_{t-1}]+\expect[Y_t^2]-t\\
      &=&X_{t-1}^2+0+1-t\\
      &=&X_{t-1}^2-(t-1)\\
      &=&Z_{t-1}\\
      \implies\expect[Z_t|\mathcal{F}_{t-1}]&=&Z_{t-1}
    \end{array}\]
    This is the definition of a \textit{Martingale}.\proved
  \end{proof}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} v)}
    TODO (Homework)
  \end{proof}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} vi)}
    TODO (Homework)
  \end{proof}

  \begin{theorem}{Adapted Stochastic Processes as Martingales}\label{the_adapated_stochastic_processes_as_martingales}
    Let $\{Z_t\}_{t\in[0,T]}$ be an \textit{Adapted Stochastic Process}.
    \par $\{Z_t\}_{t\in[0,T]}$ is a \textit{Martingale} \underline{iff}
    \[ \forall\ t\geq s,\  \expect[Z_t|\mathcal{F}_s]=Z_s\footnotemark \]
    \footnotetext{Equivalent results can be made for \textit{Super-} and \textit{Sup-Martingales} by replacing $=$ with $\leq,\geq$ respectively.}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_adapated_stochastic_processes_as_martingales}}}
    Let $\{Z_t\}_{t\in[0,T]}$ be an \textit{Adapted Stochastic Process}.
    \par I prove this statement in both directions\footnote{The proofs for \textit{Super-} and \textit{Sup-Martingales} are very similar.}
    \begin{itemize}
      \item[$\Longrightarrow$] Suppose $\{Z_t\}_{t\in[0,T]}$ is a \textit{Martingale}.
      \par Using \texttt{Theorem \ref{sec_probability}.\ref{the_general_conditional_expectation}} we can deduce that
      \[\begin{array}{rcll}
        \expect[Z_t|\mathcal{F}_s]&=&\expect\big[\expect[Z_t|\mathcal{F}_{t-1}]\big|\mathcal{F}_s\big]&\text{by \texttt{Theorem \ref{sec_probability}.\ref{the_general_conditional_expectation}}}\\
        &=&\expect[Z_{t-1}|\mathcal{F}_s]&\text{as }Z\text{ is a Martingale}\\
        &=&\expect[Z_s|\mathcal{F}_s]&\text{by recursion}\\
        &=&\expect[Z_s]&\text{ by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}} }\\
        &=&Z_s
      \end{array}\]
      \item[$\Longleftarrow$] Suppose it holds that
      \[ \forall\ t\geq s,\  \expect[Z_t|\mathcal{F}_s]=Z_s \]
      Consider the case where $s=t-1$, it holds that
      \[ \expect[Z_t|\mathcal{F}_{t-1}]=Z_{t-1} \]
      This is the definition of a \textit{Martingale}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{definition}{Stopping Times $\tau$}
    Let $\{\mathcal{F}_t\}_{t\in\nats_0}$ be a \textit{Filtration} of \textit{Sample Space} $\Omega$ and $\tau$ be a random variable which takes values in $(\reals\geq0\cup\{\infty\})$\footnote{$\infty$ is used for impossible events.}.
    \par $\tau$ is a \textit{Stopping Time} if the event $\{\tau<t\}$ is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t$.
    \par \textit{Stopping Times} are used to determine whether an event has occurred, or not.\footnote{Examples of \textit{Stopping Times} are ``RBS shares hit £1''.}
  \end{definition}

  \begin{definition}{Bounded Stopping Time $\tau$}
    Let $\tau$ be a \textit{Stopping Time}.
    \par A $\tau$ is a \textit{Bounded Stopping Time} if
    \[ \exists\ t\in\reals^{\geq0},\ \prob(\tau<t)=1 \]
  \end{definition}

  \begin{theorem}{Stopping Times \& $\sigma$ Algebras}\label{the_stopping_times_and_sigma_algebras}
    Let $\tau$ be a random variable.
    \par $\tau$ is a \textit{Stopping Time} \underline{iff} $\forall\ t\in\nats_0$ the event $\{\tau=t\}$  is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_stopping_times_and_sigma_algebras}}}
    Let $\tau$ be a random variable.
    \par I prove this statement in both directions
    \begin{itemize}
      \item[$\Longrightarrow$] Suppose $\tau$ is a \textit{Stopping Time}.
      \par Then the event $\{\tau\leq t\}$ is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t\ \forall\ t\in\nats_0$.
      \par We can restate this event as
      \[ \{\tau\leq t\}=\bigcup_{k\leq t}\{\tau=k\} \]
      As $\{\tau\leq t\}\in\mathcal{F}_t$, then each of $\{\tau=k\}\in\mathcal{F}_t$ due to the definition of a \textit{$\sigma$-Algebra}.

      \item[$\Longleftarrow$] Suppose the event $\{\tau=t\}$  is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t\ \forall\ t\in\nats_0$.
      \par We can restate this event as
      \[ \{\tau\leq t\}=\big(\{\tau\leq t\}\setminus\{\tau\leq t-1\}\big) \]
      Since $\{\tau\leq t\},\{\tau\leq t-1\}$ are elements of $\mathcal{F}_t$, then $\{\tau\leq t\}\in\mathcal{F}_t$ due to the definition of a \textit{$\sigma$-Algebra}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{theorem}{Stopping Time for an Adapted Stochastic Process}\label{the_stopping_time_adapted_stochastic_process}
    Let $\{X_t\}_{t\in\nats_0}$ be an \textit{Adapted Stochastic Process} and $c\in\reals$.
    \par The event $\tau_c:=\inf\{t\geq0:X_t\geq c\}$\footnote{The first time $X_t$ reaches value $c$.} is a \textit{Stopping Time}.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_stopping_time_adapted_stochastic_process}}}
    Let $\{X_t\}_{t\in\nats_0}$ be an \textit{Adapted Stochastic Process} and $c\in\reals$.
    \par Note that $\tau\leq t$ \underline{iff} $\exists\ k\leq t$ st $X_k\geq c$ due to the definition of $\tau_c$.
    \par Therefore
    \[ \{\tau_c\leq t\}=\bigcup_{k\leq t}\{X_k\geq c\} \]
    Since each $\{X_k\geq c\}\in\mathcal{F}_t$ then $\{\tau_c\leq t\}\in\mathcal{F}_t$ by the definition of \textit{$\sigma$-Fields}.
    \par Thus $\tau_c$ is a \textit{Stopping Time}.\proved
  \end{proof}

  \begin{theorem}{Optional Stopping Theorem\footnote{AKA \textit{Optional Sampling Theorem}} - Martingale}\label{the_optional_stopping_theorem_martingale}
    Let $\tau$ be a \textit{Bounded Stopping Time} and $\{X_t\}_{t\in\nats_0}$ be a \textit{Martingale}.
    \par Then
    \[ \expect[X_\tau]=\expect[X_0]=X_0 \]
  \end{theorem}

  \begin{theorem}{Optional Stopping Theorem - Super-Martingale}
    Let $\tau$ be a \textit{Bounded Stopping Time} and $\{X_t\}_{t\in\nats_0}$ be a \underline{Super}\textit{-Martingale}.
    \par Then
    \[ \expect[X_\tau]\leq\expect[X_0]=X_0 \]
  \end{theorem}

  \begin{remark}{Weaker Conditions for Optional Stopping Theorem}\label{rem_weaker_optional_stopping_theorem}
    The following are weaker conditions\footnote{Rather than $\tau$ being a bounded stopping time} that suffice for the \textit{Optional Stopping Theorem} to hold
    \begin{enumerate}
      \item $\prob(\tau<\infty)=1$ and $X_\tau$ is bounded.
      \item $\expect[\tau]<\infty$ and $(X_t-X_{t-1})$ is bounded.
    \end{enumerate}
  \end{remark}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_optional_stopping_theorem_martingale}}}
    \everymath={\displaystyle}
    Let $\tau$ be a \textit{Bounded Stopping Time} and $\{X_t\}_{t\in\nats_0}$ be a \textit{Martingale}.
    \par Assume that $\tau\leq K$ (This is reasonable since $\tau$ is bounded). We can write
    \[ X_{\tau(\omega)}{\omega}=\sum_{t=0}^KX_t(\omega)\indexed\{\tau(\omega)=t\} \]
    Note that this is not really a sum as there is only one event $\omega$ st $\indexed\{\tau(\omega)=t\}=1$, the rest equal 0.
    \par Then
    \[\begin{array}{rcl}
      \expect[X_\tau]&=&\expect\left[\sum_{t=0}^KX_t\indexed\{\tau=t\}\right]\\
      &=&\sum_{t=0}^K\expect\left[X_t\indexed\{\tau=t\}\right]\text{ by linearity of exp.}\\
      &=&\sum_{t=0}^K\expect\left[\expect[X_K|\mathcal{F}_t]\indexed\{\tau=t\}\right]\text{ by \texttt{Theorem \ref{sec_probability}.\ref{the_adapated_stochastic_processes_as_martingales}}}
    \end{array}\]
    Since $\tau$ is a \textit{Stopping Time} then $\{\tau=t\}$ is \mathit{Measurable} wrt $\mathcal{F}_t$.
    \par Thus, by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}}
    \[ \expect[X_K|\mathcal{F}_t]\indexed\{\tau=t\}=\expect[X_K\indexed\{\tau=t\}|\mathcal{F}_t] \]
    We continue the analysis of $\expect[X_\tau]$
    \[\begin{array}{rcl}
    \expect[X_\tau]&=&\sum_{t=0}^K\expect\left[\expect[X_K|\mathcal{F}_t]\indexed\{\tau=t\}\right]\\
    &=&\sum_{t=0}^K\expect\left[\expect[X_K\cdot \indexed\{\tau=t\}|\mathcal{F}_t]\right]\\
    &=&\sum_{t=0}^K\expect[X_K\cdot \indexed\{\tau=t\}]\text{ by Tower Law}\\
    &=&\expect\left[X_K\sum_{t=0}^K\indexed\{\tau=t\}\right]\\
    &=&\expect\left[X_K\cdot1\right]\\
    &=&\expect\left[X_K\right]\\
    &=&\expect[X_0]\text{ as }\{X_t\}_{t\in\nats_0}\text{ is a Martingale}\\
    &=&X_0\text{ as its value is known}
    \end{array}\]
  \end{proof}

  \begin{definition}{Gambler's Ruin Problem}\label{def_gamblers_ruin}
    The \textit{Gambler's Ruin Problem} involves considering a gambler with an initial wealth of £$C$. The gambler is allowed to play a game until either they become bankrupt (i.e. have £0) or reach a target of £$(C+G)$ where $G>0$.
    \par The simplest specification of the game is flipping a coin\footnote{potentially fair, potentially not.} and the gambler receives £1 if it lands heads, or loses £1 if it lands tails.
  \end{definition}

  \begin{proposition}{Stopping Time in Gambler's Ruin Problem}\label{prop_stopping_time_gamblers_ruin}
    \everymath={\displaystyle}
    Consider the \textit{Gambler's Ruin Problem} using the simple game described in \texttt{Definition \ref{sec_probability}.\ref{def_gamblers_ruin}}.
    \par Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$\footnote{$\{X_t\}_{t\in\nats_0}$ can be consider to model the net winnings of the gambler and $p$ is the probability of the coin landing heads (i.e. the gambler wins money).} and $X_0=0$ and $C,G>0$.
    \par Consider the \textit{Stopping Time} $\tau:=\inf\{t:X_t=G\text{ or }X_t=-C\}$, the event the gambler stops playing\footnote{Either due to reaching goal or going bankrupt.}. Then
    \begin{itemize}
      \item If $p=1/2$ then
        \[\begin{array}{rcl}
          \prob(X_\tau=G)\footnotemark&=&\frac{C}{C+G}\\
          \prob(X_\tau=-C)\footnotemark&=&\frac{G}{C+G}\\
          \expect[\tau]&=&CG
        \end{array}\]
        \footnotetext{Gambler reaches goal.}
        \footnotetext{Gambler goes bankrupt.}
      \item If $p\neq1/2$ then
        \[\begin{array}{rcl}
          \prob(X_\tau=G)&=&\frac{1-\left(\frac{p}{1-p}\right)^C}{\left(\frac{p}{1-p}\right)^G-\left(\frac{p}{1-p}\right)^C}\\
          \prob(X_\tau=-C)&=&1-\prob(X_\tau=G)=\frac{\left(\frac{p}{1-p}\right)^G-1}{\left(\frac{p}{1-p}\right)^G-\left(\frac{p}{1-p}\right)^C}\\
          \expect[\tau]&=&\frac{G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)}{2p-1}
        \end{array}\]
    \end{itemize}
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_stopping_time_gamblers_ruin}}}
    \everymath={\displaystyle}
    Since $\tau$ is \underline{not} \textit{Bounded}, but $X_\tau$ is \textit{Bounded} by $G,-C$, we can use a weaker condition from \texttt{Remark \ref{sec_probability}.\ref{rem_weaker_optional_stopping_theorem}} to apply the \textit{Optional Stopping Theorem} (\texttt{Theorem \ref{sec_probability}.\ref{the_optional_stopping_theorem_martingale}}) provided we can show that $\prob(\tau<\infty)=1$.
    \par Note that whenever there is a run of $k\geq C+G$ successive 1's in the process $\{Y_t\}_{t\in\nats_0}$ which defines the random walk $X$, the process will stop and $\tau<\infty$. Thus, for all $m$, the following hold
    \[\begin{array}{rcl}
      \prob(\tau>km)&=&\prob(\text{No run of }k\text{ 1's in }Y_1\text{ to }Y_{mk})\\
      &=&\prod_{j=0}^{m-1}\prob(\text{No run of }k\text{ 1's in }Y_{jk+1}\text{ to }Y_{(j+1)k})\\
      &=&(1-p^k)^m\\
      \implies\prob(\tau<\infty)&=&1
    \end{array}\]
    We can now consider the two cases for the value of $p$
    \begin{itemize}
      \item If $p=1/2$. Then by the \textit{Optional Stopping Theorem} we can deduce the following
      \[\begin{array}{rrcl}
        &0&=&\expect[X_\tau]\text{ as }p=1/2\\
        &&=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)\\
        &&=&G\prob(X_\tau=G)+(-C)(1-\prob(X_\tau=G))\\
        \implies&C&=&(G+C)\prob(X_\tau=G)\\
        \implies&\prob(X_\tau=G)&=&\frac{C}{G+C}\\
        \text{and }&\prob(X_\tau=-C)&=&1-\prob(X_\tau=G)=\frac{G}{G+C}
      \end{array}\]
      To determine $\expect[X_\tau]$ we apply the \textit{Optional Stopping Theorem} to the process $\{Z_t\}_{\nats_0}$ where $Z_t:=X_t^2-t$. It was shown in \texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}}  that $\{Z_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \par As $\{Z_t\}_{t\in\nats_0}$ is a \textit{Martingale} it holds that
      \[ 0=\expect[Z_0]=\expect[Z_\tau]=\expect[X_\tau^2-\tau]=\expect[X_\tau^2]-\expect[\tau] \]
      By rearranging we obtain that
      \[\begin{array}{rcl}
        \expect[\tau]&=&\expect[\tau]\\
        &=&G^2\prob(X_\tau=G)+C^2\prob(X_\tau=-C)\\
        &=&G^2\cdot\frac{C}{C+G}+C^2\frac{G}{C+G}\\
        &=&CG
      \end{array}\]
      \item Consider the case $p\neq1/2$ and the process $\{L_t\}_{t\in\nats_0}$ where $L_t:=\left(\frac{1-p}p\right)^{X_t}$. It was shown in \texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} that $\{L_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \par By the \textit{Optional Stopping Theorem}
      \[\begin{array}{rcl}
        1&=&\expect[L_0]\\
        &=&\left(\frac{1-p}p\right)^G\prob(X_\tau=G)+\left(\frac{1-p}p\right)^C\prob(X_\tau=-C)
      \end{array}\]
      Remembering that $\prob(X_\tau=G)+\prob(X_\tau=-C)=1$, we can derive the probabilities of each end event occurring
      \[\begin{array}{rcl}
        1&=&\left(\frac{1-p}p\right)^G\prob(X_\tau=G)+\left(\frac{1-p}p\right)^C(1-\prob(X_\tau=G))\\
        &=&\left(\frac{1-p}p\right)^C+\left[\left(\frac{1-p}p\right)^G-\left(\frac{1-p}p\right)^C\right]\prob(X_\tau=G)\\
        \implies\prob(X_\tau=G)&=&\frac{1-\left(\frac{1-p}p\right)^C}{\left(\frac{1-p}p\right)^G-\left(\frac{1-p}p\right)^C}
      \end{array}\]
      Consider the process $\{M_t\}_{t\in\nats_0}$ where $M_t:=X_t-t(2p-1)$. It was shown in \texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} that $\{M_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \par We determine $\expect[X_\tau]$ by applying the \textit{Optional Stopping Theorem} to $\{M_t\}_{t\in\nats_0}$.
      \[\begin{array}{rcl}
        0&=&\expect[M_\tau]\\
        &=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)-\expect[\tau](2p-1)
      \end{array}\]
      By rearranging we obtain that
      \[\begin{array}{rrcl}
        &0&=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)-\expect[\tau](2p-1)\\
        \implies&\expect[\tau](2p-1)&=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)\\
        \implies&\expect[\tau]&=&\frac{G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)}{2p-1}
      \end{array}\]
    \end{itemize}
    \proved
  \end{proof}

\section{Financial Terminology}\label{sec_financial_terminology}

  \begin{definition}{Underlying Asset}
    The \textit{Underlying Asset} is a real financial asset or security which a contract can be based on. (e.g. Oil, interest rate, shares).
  \end{definition}

  \begin{definition}{Dividend}
    A \textit{Dividend} is a one-off payment provided to the holder of an \textit{Underlying Asset} at a certain time. Whether an \textit{Underlying Asset} pays a \textit{Dividend}, and the value of the \textit{Dividend}, will affect the value of the \textit{Underlying Asset}.
    \par A \textit{Dividend} is generally used by companies to distribute yearly profits to its shareholders.
  \end{definition}

  \begin{definition}{Long Selling}
    \textit{Long Selling} is the practice of buying an asset (or security) and then selling it at some point in the future.
    \par In \textit{Long Selling} your profit/loss is $P_{\text{sell}}-P_{\text{buy}}$, thus you hope the price of the asset \underline{increases} in the period between you buying and selling it.
  \end{definition}

  \begin{definition}{Short Selling}
    \textit{Short Selling} is the practice of borrowing an asset (or security), immediately selling it\footnote{Receiving payment at this point.} and at some point in the future buying an equivalent asset in order to reimburse your lender.
    \par In \textit{Short Selling} your profit/loss if $P_{\text{sell}}-P_{\text{buy}}$, thus you hope the price of the asset \underline{decreases} in the period between you selling and having to reimburse your lender.
  \end{definition}

  \begin{remark}{Short Selling \& Dividends}
    If the asset you borrowed in \textit{Short Selling} pays a \textit{Dividend} during the time you have borrowed the asset, then you must pay this \textit{Dividend} to the lender.\footnote{As you have already sold the asset, then this expense will come out of your own pocket.}
  \end{remark}

  \begin{definition}{Arbitrage Opportunity}
    An \textit{Arbitrage Opportunity} occurs when it is possible to make a profit without being exposed to the risk of incurring a loss.\footnote{Someone who loos for \textit{Arbitrage Opportunities} is called an \textit{Arbitrageur}.}
    \par Generally \textit{Arbitrage Opportunities} occur by being able to buy and sell the same asset in different markets, as each market may have a different price.
  \end{definition}

  \begin{theorem}{No-Arbitrage Principle}
    \begin{quote}
      ``\textit{Arbitrage Opportunities} do not exist (for long) in real life markets.''
    \end{quote}
    As when the opportunities arise, the market activity cause by agents exploiting the opportunity would raise the cost of buying and thus remove the opportunity due to the \textit{Law of Supply-and-Demand}.
  \end{theorem}

  \begin{remark}{Value of Money}
    IRL the value of money is not constant due to inflation, interest rates \& exchange rates. We generally want to normalise the returns of our portfolio wrt the change in value of money in order to determine the ``real returns''.
  \end{remark}

  \begin{definition}{Bank Account Process, $B_t$}\label{def_bank_account_process}
    A \textit{Bank Account Process}\footnote{AKA a \textit{Bond} or a \textit{Numeraire}.} $B_t$ is how much an initial deposit of one unit at time $t=0$ would be worth at time point $t$ if the deposit was made into a ``Risk-Free Bank Account'', given some risk-free \textit{Interest Rate} $r$. This is a measure of how the value of money changes over the $t$ time-periods.
    \par The \textit{Bank Account Process} must fulfil the following criteria
    \[ B_0=1\quad\text{and}\quad B_t(\omega)\geq0\ \forall\ \omega\in\Omega \]
    It is generally assumed that you can borrow money from these accounts, paying the same interest rate $r$.
  \end{definition}

  \begin{proposition}{Value of Bank Account Process $B_t$}
    \par Suppose our ``Risk-Free Bank Account'' pays a constant interest rate of $r$ in each time-period, then after $t$ time-periods our initial deposit would be worth
    \begin{itemize}
      \item \textit{Continuous Time Model} $B_t=B_0e^{rt}$.
      \item \textit{Single-Period Model} $B_1=B_0(1+r)$.\footnote{Must be that $t=1$ in a \textit{Single-Period Model}.}
      \item \textit{Multi-Period Model} $B_t=B_0(1+r)^t$.
    \end{itemize}
  \end{proposition}

  \begin{definition}{Portfolio}
    % Replicating Portfolio
  \end{definition}

\subsection{Derivatives}

  \begin{definition}{Derivative Securities}
    A \textit{Deriviative Security} is a contract which has an expiry date $T$ and pays out different amounts depending upon the value of some \textit{Underlying Asset} in the time-period $[0,T]$.
  \end{definition}

  \begin{remark}{Valuing Contracts}
    When valuing contracts we assume that arbitrage does not exist. This means we can derive a single price\footnote{Known as the \textit{Fair Price}.} for a contract, as any other price would create an \textit{Arbitrage Opportunity}.
  \end{remark}

  \begin{theorem}{Equivalent Contract Valuations over Time}\label{the_equivalent_contract_valuations_over_time}
    If two combinations of financial derivatives both have the same value $V_T=W_T$ at time $t=T$. Then their prices will be the same at all $t<T$
    \[ \text{if }V_T=W_t\text{ then }V_t=W_t\ \forall\ t<T \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_equivalent_contract_valuations_over_time}} }
    \textit{We assume the ``No-Arbitrage Principle'' holds throughout this proof.}
    \par Let $V_t,W_t$ represent the fair price for two different combinations of financial derivatives at time $t$ and that $V_T=W_T$. Suppose there is a risk-free profit of $r$.
    \par Assume WLOG that $V_t>W_t$. Then an arbitrage opportunity exists and can be exploited by doing the following:
    \begin{itemize}
      \item At $t=0$
      \begin{enumerate}
        \item Sell/short the first combination, receiving £$V_t$.
        \item Buy the second combination, costing £$W_t$.
        \item Invest the difference (£$V_t-W_t>0$).
      \end{enumerate}
      \item At $t=T$
      \begin{enumerate}
        \item Sell the first combination, receiving £$V_T=W_T$
        \item Buy the second combination, costing £$W_T=V_T$.
      \end{enumerate}
    \end{itemize}
    Following this will result in a ``riskless'' profit of $(V_t-W_t)e^{r(T-t)}>0$.
  \end{proof}

  \begin{definition}{Forward Contract}
    A \textit{Forward Contract} is a type of \textit{Derivative Security}. In a \textit{Forward Contract} two parties agree to an exchange on a predetermined future date for a predetermined amount, and are both \underline{obliged} to fulfil this exchange.
    \par All \textit{Forward Contracts} have the following components
    \begin{itemize}
      \item \textit{Delivery Date} $T$.
      \item \textit{Delivery Price} $K$.
    \end{itemize}
  \end{definition}

  \begin{remark}{Positions in a Forward Contract}
    In a \textit{Forward Contract} agents can take two positions
    \begin{itemize}
      \item \textit{Long Position} - Agree to buy the underlying asset for $\pounds K$ on date $T$. Makes a profit if the market-value of the underlying asset is \underline{greater} than $K$ in time-period $T$.
      \item \textit{Short Position} - Agree to sell the underlying asset for $\pounds K$ on date $T$. Makes a profit if the market-value of the underlying asset is \underline{less} than $K$ in time-period $T$.
    \end{itemize}
  \end{remark}

  \begin{remark}{Utility of Forwards Contracts}
    \textit{Forward Contracts} allow you to agree terms of a purchase/sale some time in advance of actually transacting. This means business have greater certainty about their future cash-flows.\footnote{e.g. Farmers may agree to a price for their whole harvest a year in advance. Thus their next years income is completely known.}
  \end{remark}

  \begin{theorem}{Fair Delivery Price of a Forward Contract}\label{the_fair_price_of_a_forward_contract}
    Consider a \textit{Forward Contract} with delivery date $T$, where the underlying asset has value $S_0$ at time $t=0$ and pays a dividend $D$ at time $t_0\in(0,T)$. Suppose there is a risk-free bank account with a constant interest rate $r$ during the interval $[0,T]$.\footnote{This means $B_t=e^{rt}$.}
    \par Then
    \begin{itemize}
      \item If $D=0$ (ie no dividend is payed) then the fair \textit{Delivery Price} for this contract is
      \[ K=S_0e^{rT} \]
      \item If $D>0$ then the fair \textit{Delivery Price} for this contract is
      \[ K=(S_0-I)e^{rT}\text{ where }I:=De^{-rt_0} \]
    \end{itemize}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_fair_price_of_a_forward_contract}}}
    \textit{We use the ``No-Arbitrage Principle'' to prove that these $K$s are the fair prices under each scenario.}
    \par \textit{Case 1} - Suppose, for the sake-of-contradiction, that $K>(S_0-I)e^{rT}$ with $I:=De^{-rt_0}$. Then an arbitrage opportunity exists and can be exploited by doing the following:
    \begin{itemize}
      \item At $t=0$
      \begin{enumerate}
        \item Borrow £$S_0$ from the bank, at an interest rate of $r$.
        \item Buy the underlying asset.
        \item Taking a short position in the forward contract (receiving $K>(S_0-I)e^{rT}$).
      \end{enumerate}
      \item At $t=t_0$
      \begin{enumerate}
        \item We will receive a dividend payment £$D$ which we shall use to partially repay our loan. This leaves an outstanding balance of $S_0e^{rt_0}-D$.
      \end{enumerate}
      \item At $t=T$
      \begin{enumerate}
        \item Sell the asset for $K$ using the forward contract.
        \item Repay the outstanding balance on the loan ($(S_0e^{rt_0}-D)e^{r(T-t_0)}$).
      \end{enumerate}
    \end{itemize}
    \par Doing all this will lead to a ``riskless'' profit of
    \[ K-(S_0e^{rt_0}-D)e^{r(T-t_0)}=K-(S_0-I)e^{rT}>0\text{ by def. }K \]
    This means that this definition of $K$ cannot be the fair-price, thus $K\leq(S_0-I)e^{rT}$.
    \par \textit{Case 2} - Suppose, for the sake-of-contradiction, that $K<(S_0-I)e^{rT}$ with $I:=De^{-rt_0}$. Then an arbitrage opportunity exists and can be exploited by doing the following:
    \begin{itemize}
      \item At $t=0$
      \begin{enumerate}
        \item Short sell the underlying asset. (Receiving £$S_0$).
        \item Invest this revenue, receiving an interest rate of $r$.
        \item Take a long position on the forward contract.
      \end{enumerate}
      \item At $t=t_0$
      \begin{enumerate}
        \item Pay the dividend £$D$ to our lender, from our bank account.
      \end{enumerate}
      \item At $t=T$
      \begin{enumerate}
        \item Buy the asset for $K$ using the forward contract.
      \end{enumerate}
    \end{itemize}
    \par Doing all this will lead to a ``riskless'' profit of
    \[ (S_0e^{rt_0}-D)e^{r(T-t_0)}-K=(S_0-I)e^{rT}-K>0\text{ by def. }K \]
    This means that this definition of $K$ cannot be the fair-price, thus $K\geq(S_0-I)e^{rT}$.
    \par Thus, by combining these two inequalities, the fair price for this \textit{Forward Contract} is
    \[ K=(S_0-I)e^{rT} \]
  \end{proof}

  \begin{definition}{Options Contract}
    An \textit{Options Contract} is a type of \textit{Derivative Security}. In an \textit{Options Contract} two parties agree to an exchange on (or before) a predetermined future date for a predetermined amount, but the holder is \underline{not obliged} to fulfil this exchange.
    \par All \textit{Options Contracts} have the following components
    \begin{itemize}
      \item \textit{Delivery Date} $T$.
      \item \textit{Strike Price} $K$.
    \end{itemize}
    There are two classes of \textit{Options Contract}
    \begin{itemize}
      \item \textit{Call Option} - The holder has the right to buy.
      \item \textit{Put Option} - The holder has the right to sell.
    \end{itemize}
  \end{definition}

  \begin{definition}{European \& American Options}
    There are two categories of \textit{Options Contract} which determine when the contract can be exercised
    \begin{itemize}
      \item \textit{European Option} - The holder can only execute on the delivery date $t=T$.
      \item \textit{American Option} - The holder can execute on \underline{any} date before the delivery date $T$.
    \end{itemize}
  \end{definition}

  \begin{definition}{Positions in an Options Contract}
    In \textit{Options Contracts} agents can take one of two positions. The position they take determines their rights \& potential cash-flows.
    \begin{itemize}
      \item \textit{Holder} - Decides whether to execute the contract of not. Will pay the \textit{Writer} a fee for creating the contract.
      \par The \textit{Holder's} only expense is the fee they pay the \textit{Writer} and they may make an income if they execute the contract.
      \item \textit{Write} - Must complete the transaction if the \textit{Holder} wishes to. Receives a fee from the \textit{Holder}.
      \par The \textit{Writer's} only income is the fee they receive from the \textit{Holder} and they may incur a loss if the contract is executed.
    \end{itemize}
  \end{definition}

  \begin{remark}{When are options executed?}
    Whether the holder should execute their option depends on the market price $S_T$ at time $T$, the strike price $K$ and the class of contract. Assuming (justifiably) that the holder will only execute the option if it will make them money, the holder should do the following
    \begin{itemize}
      \item For a \textit{Call Option} the holder should execute if $S_T>K$. As they can immediately sell their newly bought asset for a profit of $S_T-K-F$ where $F$ is the fee payed to the writer.
      \item For a \textit{Put Option} the holder should execute if $S_T<K$. As they can buy the asset from the market and sell it to the writer of their option for a profit of $S_T-K-F$ where $F$ is the fee payed to the writer.
    \end{itemize}
  \end{remark}

  \begin{theorem}{Put-Call Parity\footnote{This is an application of \texttt{Theorem \ref{sec_financial_terminology}.\ref{the_equivalent_contract_valuations_over_time}} to European Put \& Call Options.}}\label{the_put_call_parity}
    Consider a \textit{European Put Option} and a \textit{European Call Option} where both have the same: underlying asset, strike price $K$ and expiry date $T$. Let $S_t$ be the value of the underlying asset at time point $t$ and assume there is a ``risk-free'' interest rate of $r$ available.
    \par Then, if \underline{no} \textit{Arbitrage Opportunities} exist then the following hold
    \[ S_t+P_t-C_t=Ke^{-r(T-t)}\ \forall\ t\in[0,T] \]
    where $P_t,C_t$ are the prices of the put \& call options at time $t$ respectively, and $Ke^{-r(T-t)}$ is the discounted value of our bank account.
  \end{theorem}

  \begin{theorem}{Lower-Bound for a European Call Option}\label{the_lower_bound_for_a_european_call_option}
     Let $S_t$ be the value of an underlying asset at time $t$.
     \par For a \textit{European Call Option} with strike price $K$ and delivery date $T$ we can determine the following lower bound on its price $C_t$
    \[\begin{array}{rcl}
      C_t&\geq&\{S_t-Ke^{-r(T-t)}\}_+
    \end{array}\]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_lower_bound_for_a_european_call_option}} }
    By \textit{Put-Call Parity} (\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_put_call_parity}}) we have that
    \[\begin{array}{rrcl}
      &S_t+P_t-C_t&=&Ke^{-r(T-t)}\\
      \implies&C_t&=&S_t+P_t-Ke^{-r(T-t)}
    \end{array}\]
    Since \textit{Put Options} cannot have a negative price, $P_t\geq0$, we have that
    \[ C_t\geq S_t+P_t-Ke^{-r(T-t)} \]
    Further, since \textit{Call Options} cannot have a negative price, $C_t\geq0$, we have that
    \[ C_t\geq \big\{S_t+P_t-Ke^{-r(T-t)}\big\}_+ \]
  \end{proof}

  \begin{theorem}{Value of American Call Options w/o Dividends}\label{the_value_of_america_call_options_wo_dividends}
    Consider an \textit{American} \& a \textit{European Call Option}, for the same underlying asset, with the same strike price and expiry date.
    \par Then, if the underlying asset does \underline{not} pay a \textit{Dividend}
    \[ C_A=C_E\footnotemark \]
    \footnotetext{This shows that if an underlying asset does not pay a dividend then it is suboptimal to exercise an \textit{American Call Option} early.}
    where $C_A,C_E$ are the price of the American \& European call options, respectively.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_value_of_america_call_options_wo_dividends}}}
    If the \textit{American Call Option} is executed early at time-point $t<T$ then it generates an income of $S_t-K$.
    \par However, \texttt{Theorem \ref{sec_financial_terminology}.\ref{the_lower_bound_for_a_european_call_option}} shows that selling a \textit{Call Option} generates
    \[ \{S_t-Ke^{-r(T_t)}\}_+\geq S_t-Ke^{-r(T-t)}>S_t-K \]
    This shows that it is sub-optimal to exercise the call at any time $t<T$.
  \end{proof}

\section{Discrete-Time}\label{sec_discrete_time_models}

\subsection{Single-Period Model}

  \begin{definition}{Single-Period Model}
    The \textit{Single-Period Model} is a model for a financial market where actions can only occur on two dates. It has the following components
    \begin{itemize}
      \item \textit{Initial Date} $t=0$.
      \item \textit{Terminal Date} $t=1$.
      \item Trading is only allowed to occur on the \textit{Initial \& Terminal Dates}.
      \item A finite \textit{Sample Space} $\Omega:=\{\omega_1,\dots,\omega_K\}$ with $K<\infty$.
      \par Each event $\omega_1,\dots,\omega_K$ corresponds to some state of the world.
      \item A \textit{Probability Measure} $\prob$ on the \textit{Sample Space} $\Omega$ with $\prob(\{\omega_i\})>0\ \forall\ i\in[1,K]$.
    \end{itemize}
  \end{definition}

  \begin{definition}{Price-Process $S$\footnote{AKA \textit{Stock Process}}}\label{def_price_process}
    A \textit{Price Process} $S$ models the price of each security at each time-point
    \[ S:=\{S(t):t=0,1\}\text{ where }S(t)=(S_1(t),\dots,S_N(t)) \]
    where $S(t)$ is the collection of the prices of each available stock at time $t$, $S_i(t)$ is the price of the $i^{th}$ stock at time $t$ and there are $N$ different stock available.
    \par The values of $S(0)$ are known to the investors, but $S(1)$ are unknown non-negative random variables whose value only become known at time $t=1$.
  \end{definition}

  \begin{definition}{Discounted Price-Process $S^*$}\label{def_discounted_price_process}
    A \textit{Discounted Price-Process} $S^*$ models the price of each security at each time-point \underline{but} normalised for the change in the value of money due to the \textit{Bank Process} $B$.
    \[ S^*:=\{S^*(t):t=0,1\}\text{ where }S^*(t)=(S_1^*(t),\dots,S_N^*(t))\text{ and }S_i^*(t):=\frac{S_i(t)}{B_t} \]
  \end{definition}

  \begin{definition}{Trading Strategy $H$}
    A \textit{Trading Strategy} $H$ describes the changes in an investors portfolio between the \textit{Initial Date} $t=0$ and \textit{Terminal Date} $t=1$.
    \[ H:=(H_0,H_1,\dots,H_N) \]
    where $H_0$ is the amount invested/borrowed in a risk-free bank account, $H_i$ is the amount bought/shorted of the $i^{th}$ stock for $i\in[1,N]$ and there are $N$ stocks available in the market.
  \end{definition}

  \begin{definition}{Value-Process $V$}\label{def_value_process}
    A \textit{Value Process} $V$ describes the total value of a \textit{Trading Strategy} $H$ at each time-point $t=0,1$
    \[ V:=\{V_t:t=0,1\}\text{ where }V_t=H_0B_t+\sum_{i=1}^NH_iS_i(t) \]
  \end{definition}

  \begin{definition}{Discounted Value-Process $V^*$}\label{def_discounted_value_process}
    A \textit{Discounted Value-Process} $V^*$ describes the total value of a \textit{Trading Strategy} $H$ at each time-point \underline{but} normalised for the change in the value of money due to the \textit{Bank Process} $B$.
    \[ V^*:=\{V_t^*:t=0,1\}\text{ where }V_t^*:=\frac{V_t}{B_t}=H_0+\sum_{i=1}^NH_iS_i^*(t) \]
  \end{definition}

  \begin{definition}{Gains-Process $G$}\label{def_gains_process}
    A \textit{Gains Process} $G$ describes the total profit/loss generated made by a \textit{Trading Strategy} $H$ between time-points $t=0,1$
    \[ G:=H_0r+\sum_{i=1}^NH_i\Delta_{S_i}\text{ where }\Delta_{S_i}=S_i(1)-S_i(0)\footnotemark \]
    \footnotetext{$\Delta_{S_i}$ The change in value of the $i^{th}$ stock.}
  \end{definition}

  \begin{definition}{Discounted Gains-Process $G^*$}\label{def_discounted_gains_process}
    A \textit{Discounted Gains-Process} $G^*$ describes the total profit/loss generated made by a \textit{Trading Strategy} $H$ between time-points $t=0,1$ \underline{but} normalised for the change in the value of money due to the \textit{Bank Process} $B$.
    \[ G^*:=\frac{G}{B_t}=\sum_{i=1}^NH_i\Delta_{S_i^*}\text{ where }\Delta_{S_i^*}=S_i^*(1)-S_i^*(0) \]
  \end{definition}

  \begin{definition}{Arbitrage Opportunity - Single-Period Model}
    Consider a \textit{Trading Strategy} $H=(H_0,H_1)$ for the \textit{Single-Period Model}.
    \par $H$ exploits an \textit{Arbitrage Opportunity} if it has the following three properties
    \begin{enumerate}
      \item $V_0=0$.
      \item $V_1(\omega)\geq0\ \forall\ \omega\in\Omega$.
      \item $\prob(V_1(\omega)\geq0)>0\ \forall\ \omega\in\Omega$.\footnote{Equivalently $\expect[V_1]>0$}
    \end{enumerate}
  \end{definition}

  \begin{theorem}{Arbitrage Opportunities \& Gains Process}\label{the_arbitrage_opportunities_and_gains_processes}
    There exists an \textit{Arbitrage Opportunity} in a market \underline{iff} there exists a \textit{Trading Strategy} $H$ st\footnote{This means $H$ never loses money, and it is expected to make money.}
    \[ G^*\geq0\quad\text{and}\quad\expect[G^*]>0 \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_arbitrage_opportunities_and_gains_processes}}}
    \begin{itemize}
      \item[$\Rightarrow$] Let $H$ be a \textit{Trading Strategy} which exploits an \textit{Arbitrage Opportunity}.
      \par By the definition of an \textit{Arbitrage Opportunity} $G^*=V_1^*-V_0^*$ and $B_t>0\ \forall\ t,\omega$, this means that $G^*\geq0$ and thus
      \[ \expect[G^*]=\expect[V_1^*]>0 \]
      \item[$\Leftarrow$] Let $H$ be a \textit{Trading Strategy} which satisfies $G^*\geq0$ and $\expect[G^*]>0$.
      \par Define $\hat{H}:=(\hat{H_0},H_1,\dots,H_N)$ where $\hat{H}_0:=-\sum_{i=1}^NH_iS_i^*(0)$\footnote{This ensures $V_0$, a requirement for $H$ to exploit an \textit{Arbitrage Opportunity}.}.
      \par Under $\hat{H}_0$ we have that $V_0^*=0$ and $V_1^*=V_0^*+G^*=G^*$.
      \par Hence, $V_1^*\geq0$ and $\expect[V_1^*]=\expect[G^*]>0$, meaning $\hat{H}$ exploits an \textit{Arbitrage Opportunity}.
    \end{itemize}
    As the result holds in both directions, we can say it holds \underline{iff}.
  \end{proof}

\subsubsection{Risk-Neutral Probability Measures $\Q$}

  \begin{definition}{Risk-Neutral Probability Measure $\Q$}
    A \textit{Probabiltiy Measure} $\Q$ on \textit{Sample Space} $\Omega$ is said to be a \textit{Risk-Neutral Probability Measure} if the following hold
    \begin{enumerate}
      \item $\Q(\{\omega\})>0\ \forall\ \omega\in\Omega$.
      \item $\expect_\Q[S_i*(1)]=S_i^*(0)\ \forall\ i\in[1,N]$
    \end{enumerate}
  \end{definition}

  \begin{theorem}{Separating Hyperplane Theorem\footnote{This theorem is used to prove \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_no_arbitrage_theorem}}. The proof of this theorem is beyond the scope of this course.}}\label{the_separating_hyperplane_theorem}
    Let $\mathbb{W}$ be a linear subspace of $\reals^K$ and $\mathbb{K}$ be a compact convex subset in $\reals^K$ which is disjoint from $\mathbb{W}$.
    \par We can separate $\mathbb{W}$ and $\mathbb{K}$ strictly by using a hyperplane containing $\mathbb{W}$\footnote{ie $\exists\ v\in\reals^K$ which is \textit{Orthogonal} to $\mathbb{W}$\footnotemark{$u^Tv=0\ \forall\ u\in \mathbb{W}$}.} st
    \[ u^Tv>0\ \forall\ u\in\mathbb{K} \]
  \end{theorem}

  \begin{theorem}{Arbitrage Opportunities \& Risk-Neutral Probability Measures}\label{the_no_arbitrage_theorem}
    No \textit{Arbitrage Opportunities} exists \underline{iff} there exists a \textit{Risk-Neural Probability Measure} $\Q$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_no_arbitrage_theorem}}}
    \par Consider the three following sets
    \begin{enumerate}
      \item $\mathbb{W}=\left\{X\in\reals^K:X=G^*\text{ for some Trading Strategy }H\right\}$.
      \par This is the set of possible \textit{Gains} in our market for \textit{Trading Strategies} which have zero initial investment. $\mathbb{W}$ is a linear subspace of $\reals^K$\footnote{Proved by showing it is complete under: addition, and scalar multiplication.}.
      \item $\mathbb{A}=\left\{X\in\reals^K:X\geq0,X\neq0\right\}$\footnote{$\mathbb{A}$ is not compact, so can not be used for $\mathbb{K}$ in \textit{Separating Hyperplane Theorem}}.
      \par There exists an arbitrage opportunity \underline{iff} $\mathbb{W}\cap\mathbb{A}\neq\emptyset$.
      \item $\mathbb{A}^+=\left\{X\in\reals^N:X\geq0,X\neq0,\sum_{i=1}^KX_i=1\right\}$.
      \par $\mathbb{A}^+$ is a convex and compact subset of $\reals^K$.
    \end{enumerate}
    \begin{itemize}
      \item[$\Rightarrow$] Assume that there are no \textit{Arbitrage Opportunities}, then $\mathbb{W}\cap\mathbb{A}\neq\emptyset$. \par By the \textit{Separating Hyperplane Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_separating_hyperplane_theorem}}) $\exists\ Y\in\reals^K$ which is \textit{orthogonal} to $\mathbb{W}$ st
      \[ X^TY>0\ \forall\ X\in\mathbb{A}^+ \]
      For each $k\in\{1,\dots,K\}$ the $k^\text{th}$ unit vector $e_k$ is an element of $\mathbb{A}^+$. Therefore,
      \[ Y_k:=e_k^TY>0\ \forall\ k\in\{1,\dots,K\} \]
      meaning all entries of $Y$ are strictly positive.
      \par Define a probability measure $\Q$ by setting
      \[ \Q(\{\omega_k\})=\frac{Y(\omega_k)}{Y(\omega_1)+\dots+Y(\omega_k)} \]
      Furthermore, $\Delta S_n^*\in\mathbb{W}\ \forall\ n$ because $\Delta S_n^*:=S_n^*(1)-S_n^*(0)$ is the discounted wealth for the portfolio $H:=e_n$ which consists of one unit of the $n^\text{th}$ asset only.
      \par Since $Y$ is orthogonal to $\mathbb{W}$ we can conclude that
      \[ \expect_\Q[\Delta S_n^*]=\sum_{k=1}^K\Delta S_n^*(\omega_k)\Q(\{\omega_k\})=0\ \forall\ n \]
      In other words
      \[ \expect_\Q[S_n^*(1)]=S_n^*(0)\ \forall\ n \]
      Thus $\Q$ is a \textit{Risk-Neutral Probability Measure}.

      \item[$\Leftarrow$] Let $\Q$ be a \textit{Risk-Neutral Probability Measure}.
      \par Then for an arbitrary \textit{Trading Strategy} $H$ we have that
      \[ \expect_\Q[G^*]=\expect_\Q\left[\sum_{n=1}^NH_n\Delta S_n^*\right]=\sum_{n=1}^NH_n\expect_\Q[\Delta S_n^*]=0 \]
      and, in particular
      \[ \sum_{k=1}^KG^*(\omega_k)\Q(\{\omega_k\})=0 \]
      which shows that either $G^*(\omega_k<0)$ for some $k$ or $G^*=0$, but then $\expect_\Q[G^*]=0$.
      \par Hence, by \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_arbitrage_opportunities_and_gains_processes}}, there cannot be any arbitrage opportunities.
    \end{itemize}
    The result holds in both directions.\proved
  \end{proof}

\subsubsection{Contingent Claims $X$}

  \begin{definition}{Contingent Claim $X$ - Single-Period Model}
    Consider a \textit{Single-Period Model} with a risk-free bank process and $K-1$ risky securities on offer.
    \par A \textit{Contingent Claim} $X\in\reals^K$ in a \textit{Single-Period Model} is a random variable which represents a payoff at time $t=1$ for each security\footnote{This payoff is not necessarily achievable}.
  \end{definition}

  \begin{definition}{Attainable Contingent Claim $X$}
    A \textit{Contingent Claim} $X$ is said to be ``\textit{attainable}'' if
    \begin{center}
      $\exists$ trading strategy $H$ st $V_1=X$ when using $H$\footnote{This $H$ called a \textit{Replicating Portfolio} and is said to ``\textit{generate}''$X$}.
    \end{center}
    Otherwise, $X$ is said to be ``\underline{un}\textit{attainable}''.
  \end{definition}

  \begin{remark}{Determining whether a Contingent Claim $X$ is Attainable}
    Consider a \textit{Single-Period Model} with $K-1$ securities, which can be described the following matrix $A$, and a \textit{Contingent Claim} $X\in\reals^K$. Then
    \begin{quote}
      $X$ is \textit{Attainable} iff $\exists$ a trading strategy $H\in\reals^K$ st $AH=X$ where
      \[ A:=\begin{pmatrix}
          B_1(\omega_1)&S_1(1)(\omega_1)&\dots&S_N(1)(\omega_1)\\
          B_1(\omega_2)&S_1(1)(\omega_2)&\dots&S_N(1)(\omega_2)\\
          \vdots&\vdots&\ddots&\vdots\\
          B_1(\omega_K)&S_1(1)(\omega_K)&\dots&S_N(1)(\omega_K)
      \end{pmatrix} \]
    \end{quote}
  \end{remark}

  \begin{theorem}{Fair Price of a Contingent Claim}\label{the_fair_price_of_a_contingent_claim}
    Let $X$ be an \textit{Attainable Contingent Claim} and $H$ be a \textit{Replicating Portfolio} which generates $X$.
    \begin{quote}
      \text{The value of portfolio $H$ at time $t=0$ ($V_0$) is the ``fair-price'' of the contingent claim $X$.}
    \end{quote}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_fair_price_of_a_contingent_claim}}}
    Let $X$ be an \textit{Attainable Contingent Claim} and $H$ be a \textit{Replicating Portfolio} which generates $X$.
    \par Let $p$ be the fair price for $X$ and assume, for the sake of contradiction, that $p$ does \underline{not} equal the value of $H$ at time $t=0$. This means we assuming that $p\neq V_0$.
    \par We have two cases
    \begin{itemize}
      \item[Case 1] - $p>V_0$.
      \par In this case, an \textit{arbitrage opportunity} exists and can be exploited by doing the following
      \begin{itemize}
        \item At $t=0$ - Short the \textit{Contingent Claim} for $p$; buy portfolio $H$ for $V_0$; and invest the difference $p-V_0>0$.
        \item At $t=1$ - Our portfolio has the same value as $X$ so we sell $H$ to fulfil our short position on the contingent claim.
      \end{itemize}
      Our profit in this scenario is $(p-V_0)B_1=(p-V_0)(1+r)>0$.
      \item[Case 2] - $p<V_0$.
      \par In this case, an \textit{arbitrage opportunity} exists and can be exploited by doing the following
      \begin{itemize}
        \item At $t=0$ - Buy the \textit{Contingent Claim} for $p$; buy portfolio $-H$\footnote{Note this is equivalent to shorting portfolio $H$} for $-V_0$; and invest the difference $V_0-p>0$.
        \item At $t=1$ - Our portfolio has value $-X$ so we sell our \textit{Contingent Claim} for $X$ to cover the portfolio, fulfilling any short positions.
      \end{itemize}
      Our profit in this scenario is $(V_0-p)B_1=(V_0-p)(1+r)>0$.
    \end{itemize}
    Hence, in all scenarios where $p\neq V_0$ an arbitrage opportunity exists.
    This means $p\neq V_0$ cannot be the fair price for $X$ and thus $p=V_0$ is the fair price.\proved
  \end{proof}

  \begin{theorem}{Risk-Neutral Valuation Principle}\label{the_risk_neutral_valuation_principle}
    Consider a \textit{Single-Period Model} where \underline{no} \textit{Arbitrage Opportunities} exists, and let $\Q$ be a \textit{Risk-Neutral Probability} for this model.
    \par Then the ``fair-price'' of an \textit{Attainable Contingent Claim} $X$ at time $t=0$
    \[ p=\expect_\Q[X/B_1] \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_risk_neutral_valuation_principle}}}\label{prf_risk_neutral_valuation_principle}
    \par Consider a \textit{Single-Period Model} with \underline{no} arbitrage opportunities and let $X$ be an \textit{Attainable Contingent Claim} under this model.
    \par Here we derive the fair-price for $X$ and show that time price is unique.
    \par Suppose there exists two trading strategies $H,\hat{H}$ st $V_1=\hat{V}_1=X$ but $\hat{V}_0\neq V_0$.
    \par Let $\Q$ be a \textit{Risk-Neutral Probability Measure} under this model. Then, by the \textit{No-Arbitrage Principle} (\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_no_arbitrage_theorem}}), we have that for any trading strategy $H$ $\expect_\Q[G^*]=0$. Thus we can deduce that
    \[\begin{array}{rcl}
      V_0&=&V_0^*\\
      &=&\expect_\Q[V_0^*]\\
      &=&\expect_\Q[V_1^*-G^*]\\
      &=&\expect_\Q[V_1^*]-\expect_\Q[G^*]\\
      &=&\expect_\Q[V_1^*]-0\\
      &=&\expect_\Q[V_1/B_1]
    \end{array}\]
    This shows that any trading strategy $H$ with $V_1=X$ (ie is worth $X$ at time $t=1$), has the following value at time $t=0$
    \[ V_0=\expect_\Q[V_1/B_1]=\expect_\Q[X/B_1] \]
    This holds for all \textit{Risk-Neutral Probability Measures} $\Q$, so the fair-price for $X$ at time $t=0$ is constant between different \textit{Risk-Neutral Probability Measures}. Further, all trading strategies with the same value at time $t=1$ have the same value at time $t=0$ (and we have a formula for this value).\proved
  \end{proof}

\subsubsection{Complete Markets}

  \begin{definition}{Complete \& Incomplete Markets}
    A model of a market is said to be \textit{Complete} if each \textit{Contingent Claim} $X$ there exists a \textit{Trading Strategy} $H$ which generates $X$.
    \par Otherwise, the model is said to be \underline{in}\textit{complete}.
  \end{definition}

  \begin{remark}{Checking if a Market is Complete}
    We can check whether the model of a market is \textit{Complete} by defining the following matrix $A$, and if $A$ spans the same space as \textit{Contigent Claims}\footnote{This is done by determining whether $\text{rank}(A)=\text{dim}(X)$.} then the market \underline{is} \textit{Complete}.
    \[ A=\begin{pmatrix}
        B_1(\omega_1)&S_1(1)(\omega_1)&\dots&S_N(1)(\omega_1)\\
        B_1(\omega_2)&S_1(1)(\omega_2)&\dots&S_N(1)(\omega_2)\\
        \vdots&\vdots&\ddots&\vdots\\
        B_1(\omega_K)&S_1(1)(\omega_K)&\dots&S_N(1)(\omega_K)
    \end{pmatrix} \]
  \end{remark}

  \begin{theorem}{Complete Markets and Risk-Neutral Probability Measure}\label{the_complete_markets_and_risk_neutral_probability_measure}
    Consider a model with \underline{no} \textit{Arbitrage Opportunities}, then
    \begin{quote}
      The model is \textit{Complete} \underline{iff} $\exists$ a \underline{unique} \textit{Risk-Neutral Probability Measure} $\Q$.
    \end{quote}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_complete_markets_and_risk_neutral_probability_measure}}}
    \everymath={\displaystyle}
    Consider a \textit{Single-Period Model} with \underline{no} \textit{Arbitrage Opportunities} and let $\mathbb{M}$ denote the set of all \textit{Risk-Neutral Probability Measures} for this model.
    \par Since there are \underline{no} arbitrage opportunities then $\mathbb{M}\neq\emptyset$.
    \par As this theorem is ``iff'' I shall prove it in both directions separately
    \begin{itemize}
      \item[$\Longrightarrow$] Assume, for the sake of contraction, that the model \underline{is} \textit{Complete} but $\mathbb{M}=\{\Q,\hat\Q\}$  (ie contains two distinct elements).
      \par Then $\exists\ \omega_k\in\Omega$ st $\Q(\omega_k)\neq\hat\Q(\omega_k)$. Consider the following \textit{Contingent Claim} $X$
      \[\begin{array}{rcl}
      X(\omega)&=&\begin{cases} B_1(\omega)&\text{if }\omega=\omega_k\\0&\text{otherwise}\end{cases}\\
      &=&B_1\indexed\{\omega=\omega_k\}
      \end{array}\]
      Then
      \[\begin{array}{rcl}
        \expect_\Q[V_0]=\expect_\Q[X/B_1]&=&\expect_\Q[\indexed\{\omega=\omega_k\}]\\
        &=&\Q(\{\omega_k\}))\\
        &\neq&\Q(\{\omega_k\})\text{ by def. }X\\
        &=&\expect_{\hat\Q}[\indexed\{\omega=\omega_k\}]\\
        &=&\expect_{\hat\Q}[X/B_1]=\expect_{\hat\Q}[V_0]\\
        \implies\ \expect_\Q[V_0]&\neq&\expect_{\hat\Q}[V_0]
      \end{array}\]
      This contradicts \texttt{Proof \ref{sec_discrete_time_models}.\ref{prf_risk_neutral_valuation_principle}}  when we showed that if $X$ is attainable then $\expect_\Q[V_0]$ is the same for all $\Q\in\mathbb{M}$.
      \par Thus, if the model is \textit{Complete} then it has a unique \textit{Risk-Neutral Probability Measure}.
      \item[$\Longleftarrow$] Assume, for the sake of contradiction, that the model has a unique \textit{Risk-Neutral Probability Measure} $\hat\Q$ but there exists a \textit{Contingent Claim} $X$ which is \underline{not} \textit{Attainable}.
      \par Then, there does not exist a trading strategy $H$ which solves $AH=X$.
      \par By the \textit{Separating Hyperplane Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_separating_hyperplane_theorem}}) it follows that
      \[ \exists\ \pi\in\reals^K\text{ st }\pi^TA=0\footnotemark\text{ and }\pi^TX>0 \]
      \footnotetext{ie $\pi$ is orthogonal to $A$.}
      Let $\lambda>0$ be small enough that
      \[ \Q(\{\omega_j\}):=\hat\Q(\{\omega_j\})+\lambda\pi_j\cdot B_1(\omega_j)>0\quad\forall\ j\in[1,K] \]
      As $A$ is defined st all the terms in its first column are $B_1$ and $\pi^TA=0$, the $\Q$ defined above is a probability measure.
      \par Moreover, for any \textit{Discounted Price Process} $s^*=(S_1^*,\dots,S_N^*)$ and any $n\in[1,N]$ we have
      \[\begin{array}{rcl}
        \expect_\Q[S_n^*(1)]&=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\Q(\{\omega_j\})\\
        &=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\left(\hat\Q(\{\omega_j\})+\lambda\pi_jB_1(\omega_j)\right)\\
        &=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\hat\Q(\{\omega_j\})+\underbrace{\lambda\sum_{j=1}^K\pi_jS_n(1)(\omega_j)}_{=0}\\
        &=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\hat\Q(\{\omega_j\})\\
        &=&\sum_{j=1}^KS_n^*(1)(\omega_j)\hat\Q(\{\omega_j\})\\
        &=&\expect_{\hat\Q}[S_n^*(1)]\\
        &=&S_n^*[0]\footnotemark
      \end{array}\]
      \footnotetext{As $\hat\Q$ is a \textit{Risk-Neutral Probability Measure}.}
      This shows that $\Q$ is a \textit{Risk-Neutral Probability Measure} and so $\Q\in\mathbb{M}$, a contradiction to the uniqueness of $\hat\Q$.
      \par If there is a unique \textit{Risk-Neutral Probability Measure} for a model, then all \textit{Contingent Claims} are attainable under the model.
    \end{itemize}
    This has proved the theorem in both directions.\proved
  \end{proof}

\subsection{Multi-Period Model}

  \begin{definition}{Multi-Period Model}
    The \textit{Single-Period Model} is a model for a financial market where actions can only occur on multiple dates. This provides a more realistic model than the \textit{Single-Period Mdeol}. It has the following components
    \begin{itemize}
      \item \textit{Initial Date} $t=0$.
      \item \textit{Terminal Date} $t=T\in\nats$.
      \item Trading can occur at any times $t\in\{0,1,\dots,T\}$
      \item A finite \textit{Sample Space} $\Omega=\{\omega_1,\dots,\omega_K\}$ with $K<\infty$. Each event $\omega_1,\dots,\omega_K$ corresponds to a state of the world.
      \item A \textit{Probability Space} $\prob$ on $\Omega$ with $\prob(\omega)>0\ \forall\ \omega\in\Omega$.
    \end{itemize}
  \end{definition}

  \begin{remark}{Processes}
    When studying \textit{Multi-Period Models} we use many of the same processes as are used to study \textit{Single-Period Model}, but with their definitions extended to allow for more time periods. Namely
    \begin{itemize}
      \item Bank Account Process (\texttt{Definition \ref{sec_financial_terminology}.\ref{def_bank_account_process}}).
      \item Price-Process (\texttt{Definition \ref{sec_discrete_time_models}.\ref{def_price_process}}) \& Discounted Price-Process (\texttt{Definition \ref{sec_discrete_time_models}.\ref{def_discounted_price_process}}).
      \item Value-Process (\texttt{Definition \ref{sec_discrete_time_models}.\ref{def_value_process}}) \& Discounted Value-Process (\texttt{Definition \ref{sec_discrete_time_models}.\ref{def_discounted_value_process}}).
      \item Gains-Process (\texttt{Definition \ref{sec_discrete_time_models}.\ref{def_gains_process}}) \& Discounted Gains-Process (\texttt{Definition \ref{sec_discrete_time_models}.\ref{def_discounted_gains_process}}).
    \end{itemize}
  \end{remark}

\section{Continuous-Time}\label{sec_continuous_time_models}

\reference

\subsection{Notation}

\subsection{Definitions}

\end{document}
