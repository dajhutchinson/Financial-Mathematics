\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage{amsmath,amsfonts,fancyhdr,bbm,graphicx,tikz}
\usetikzlibrary{automata,positioning}
\graphicspath{ {img/} }
\usepackage[section,nohyphen]{DomH}
\headertitle{Financial Mathematics - Reviewed Notes}

\begin{document}

\title{Financial Mathematics - Reviewed Notes}
\author{Dom Hutchinson}
\date{\today}
\maketitle

\tableofcontents\newpage

\section{General}\label{sec_general}

  \begin{definition}{Modelling}
    TODO
  \end{definition}

  \begin{definition}{Risk-Free}
    An activity is said to be ``\textit{Risk-Free}'' if the potential profits \& losses are completely known.\footnote{It does not refer to whether there no chance of making a loss.}
  \end{definition}

\section{Probability}\label{sec_probability}

\subsection{General Probability}

  \begin{definition}{Sample Space $\Omega$}
    The \textit{Sample Space} $\Omega$ is the set consisting of all elementary outcomes from a (series of) event(s).
  \end{definition}

  \begin{definition}{Random Variable $X$}
    A \textit{Random Variable} $X$ is a function from the \textit{Sample Space} $\Omega$ to the real numbers $\reals$.
    \[ X:\Omega\to\reals \]
  \end{definition}

\subsection{Stochastic Processes}

  \begin{definition}{Stochastic Process}
    A \textit{Stochastic Process} $S$ is a real-valued function $S(t)(\omega)$
    \[ S:[0,T]\times\Omega\to\reals \]
  \end{definition}

  \begin{proposition}{Fixing components of a Stochastic Process}
    Let a \textit{Stochastic Process} $S:[0,T]\times\Omega\to\reals$ and consider fixing different variables
    \begin{itemize}
      \item If we fix $t\in[0,T]$ then $S(t)(\cdot):\Omega\to\reals$\footnote{The event $\omega$ is the only variable} is a \textit{Random Variable}.
      \item If we fix $\omega\in\Omega$ then $S(\cdot)(\omega):[0,T]\to\reals$\footnote{The time-point $t$ is the only variable} is called a \textit{Sample Path}.
    \end{itemize}
  \end{proposition}

  \begin{definition}{Predictable Stochastic Process}
    A \textit{Stochastic Process} $\{X_t\}_t$ is ``\textit{predictable}'' if, for each $t$, $X_t$ is $\mathcal{F}_{t-1}$-\textit{Measurable} wrt some filtration $\{\mathcal{F}_t\}_t$/
  \end{definition}

  \begin{definition}{Simple Stochastic Process}\label{def_simple_stochastic_process}
    A \textit{Stochastic Process} $\{X_t\}_{t\in[0,T]}$ is ``\textit{simple}'' if there exists
    \begin{itemize}
      \item A partition $\{t_0,t_1,\dots,t_n\}$ with $0=t_0<t_1<\dots<t_n=T$. %Partition?
      \item a set of random variables $\{\xi_k\}_{k\in[0,n]}$ which are $\mathcal{F}_{t_k}$-\textit{Measurable} and have finite expected values\footnote{$\expect\left[|\xi_k|\right]<\infty$}.
    \end{itemize}
    such that $X_t(\omega)$ can be written as the stepped-function (\ref{eqn_simple_stochastic_process}).
    \begin{equation}\label{eqn_simple_stochastic_process}
      X_t(\omega)=\xi_0(\omega)\indexed\{t=0\}+\sum_{i=0}^{n-1}\xi_i(\omega)\indexed\{t\in[t_i,t_{i+1}]\}
    \end{equation}
  \end{definition}

  \begin{definition}{Adapted Stochastic Process}
    Let $S:[0,T]\times\Omega\to\reals$ be a \textit{Stochastic Process} and $\{\mathcal{F}_t\}_{t\in[0,T]}$ be a \textit{Filtration}.
    \par $S$ is \textit{Adapted} to \textit{Filtration} $\{\mathcal{F}_t\}_{t\in[0,T]}$ if the \textit{Random Variable} $S(t)$ is \textit{Measurable} wrt $\sigma$-algebra $\mathcal{F}_t$, for all $t\in[0,T]$.\footnote{It is often easier to define a stochastic process first and then find a filtration for it (e.g. the \textit{Natural Filtration}).}
  \end{definition}

  \begin{definition}{Natural Filtration}
    Let $S:[0,T]\times\Omega\to\reals$ be a \textit{Stochastic Process}.
    \par We generate the \textit{Natural Filtration} $\{\mathcal{F}_t\}_{t\in[0,T]}$ for $S$ by doing the following for each $t=0,1,\dots,T$
    \begin{enumerate}
      \item Define $\mathcal{P}_t$ to be a partition of the \textit{Sample Space} $\Omega$ st $S(t)(\cdot)$ takes the same value for each element in each subset of $\mathcal{P}_t$.
      \[ \mathcal{P}_t:=\big\{A_1,\dots,A_m:S(t)(a)=S(t)(a')\ \forall\ a,a'\in A\big\}\text{ and }A_1,\dots,A_m\text{ form a partition.} \]
      \item Define $\mathcal{F}_t$ to be the \textit{$\sigma$-Algebra} generated by\footnote{See \texttt{Proposition \ref{sec_probability}.\ref{prop_generate_sigma_algebras}}.} partition $\mathcal{P}_t$.
    \end{enumerate}
  \end{definition}

  \begin{definition}{Bernoulli Process}
    A stochastic process $\{X_t\}_{t\in\nats}$ is a \textit{Bernoulli Process}, with parameter $p$, if $X_1,X_2,\dots$ are independent RVS taking only values $\{0,1\}$ and with $\prob(X_t=1)=p\ \forall\ t$.
  \end{definition}

  \begin{definition}{Random Walk Process}
    A stochastic process $\{N_t\}_{t\in\nats}$ is a \textit{Random Walk Process} when $N_t:=X_1+\dots+X_t$ for some \textit{Bernoulli Process} $\{X_t\}_{t\in\nats}$.
  \end{definition}

  \begin{theorem}{Binomial Distribution and Standard Normal}\label{the_binomial_distribution_and_standard_normal}
    Let $Y_n\sim\text{Binomial}(n,\pi_n)$. Then
    \[ \tilde{Y}_n:=\frac{Y_n-n\pi_n}{\sqrt{n\pi_n(1-\pi_n)}} \]
    converges in distribution to the standard normal distribution as $n\to\infty$.
  \end{theorem}

\subsection{Information Structures}

  \begin{definition}{Partition $\mathcal{P}$}
    Let $\mathcal{P}:=\{A_1,\dots,A_N\}$ be a set (of sets) and $\Omega$ be a \textit{Sample Space}.
    \par $\mathcal{P}$ is a \textit{Partition} of $\Omega$ if it has the following properties
    \begin{enumerate}
      \item All elements in $\mathcal{P}$ are mutually disjoint
      \[ A_i\cap A_j=\emptyset\ \forall\ A_i,A_j\in\mathcal{P} \]
      \item The union of the elements form the \textit{Sample Space} $\Omega$.
      \[ \bigcup_{i=1}^NA_i=\Omega \]
    \end{enumerate}
  \end{definition}

  \begin{remark}{Flow of Information}
    At time $t=0$ every state $\omega\in\Omega$ is a possible outcome at time $t=T$. And, at time $t=T$ we know for certain which outcome has occurred.
    \par At each time in-between $t\in(0,T)$ our information about the world increases\footnote{or, at least, does not decrease.} meaning the set of possible outcomes at time $t=T$ may decrease. Let $A_t$ denote the possible set of outcomes given we are at time $t$, then
    \[\begin{array}{rcl}
      A_0&=&\Omega\\
      A_T&=&\{\omega\}\\
      A_0&\supseteq&A_1\supseteq\dots\supseteq A_T
    \end{array}\]
    Flipping a coin 3 times is a motivating example. Before we start flipping ($t=0$) it is possible that we will flip three tails, but if the first flip ($t=1$) is heads then this is no longer possible.
  \end{remark}

  \begin{definition}{Information Sequence $\{\mathcal{P}_0,\dots,\mathcal{P}_T\}$}
    An \textit{Information Sequence} is a sequence of \textit{Partitions} $\{\mathcal{P}_0,\dots,\mathcal{P}_T\}$ of the \textit{Sample Space} $\Omega$, which fulfil the following criteria
    \begin{enumerate}
      \item $\mathcal{P}_0=\big\{\Omega\big\}$.
      \item For $t\in[1,T)$ each $A\in\mathcal{P}_t$ is equal to the union of a subset of elements in $\mathcal{P}_{t+1}$.
      \item $\mathcal{P}_T=\big\{\{\omega_1\},\dots,\{\omega_N\}\big\}$.
    \end{enumerate}
    \textit{Information Sequences} show the set of possible events, at each time point $t$, which could still occur.\footnote{An \textit{Information Sequence} is a sequence of \textit{$\sigma$-Algebras}.}
  \end{definition}

  \begin{remark}{Visualising Information Structures}
    TODO
  \end{remark}

  \begin{definition}{$\sigma$-Algebra $\mathcal{F}$}
    A \textit{$\sigma$-Algebra} $\mathcal{F}$ is a set of subsets of the \textit{Sample Space} $\Omega$ which satisfy the following conditions
    \begin{enumerate}
      \item $\Omega\in\mathcal{F}$.
      \item $\forall\ A\in\mathcal{F},\ A^c\in\mathcal{F}$.
      \item $\forall\ A,B\in\mathcal{F},\ (A\cup B)\in\mathcal{F}$.
    \end{enumerate}
  \end{definition}

  \begin{definition}{Filtration $\{\mathcal{F}_0,\dots,\mathcal{F}_T\}$}
    A \textit{Filtration} is a sequence of \textit{$\sigma$-Algebras} $\{\mathcal{F}_t:t=0,1,\dots,T\}$ where
    \begin{enumerate}
      \item $\mathcal{F}_0=\{\emptyset,\Omega\}$.
      \item $\forall\ n<T,\ \mathcal{F}_n\subset\mathcal{F}_{n+1}$ (Meaning each subset of $\mathcal{F}_n$ must be an element of $\mathcal{F}_{n+1}$).
      \item $\mathcal{F}_T=2^\Omega$.\footnote{The set of all subsets of the sample space $\Omega$.}
    \end{enumerate}
    Each \textit{$\sigma$-Algebra} $\mathcal{F}_t$ represents all the information generated up to time-point $t$ by the random stock processes\footnote{So we know how the stock has developed up to time $t$.}.
  \end{definition}

  \begin{definition}{Measurable Function}
    Consider a random variable $X:\Omega\to\reals$ and a \textit{$\sigma$-Algebra} $\mathcal{F}$.
    \par $X$ is \textit{Measurable} wrt $\mathcal{F}$ if
    \[ \forall\ x\in\reals, X^{-1}(x)\subset\mathcal{F}\text{ where }X^{-1}(x):=\{\omega\in\Omega:X(\omega)=x\} \]
    This can be interpreted to mean that, if we known which set of $\mathcal{F}$ $\omega$ is in, then we know the values of $X(\omega)$.
  \end{definition}

  \begin{proposition}{Measurability and Filtrations}
    Consider a \textit{Filtration} $\{\mathcal{F}_1,\dots,\mathcal{F}_T\}$ and a random variable $X:\Omega\to\reals$.
    \par If $X$ is \textit{Measurable} wrt $\mathcal{F}_t$ then it is \textit{Measurable} wrt $\mathcal{F}_{t+1}$ since $\mathcal{F}_t\subseteq\mathcal{F}_{t+1}$.
  \end{proposition}

  \begin{proposition}{How to generate $\sigma$-Algebras}\label{prop_generate_sigma_algebras}
    Let $\mathcal{P}$ be a \textit{Partition} of the \textit{Sample Space} $\Omega$.
    \par We can generate a \textit{$\sigma$-Algebra} $\mathcal{F}$ from $\mathcal{P}$ be defining $\mathcal{F}$ to be the set of all possible unions from elements in $\mathcal{P}$ \underline{as well as} the compliments of all these unions.
  \end{proposition}

\subsection{Conditional Expectation}

  \begin{definition}{Conditional Expectation $\expect[\cdot|\cdot]$}
    \everymath={\displaystyle}
    Let $\Omega$ be a finite sample space, $X$ be a discrete random variable and $A\subseteq\Omega$.
    \par The \textit{Conditional Expectation} of $X$ given $A$ has occurred is defined as
    \[ \expect[X|A]=\sum_xx\prob(X=x|A) \]
  \end{definition}

  \begin{remark}{Alternative Definitions of Conditional Expectation}
    \everymath={\displaystyle}
    Here are two restatements of the definition of \textit{Conditional Expectation}, both are consequences of \textit{Bayes Rule}.
    \[\begin{array}{rcl}
      \expect[X|A]&=&\sum_x\frac{\prob(X=x,A)}{\prob(A)}\\
      \expect[X|A]&=&\sum_{\omega\in A}X(\omega)\frac{\prob(\omega)}{\prob(A)}
    \end{array}\]
  \end{remark}

  \begin{definition}{Conditional Expectation \textbackslash{w} $\sigma$-Algebra $\expect[\cdot|\mathcal{F}]$}
    Let $\mathcal{F}$ be a \textit{$\sigma$-algebra}, $\mathcal{P}$ be the corresponding \textit{Partition} of the sample space $\Omega$ and $X$ be a discrete random variable.
    \par The \textit{Conditional Expectation} of $X$ given $\mathcal{F}$ is defined as
    \[ \expect[X|\mathcal{F}]:=\sum_{A\in\mathcal{P}}\expect[X|A]\indexed\{A\}\footnotemark \]
    \footnote{This is not really a summation as there is only \underline{one} event $A$ st $\indexed\{A\}=1$.}
    \underline{Note} - This is a random variable as its value depends on which random event $A$ occurs. Moreover, it is \textit{Measurable} wrt $\mathcal{F}$ and for a given $A\in\mathcal{P}$
    \[ \forall\ \omega\in A,\ \expect[X|\mathcal{F}](\omega)=\expect[X|A]\footnotemark \]
    \footnotetext{This is intuitive from the definition of $\expect[\cdot|\mathcal{F}]$.}
  \end{definition}

  \begin{theorem}{Tower Law}\label{the_tower_law}
    Let $X$ be a discrete random variable and $\mathcal{F}_1,\mathcal{F}_2$ be \textit{$\sigma$-Algebras} with $\mathcal{F}_1\subset\mathcal{F}_2$.
    \par The \textit{Tower Law} states that
    \[ \expect\big[\expect[X|\mathcal{F}]\big]=\expect[X] \]
    The \textit{Generalised Tower Law} states that
    \[ \expect\big[\expect[X|\mathcal{F}_2]\big|\mathcal{F}_1\big] = \expect[X|\mathcal{F}_1] = \expect\big[\expect[X|\mathcal{F}_1]\big|\mathcal{F}_2\big] \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_tower_law}} - Tower Law}
    \everymath={\displaystyle}
    Let $X$ be a discrete random variable, $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $\mathcal{P}$ be the partition of the sample space $\Omega$ associated with $\mathcal{F}$.
    \[\begin{array}{rcl}
      \expect\big[\expect[X|\mathcal{F}]\big]&=&\expect\left[\sum_{A\in\mathcal{P}}\expect[X|A]\indexed\{A\}\right]\text{ by def.}\\
      &=&\sum_{A\in\mathcal{P}}\expect\big[\expect[X|A]\indexed\{A\}\big]\text{ by linearity of expectation}\\
      &=&\sum_{A\in\mathcal{P}}\expect[X|A]\expect[\indexed\{A\}]\\
      &=&\sum_{A\in\mathcal{P}}\prob(A)\cdot\left(\sum_{\omega\in A}\frac{X(\omega)\prob(\omega)}{\prob(A)}\right)\text{ by alt def.}\\
      &=&\sum_{A\in\mathcal{P}}\sum_{\omega\in A}X(\omega)\prob(\omega)\text{ as }\sum \prob(A)=1\\
      &=&\expect[X]\text{ by def.}
    \end{array}\]\proved
  \end{proof}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_tower_law}} - Generalised Tower Law}
    \everymath={\displaystyle}
    Let $X$ be a discrete random variable, $\mathcal{F}_1,\mathcal{F}_2$ be \textit{$\sigma$-Algebras} with $\mathcal{F}_1\subset\mathcal{F}_2$ and $\mathcal{P}_1,\mathcal{P}_2$ be the partitions associated to $\mathcal{F}_1,\mathcal{F}_2$.
    \[\begin{array}{rcl}
      \expect\big[\expect[X|\mathcal{F}_2]\big|\mathcal{F}_1\big]&=&\expect\left[\sum_{B\in\mathcal{P}_2}\expect[X|B]\indexed\{B\}\bigg|\mathcal{F}_1\right]\\
      &=&\sum_{B\in\mathcal{P}_2}\expect[X|B]\expect[\indexed\{B\}|\mathcal{F}_1]\\
      &=&\sum_{B\in\mathcal{P_2}}\expect[X|B]\left(\sum_{A\in\mathcal{P}_1}\expect[\indexed\{B\}|A]\indexed\{A\}\right)\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2}}\expect[X|B]\expect[\indexed\{B\}|A]\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2}}\expect[X|B]\cdot\frac{\prob(A\cap B)}{\prob(A)}\cdot\indexed\{A\}
    \end{array}\]
    Since $\mathcal{P}_2$ is more refined than $\mathcal{P}_1$, either $B\subset A$ or $B\cap A=\emptyset$. Thus
    \[\begin{array}{rcl}
      \expect\big[\expect[X|\mathcal{F}_2]\big|\mathcal{F}_1\big]
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2},B\subset A}\expect[X|B]\cdot\frac{\prob(B)}{\prob(A)}\cdot\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{B\in\mathcal{P_2},B\subset A}\left(\sum_{\omega\in B}X(\omega)\frac{\prob(\omega)}{\prob(B)}\right)\cdot\frac{\prob(B)}{\prob(A)}\cdot\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\sum_{\omega\in B}X(\omega)\frac{\prob(\omega)}{\prob(A)}\cdot\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}_1}\expect[X|A]\indexed\{A\}\\
      &=&\expect[X|\mathcal{F}_1]
    \end{array}\]
    \proved
  \end{proof}

  \begin{theorem}{Conditional Expectation \& Measurable Random Variables}\label{the_cond_exp_and_measurable}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $X,Y$ be discrete random variables with $X$ being \textit{Measurable} wrt $\mathcal{F}$.
    \par Then
    \[\begin{array}{rcl}
      \expect[X|\mathcal{F}]&=&X\\
      \expect[XY|\mathcal{F}]&=&X\expect[Y|\mathcal{F}]
    \end{array}\]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}}}\label{proof_cond_exp_and_measurable}
    \everymath={\displaystyle}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra}, $\mathcal{P}$ be the partition associated with $\mathcal{F}$ and $X,Y$ be discrete random variables with $Y$ being \textit{Measurable} wrt $\mathcal{F}$.
    \par Since $Y$ is \textit{Measurable} it is constant on sets of $\mathcal{P}$ we write $X$ as
    \[ Y=\sum_{A\in\mathcal{P}}Y_A\indexed\{A\}\text{ with }Y_A\in\reals \]
    Thus
    \[\begin{array}{rcl}
      \expect[XY|\mathcal{F}]&=&\sum_{A\in\mathcal{P}}\expect[XY|A]\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}}\expect[XY_A|A]\indexed\{A\}\\
      &=&\sum_{A\in\mathcal{P}}Y_A\expect[X|A]\indexed\{A\}\text{ as }Y_A\text{ is a scalar}\\
      &=&\sum_{A\in\mathcal{P}}Y\expect[X|A]\indexed\{A\}\footnotemark\\
      &=&Y\sum_{A\in\mathcal{P}}\expect[X|A]\indexed\{A\}\\
      &=&Y\expect[X|\mathcal{F}]
    \end{array}\]
    \proved
    \footnotetext{As there is only one event $A$ where $\indexed\{A\}=1$.}
  \end{proof}

  \begin{theorem}{Conditional Expectation \& Independent Random Variables}\label{the_cond_exp_and_independent}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $X$ be a discrete random variable which is independent of $\mathcal{F}$.
    \par Then
    \[ \expect[X|\mathcal{F}]=\expect[X] \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_independent}}}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} and $X$ be a discrete random variable which is independent of $\mathcal{F}$.
    \[\begin{array}{rcl}
      \expect[X|A]&=&\sum_x\prob(X=x|A)\\
      &=&\sum_x\prob(X=x)\text{ by independence}\\
      &=&\expect[X]
    \end{array}\]
    \proved
  \end{proof}

  \begin{theorem}{General Conditional Expectation}\label{the_general_conditional_expectation}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} of a general sample space\footnote{i.e. Not necessarily finite} $\Omega$ and $X$ be a discrete random variable.
    \par Then, the \textit{Conditional Expectation} $\expect[X|\mathcal{F}]$ is a \underline{unique} random variable with the following properties
    \begin{enumerate}
      \item $\expect[X|\mathcal{F}]$ is \textit{Measurable} wrt $\mathcal{F}$.
      \item $\forall\ A\in\mathcal{F},\ \expect\big[\expect[X|\mathcal{F}]\indexed\{A\}\big]=\expect[X\indexed\{A\}]$
    \end{enumerate}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_general_conditional_expectation}}}
    \everymath={\displaystyle}
    Let $\mathcal{F}$ be a \textit{$\sigma$-Algebra} of a general sample space $\Omega$, $\mathcal{P}$ be the partition associated with $\mathcal{F}$ and $X$ be a discrete random variable.
    \begin{enumerate}
      \item
      Let $Y$ be a random variable which is \textit{Measurable} wrt $\mathcal{F}$ and satisfies
      \[ \expect[Y\indexed\{A\}]=\expect[X\indexed\{A\}]\ \forall\ A\in\mathcal{F} \]
      Consider the expression $\expect[X\indexed\{A\}]$
      \[\begin{array}{rcl}
        \expect[X\indexed\{A\}]&=&\sum_{\omega\in A}X(\omega)\prob(\omega)\\
        &=&\frac{\prob(A)}{\prob(A)}\sum_{\omega\in A}X(\omega)\prob(\omega)\\
        &=&\prob(A)\sum_{\omega\in A}\frac{X(\omega)\prob(\omega)}{\prob(A)}\\
        &=&\prob(A)\expect[X|A]
      \end{array}\]
      Now, Note that $Y=\sum_{A\in\mathcal{P}}Y_A\indexed\{A\}$ (As in \texttt{Proof \ref{sec_probability}.\ref{proof_cond_exp_and_measurable}}).
      \par It follows that
      \[ \forall\ A\in\mathcal{P},\ \expect[Y\indexed\{A\}]=Y_A\expect[\indexed\{A\}]=Y_A\prob(A) \]
      We now have that
      \[\begin{array}{rrcl}
        &\expect[X\indexed\{A\}]&=&\expect[Y\indexed\{A\}]\text{ by def. }Y\\
        \implies&\prob(A)\expect[X|A]&=&Y_A\prob(A)\\
        \implies&Y_A&=&\expect[X|A]\ \forall\ A\in\mathcal{P}\\
        \implies&Y&=&\expect[X|\mathcal{F}]
      \end{array}\]
      As we defined $Y$ to be \textit{Measurable} wrt $\mathcal{F}$, this means $\expect[X|\mathcal{F}]$ is \textit{Measurable} wrt $\mathcal{F}$.

      \item \par For any event $A\in\mathcal{F}$, the indicator function $\indexed\{A\}$ is \textit{$\mathcal{F}$-Measurable}.
      \par Thus, $\expect[X\indexed\{A\}|\mathcal{F}]=\indexed\{A\}\cdot\expect[X|\mathcal{F}]$ by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}}.
      \par Hence, by the Tower Law (\texttt{Theorem \ref{sec_probability}.\ref{the_tower_law}}).
      \[ \expect\big[\expect[X|\mathcal{F}]\cdot\indexed\{A\}\big]=\expect\big[\expect[X\indexed\{A\}|\mathcal{F}]\big]=\expect[X\indexed\{A\}] \]
    \end{enumerate}
    \proved
  \end{proof}

\subsection{Random Walks}

  \begin{remark}{Random Walks}
    Random walks are a class of discrete-time stochastic processes.
  \end{remark}

  \begin{definition}{Random Walk}
    Let $Y_0,Y_1,\dots$ be IID random variables with finite variance $\sigma^2$ and finite mean $\mu$.
    \par A \textit{Random Walk} is the sequence $\{X_t\}_{t\geq0}$ where $X_t:=\sum_{i=1}^tY_i$.
  \end{definition}

  \begin{definition}{Simple Random Walk}
    Let $\{X_t\}_{t\geq0}$ be a \textit{Random Walk} with $X_t:=\sum_{i=1}^tY_i$ where $Y_0,Y_1,\dots$ are IID RVs.
    \par We say that $\{X_t\}_{t\geq0}$ is a \textit{Simple Random Walk} if
    \[ Y_t\in\{-1,1\}\quad\prob(Y_t=1)=p\quad\prob(Y_t=-1)=1-p \]
    A \textit{Simple Random Walk} can be thought of as a process where you only ever step forward or step backwards, with fixed probabilities.
  \end{definition}

  \begin{theorem}{Distribution of a Simple Random Walk}\label{the_distribution_of_simple_random_walk}
    Let $\{X_t\}_{t\geq0}$ be a \textit{Simple Random Walk}. Then
    \[ \prob(X_t=x)={t \choose {\frac{t+x}2}}p^{(t+x)/2}(1-p)^{(t-x)/2}\quad\ \forall\ t\geq0,\ x\in\{-t,-t+2,\dots,t\} \]
    Note that the set of possible $x$ values steps by 2.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_distribution_of_simple_random_walk}}}
    Note that $x=\frac12(2x+t-t)=(+1)\cdot\frac12(t+x)+(-1)\cdot\frac12(t-x)$.
    \par For $X_t=x$ we require exact $\frac12(t+x)$ of $Y_1,\dots,Y_t$ to take value 1, and then the remaining $\frac12(t-x)$ will take value -1. There are ${t\choose{\frac{t+x}2}}$ different ways this can occur.
    \par Note that each $Y_i$ takes its value independently and takes value 1 with probability $p$ and -1 with probability $1-p$. Thus
    \[ \prob(X_t=x)={t \choose {\frac{t+x}2}}p^{(t+x)/2}(1-p)^{(t-x)/2}\quad\ \forall\ t\geq0,\ x\in\{-t,-t+2,\dots,t\} \]
  \end{proof}

\subsection{Martingales}

  \begin{definition}{Discrete-Time Martingale $\{Z_t\}_{t\in\nats_0}$}
    % super-, sub- martingale
    Let $\{Z_t\}_{t\in[0,T]}$ be an \textit{Adapted Stochastic Process} on a \textit{Sample Space} $\Omega$ wrt a \textit{Filtration} $\{\mathcal{F}_t\}_{t\in[0,T]}$.
    \begin{itemize}
      \item $\{Z_t\}_{t\in[0,T]}$ is a \textit{Martingale} if
      \[ \forall\ t\geq1,\ \expect[Z_t|\mathcal{F}_{t-1}]=Z_{t-1} \]
      This can be interpreted to mean that, given all available information $\mathcal{F}_{t-1}$, our present state $Z_{t-1}$ is the best indicator of the future state $Z_t$.
      \item $\{Z_t\}_{t\in[0,T]}$ is a \underline{Super}\textit{-Martingale} if
      \[ \forall\ t\geq1,\ \expect[Z_t|\mathcal{F}_{t-1}]\leq Z_{t-1} \]
      This can be interpreted to mean that, given all available information $\mathcal{F}_{t-1}$, our present state $Z_{t-1}$ provides an upper-bound on the future state $Z_t$.
      \item $\{Z_t\}_{t\in[0,T]}$ is a \underline{Sub}\textit{-Martingale} if
      \[ \forall\ t\geq1,\ \expect[Z_t|\mathcal{F}_{t-1}]\geq Z_{t-1} \]
      This can be interpreted to mean that, given all available information $\mathcal{F}_{t-1}$, our present state $Z_{t-1}$ provides a lower-bound on the future state $Z_t$.
    \end{itemize}
  \end{definition}

  \begin{definition}{Continuous Time Martingale}
    Let $\{Z_t\}_{t\in\reals^{\geq0}}$ be an \textit{Adapted Stochastic Process} on a \textit{Sample Space} $\Omega$ wrt a \textit{Filtration} $\{\mathcal{F}_t\}_{t\in\reals^{\geq0}}$.
    \begin{itemize}
      \item $\{Z_t\}_{t\in\reals^{\geq0}}$ is a \textit{Martingale} if
      \[ \forall\ t\geq s\geq0,\ \expect\left[|X_t|\right]<\infty\text{ and }\expect\left[X_t|\mathcal{F}_s\right]=X_s \]
      \item $\{Z_t\}_{t\in\reals^{\geq0}}$ is a \underline{Super}-\textit{Martingale} if
      \[ \forall\ t\geq s\geq0,\ \expect\left[|X_t|\right]<\infty\text{ and }\expect\left[X_t|\mathcal{F}_s\right]\leq X_s \]
      \item $\{Z_t\}_{t\in\reals^{\geq0}}$ is a \underline{Sub}-\textit{Martingale} if
      \[ \forall\ t\geq s\geq0,\ \expect\left[|X_t|\right]<\infty\text{ and }\expect\left[X_t|\mathcal{F}_s\right]\geq X_s \]
    \end{itemize}
  \end{definition}

  \begin{proposition}{Notable Martingales}\label{prop_notable_martingales}
    Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$ and let $\mathcal{F}_t$ be the \textit{$\sigma$-Algebra} generated by $X_t$. Then
    \begin{enumerate}
      \item If $p=1/2$ $\{X_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \item If $p\leq1/2$ $\{X_t\}_{t\in\nats_0}$ is a \textit{Super-Martingale}.
      \item If $p\geq1/2$ $\{X_t\}_{t\in\nats_0}$ is a \textit{Sub-Martingale}.
      \item If $p=1/2$ then $\{Z_t\}_{t\in\nats_0}$ where $Z_t:=(X_t^2-t)$ is a \textit{Martingale}.
      \item If $p\neq1/2$ then $\{L_t\}_{t\in\nats_0}$ where $L_0:=1,L_t:=\left(\frac{1-p}p\right)^{X_t}$ is a \textit{Martingale} \textit{Martingale}.
      \item If $p\neq1/2$ then $\{M_t\}_{t\in\nats_0}$ where $M_t:=\big(X_t-t(2p-1)\big)$ is a \textit{Martingale}. \textit{Martingale}.
    \end{enumerate}
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} i)-iii)}
    Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$ and let $\mathcal{F}_t$ be the \textit{$\sigma$-Algebra} generated by $X_t$.
    \par Since $\{\mathcal{F}_t\}_{t\in\nats}$ is the \textit{Natural Filtration} of $\{X_t\}_{t\in\nats}$, then $\{X_t\}_{t\in\nats}$ is \textit{Measurable} wrt $\mathcal{F}_t$ and $Y_t$\footnote{The $t^{th}$ step of the random walk.} is independent of $\mathcal{F}_{t-1}$.
    \par Then
    \[\begin{array}{rcl}
      \expect[X_t|\mathcal{F}_{t-1}]&=&\expect[X_{t-1}+Y_t|\mathcal{F}_{t-1}]\text{ by def. }X_t\\
      &=&\expect[X_{t-1}|\mathcal{F}_{t-1}]+\expect[Y_t|\mathcal{F}_{t-1}]\text{ by linearity of exp.}\\
      &=&X_{t-1}+\expect[Y_t]\text{ by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_independent}}}
    \end{array}\]
    Thus
    \begin{itemize}
      \item If $p=1/2$ then $\expect[Y_t]=0\implies\expect[X_t|\mathcal{F}_{t-1}]=X_{t-1}$. This is the definition of a \textit{Martingale}.
      \item If $p\leq1/2$ then $\expect[Y_t]\leq0\implies\expect[X_t|\mathcal{F}_{t-1}]\leq X_{t-1}$. This is the definition of a \textit{Super-Martingale}.
      \item If $p\geq1/2$ then $\expect[Y_t]\geq0\implies\expect[X_t|\mathcal{F}_{t-1}]\geq X_{t-1}$. This is the definition of a \textit{Sub-Martingale}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} iv)}
    Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$ and let $\mathcal{F}_t$ be the \textit{$\sigma$-Algebra} generated by $X_t$.
    \par As the definition of a \textit{Martingale} depends on the conditional expectation of $Z_t$ given $\mathcal{F}_{t-1}$ we consider its value
    \[\begin{array}{rcl}
      \expect[Z_t|\mathcal{F}_{t-1}]&=&\expect[X_t^2-t|\mathcal{F}_{t-1}]\text{ by def. }Z_t\\
      &=&\expect[(X_{t-1}+Y_t)^2-t|\mathcal{F}_{t-1}]\text{ by def. }X_t\\
      &=&\expect[(X_{t-1}+Y_t)^2|\mathcal{F}_{t-1}]-t\\
      &=&\expect[X_{t-1}^2+2X_{t-1}Y_t+Y_t^2|\mathcal{F}_{t-1}]-t\\
      &=&\expect[X_{t-1}^2|\mathcal{F}_{t-1}]+2\expect[X_tY_t|\mathcal{F}_{t-1}]+\expect[Y_t^2|\mathcal{F}_{t-1}]-t\\
      &=&X_{t-1}^2+2X_{t-1}\expect[Y_t|\mathcal{F}_{t-1}]+\expect[Y_t^2]-t\\
    \end{array}\]
    Since $p=1/2\implies \expect[Y_t]=0,\expect[Y_t^2=1]$.
    \[\begin{array}{rcl}
      \expect[Z_t|\mathcal{F}_{t-1}]&=&X_{t-1}^2+2X_{t-1}\expect[Y_t|\mathcal{F}_{t-1}]+\expect[Y_t^2]-t\\
      &=&X_{t-1}^2+0+1-t\\
      &=&X_{t-1}^2-(t-1)\\
      &=&Z_{t-1}\\
      \implies\expect[Z_t|\mathcal{F}_{t-1}]&=&Z_{t-1}
    \end{array}\]
    This is the definition of a \textit{Martingale}.\proved
  \end{proof}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} v)}
    TODO (Homework)
  \end{proof}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} vi)}
    TODO (Homework)
  \end{proof}

  \begin{theorem}{Adapted Stochastic Processes as Martingales}\label{the_adapated_stochastic_processes_as_martingales}
    Let $\{Z_t\}_{t\in[0,T]}$ be an \textit{Adapted Stochastic Process}.
    \par $\{Z_t\}_{t\in[0,T]}$ is a \textit{Martingale} \underline{iff}
    \[ \forall\ t\geq s,\  \expect[Z_t|\mathcal{F}_s]=Z_s\footnotemark \]
    \footnotetext{Equivalent results can be made for \textit{Super-} and \textit{Sup-Martingales} by replacing $=$ with $\leq,\geq$ respectively.}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_adapated_stochastic_processes_as_martingales}}}
    Let $\{Z_t\}_{t\in[0,T]}$ be an \textit{Adapted Stochastic Process}.
    \par I prove this statement in both directions\footnote{The proofs for \textit{Super-} and \textit{Sup-Martingales} are very similar.}
    \begin{itemize}
      \item[$\Longrightarrow$] Suppose $\{Z_t\}_{t\in[0,T]}$ is a \textit{Martingale}.
      \par Using \texttt{Theorem \ref{sec_probability}.\ref{the_general_conditional_expectation}} we can deduce that
      \[\begin{array}{rcll}
        \expect[Z_t|\mathcal{F}_s]&=&\expect\big[\expect[Z_t|\mathcal{F}_{t-1}]\big|\mathcal{F}_s\big]&\text{by \texttt{Theorem \ref{sec_probability}.\ref{the_general_conditional_expectation}}}\\
        &=&\expect[Z_{t-1}|\mathcal{F}_s]&\text{as }Z\text{ is a Martingale}\\
        &=&\expect[Z_s|\mathcal{F}_s]&\text{by recursion}\\
        &=&\expect[Z_s]&\text{ by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}} }\\
        &=&Z_s
      \end{array}\]
      \item[$\Longleftarrow$] Suppose it holds that
      \[ \forall\ t\geq s,\  \expect[Z_t|\mathcal{F}_s]=Z_s \]
      Consider the case where $s=t-1$, it holds that
      \[ \expect[Z_t|\mathcal{F}_{t-1}]=Z_{t-1} \]
      This is the definition of a \textit{Martingale}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{definition}{Stopping Times $\tau$}
    Let $\{\mathcal{F}_t\}_{t\in\nats_0}$ be a \textit{Filtration} of \textit{Sample Space} $\Omega$ and $\tau$ be a random variable which takes values in $(\reals\geq0\cup\{\infty\})$\footnote{$\infty$ is used for impossible events.}.
    \par $\tau$ is a \textit{Stopping Time} if the event $\{\tau<t\}$ is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t$.
    \par \textit{Stopping Times} are used to determine whether an event has occurred, or not.\footnote{Examples of \textit{Stopping Times} are ``RBS shares hit £1''.}
  \end{definition}

  \begin{definition}{Bounded Stopping Time $\tau$}
    Let $\tau$ be a \textit{Stopping Time}.
    \par A $\tau$ is a \textit{Bounded Stopping Time} if
    \[ \exists\ t\in\reals^{\geq0},\ \prob(\tau<t)=1 \]
  \end{definition}

  \begin{theorem}{Stopping Times \& $\sigma$ Algebras}\label{the_stopping_times_and_sigma_algebras}
    Let $\tau$ be a random variable.
    \par $\tau$ is a \textit{Stopping Time} \underline{iff} $\forall\ t\in\nats_0$ the event $\{\tau=t\}$  is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_stopping_times_and_sigma_algebras}}}
    Let $\tau$ be a random variable.
    \par I prove this statement in both directions
    \begin{itemize}
      \item[$\Longrightarrow$] Suppose $\tau$ is a \textit{Stopping Time}.
      \par Then the event $\{\tau\leq t\}$ is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t\ \forall\ t\in\nats_0$.
      \par We can restate this event as
      \[ \{\tau\leq t\}=\bigcup_{k\leq t}\{\tau=k\} \]
      As $\{\tau\leq t\}\in\mathcal{F}_t$, then each of $\{\tau=k\}\in\mathcal{F}_t$ due to the definition of a \textit{$\sigma$-Algebra}.

      \item[$\Longleftarrow$] Suppose the event $\{\tau=t\}$  is an element of the \textit{$\sigma$-Algebra} $\mathcal{F}_t\ \forall\ t\in\nats_0$.
      \par We can restate this event as
      \[ \{\tau\leq t\}=\big(\{\tau\leq t\}\setminus\{\tau\leq t-1\}\big) \]
      Since $\{\tau\leq t\},\{\tau\leq t-1\}$ are elements of $\mathcal{F}_t$, then $\{\tau\leq t\}\in\mathcal{F}_t$ due to the definition of a \textit{$\sigma$-Algebra}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{theorem}{Stopping Time for an Adapted Stochastic Process}\label{the_stopping_time_adapted_stochastic_process}
    Let $\{X_t\}_{t\in\nats_0}$ be an \textit{Adapted Stochastic Process} and $c\in\reals$.
    \par The event $\tau_c:=\inf\{t\geq0:X_t\geq c\}$\footnote{The first time $X_t$ reaches value $c$.} is a \textit{Stopping Time}.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_stopping_time_adapted_stochastic_process}}}
    Let $\{X_t\}_{t\in\nats_0}$ be an \textit{Adapted Stochastic Process} and $c\in\reals$.
    \par Note that $\tau\leq t$ \underline{iff} $\exists\ k\leq t$ st $X_k\geq c$ due to the definition of $\tau_c$.
    \par Therefore
    \[ \{\tau_c\leq t\}=\bigcup_{k\leq t}\{X_k\geq c\} \]
    Since each $\{X_k\geq c\}\in\mathcal{F}_t$ then $\{\tau_c\leq t\}\in\mathcal{F}_t$ by the definition of \textit{$\sigma$-Fields}.
    \par Thus $\tau_c$ is a \textit{Stopping Time}.\proved
  \end{proof}

  \begin{theorem}{Optional Stopping Theorem\footnote{AKA \textit{Optional Sampling Theorem}} - Martingale}\label{the_optional_stopping_theorem_martingale}
    Let $\tau$ be a \textit{Bounded Stopping Time} and $\{X_t\}_{t\in\nats_0}$ be a \textit{Martingale}.
    \par Then
    \[ \expect[X_\tau]=\expect[X_0]=X_0 \]
  \end{theorem}

  \begin{theorem}{Optional Stopping Theorem - Super-Martingale}
    Let $\tau$ be a \textit{Bounded Stopping Time} and $\{X_t\}_{t\in\nats_0}$ be a \underline{Super}\textit{-Martingale}.
    \par Then
    \[ \expect[X_\tau]\leq\expect[X_0]=X_0 \]
  \end{theorem}

  \begin{remark}{Weaker Conditions for Optional Stopping Theorem}\label{rem_weaker_optional_stopping_theorem}
    The following are weaker conditions\footnote{Rather than $\tau$ being a bounded stopping time} that suffice for the \textit{Optional Stopping Theorem} to hold
    \begin{enumerate}
      \item $\prob(\tau<\infty)=1$ and $X_\tau$ is bounded.
      \item $\expect[\tau]<\infty$ and $(X_t-X_{t-1})$ is bounded.
    \end{enumerate}
  \end{remark}

  \begin{proof}{\texttt{Theorem \ref{sec_probability}.\ref{the_optional_stopping_theorem_martingale}}}
    \everymath={\displaystyle}
    Let $\tau$ be a \textit{Bounded Stopping Time} and $\{X_t\}_{t\in\nats_0}$ be a \textit{Martingale}.
    \par Assume that $\tau\leq K$ (This is reasonable since $\tau$ is bounded). We can write
    \[ X_{\tau(\omega)}{\omega}=\sum_{t=0}^KX_t(\omega)\indexed\{\tau(\omega)=t\} \]
    Note that this is not really a sum as there is only one event $\omega$ st $\indexed\{\tau(\omega)=t\}=1$, the rest equal 0.
    \par Then
    \[\begin{array}{rcl}
      \expect[X_\tau]&=&\expect\left[\sum_{t=0}^KX_t\indexed\{\tau=t\}\right]\\
      &=&\sum_{t=0}^K\expect\left[X_t\indexed\{\tau=t\}\right]\text{ by linearity of exp.}\\
      &=&\sum_{t=0}^K\expect\left[\expect[X_K|\mathcal{F}_t]\indexed\{\tau=t\}\right]\text{ by \texttt{Theorem \ref{sec_probability}.\ref{the_adapated_stochastic_processes_as_martingales}}}
    \end{array}\]
    Since $\tau$ is a \textit{Stopping Time} then $\{\tau=t\}$ is \textit{Measurable} wrt $\mathcal{F}_t$.
    \par Thus, by \texttt{Theorem \ref{sec_probability}.\ref{the_cond_exp_and_measurable}}
    \[ \expect[X_K|\mathcal{F}_t]\indexed\{\tau=t\}=\expect[X_K\indexed\{\tau=t\}|\mathcal{F}_t] \]
    We continue the analysis of $\expect[X_\tau]$
    \[\begin{array}{rcl}
    \expect[X_\tau]&=&\sum_{t=0}^K\expect\left[\expect[X_K|\mathcal{F}_t]\indexed\{\tau=t\}\right]\\
    &=&\sum_{t=0}^K\expect\left[\expect[X_K\cdot \indexed\{\tau=t\}|\mathcal{F}_t]\right]\\
    &=&\sum_{t=0}^K\expect[X_K\cdot \indexed\{\tau=t\}]\text{ by Tower Law}\\
    &=&\expect\left[X_K\sum_{t=0}^K\indexed\{\tau=t\}\right]\\
    &=&\expect\left[X_K\cdot1\right]\\
    &=&\expect\left[X_K\right]\\
    &=&\expect[X_0]\text{ as }\{X_t\}_{t\in\nats_0}\text{ is a Martingale}\\
    &=&X_0\text{ as its value is known}
    \end{array}\]
  \end{proof}

  \begin{definition}{Gambler's Ruin Problem}\label{def_gamblers_ruin}
    The \textit{Gambler's Ruin Problem} involves considering a gambler with an initial wealth of £$C$. The gambler is allowed to play a game until either they become bankrupt (i.e. have £0) or reach a target of £$(C+G)$ where $G>0$.
    \par The simplest specification of the game is flipping a coin\footnote{potentially fair, potentially not.} and the gambler receives £1 if it lands heads, or loses £1 if it lands tails.
  \end{definition}

  \begin{proposition}{Stopping Time in Gambler's Ruin Problem}\label{prop_stopping_time_gamblers_ruin}
    \everymath={\displaystyle}
    Consider the \textit{Gambler's Ruin Problem} using the simple game described in \texttt{Definition \ref{sec_probability}.\ref{def_gamblers_ruin}}.
    \par Let $\{X_t\}_{t\in\nats_0}$ be a \textit{Simple Random Walk} with parameter $p$\footnote{$\{X_t\}_{t\in\nats_0}$ can be consider to model the net winnings of the gambler and $p$ is the probability of the coin landing heads (i.e. the gambler wins money).} and $X_0=0$ and $C,G>0$.
    \par Consider the \textit{Stopping Time} $\tau:=\inf\{t:X_t=G\text{ or }X_t=-C\}$, the event the gambler stops playing\footnote{Either due to reaching goal or going bankrupt.}. Then
    \begin{itemize}
      \item If $p=1/2$ then
        \[\begin{array}{rcl}
          \prob(X_\tau=G)\footnotemark&=&\frac{C}{C+G}\\
          \prob(X_\tau=-C)\footnotemark&=&\frac{G}{C+G}\\
          \expect[\tau]&=&CG
        \end{array}\]
        \footnotetext{Gambler reaches goal.}
        \footnotetext{Gambler goes bankrupt.}
      \item If $p\neq1/2$ then
        \[\begin{array}{rcl}
          \prob(X_\tau=G)&=&\frac{1-\left(\frac{p}{1-p}\right)^C}{\left(\frac{p}{1-p}\right)^G-\left(\frac{p}{1-p}\right)^C}\\
          \prob(X_\tau=-C)&=&1-\prob(X_\tau=G)=\frac{\left(\frac{p}{1-p}\right)^G-1}{\left(\frac{p}{1-p}\right)^G-\left(\frac{p}{1-p}\right)^C}\\
          \expect[\tau]&=&\frac{G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)}{2p-1}
        \end{array}\]
    \end{itemize}
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{prop_stopping_time_gamblers_ruin}}}
    \everymath={\displaystyle}
    Since $\tau$ is \underline{not} \textit{Bounded}, but $X_\tau$ is \textit{Bounded} by $G,-C$, we can use a weaker condition from \texttt{Remark \ref{sec_probability}.\ref{rem_weaker_optional_stopping_theorem}} to apply the \textit{Optional Stopping Theorem} (\texttt{Theorem \ref{sec_probability}.\ref{the_optional_stopping_theorem_martingale}}) provided we can show that $\prob(\tau<\infty)=1$.
    \par Note that whenever there is a run of $k\geq C+G$ successive 1's in the process $\{Y_t\}_{t\in\nats_0}$ which defines the random walk $X$, the process will stop and $\tau<\infty$. Thus, for all $m$, the following hold
    \[\begin{array}{rcl}
      \prob(\tau>km)&=&\prob(\text{No run of }k\text{ 1's in }Y_1\text{ to }Y_{mk})\\
      &=&\prod_{j=0}^{m-1}\prob(\text{No run of }k\text{ 1's in }Y_{jk+1}\text{ to }Y_{(j+1)k})\\
      &=&(1-p^k)^m\\
      \implies\prob(\tau<\infty)&=&1
    \end{array}\]
    We can now consider the two cases for the value of $p$
    \begin{itemize}
      \item If $p=1/2$. Then by the \textit{Optional Stopping Theorem} we can deduce the following
      \[\begin{array}{rrcl}
        &0&=&\expect[X_\tau]\text{ as }p=1/2\\
        &&=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)\\
        &&=&G\prob(X_\tau=G)+(-C)(1-\prob(X_\tau=G))\\
        \implies&C&=&(G+C)\prob(X_\tau=G)\\
        \implies&\prob(X_\tau=G)&=&\frac{C}{G+C}\\
        \text{and}&\prob(X_\tau=-C)&=&1-\prob(X_\tau=G)=\frac{G}{G+C}
      \end{array}\]
      To determine $\expect[X_\tau]$ we apply the \textit{Optional Stopping Theorem} to the process $\{Z_t\}_{\nats_0}$ where $Z_t:=X_t^2-t$. It was shown in \texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}}  that $\{Z_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \par As $\{Z_t\}_{t\in\nats_0}$ is a \textit{Martingale} it holds that
      \[ 0=\expect[Z_0]=\expect[Z_\tau]=\expect[X_\tau^2-\tau]=\expect[X_\tau^2]-\expect[\tau] \]
      By rearranging we obtain that
      \[\begin{array}{rcl}
        \expect[\tau]&=&\expect[\tau]\\
        &=&G^2\prob(X_\tau=G)+C^2\prob(X_\tau=-C)\\
        &=&G^2\cdot\frac{C}{C+G}+C^2\frac{G}{C+G}\\
        &=&CG
      \end{array}\]
      \item Consider the case $p\neq1/2$ and the process $\{L_t\}_{t\in\nats_0}$ where $L_t:=\left(\frac{1-p}p\right)^{X_t}$. It was shown in \texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} that $\{L_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \par By the \textit{Optional Stopping Theorem}
      \[\begin{array}{rcl}
        1&=&\expect[L_0]\\
        &=&\left(\frac{1-p}p\right)^G\prob(X_\tau=G)+\left(\frac{1-p}p\right)^C\prob(X_\tau=-C)
      \end{array}\]
      Remembering that $\prob(X_\tau=G)+\prob(X_\tau=-C)=1$, we can derive the probabilities of each end event occurring
      \[\begin{array}{rcl}
        1&=&\left(\frac{1-p}p\right)^G\prob(X_\tau=G)+\left(\frac{1-p}p\right)^C(1-\prob(X_\tau=G))\\
        &=&\left(\frac{1-p}p\right)^C+\left[\left(\frac{1-p}p\right)^G-\left(\frac{1-p}p\right)^C\right]\prob(X_\tau=G)\\
        \implies\prob(X_\tau=G)&=&\frac{1-\left(\frac{1-p}p\right)^C}{\left(\frac{1-p}p\right)^G-\left(\frac{1-p}p\right)^C}
      \end{array}\]
      Consider the process $\{M_t\}_{t\in\nats_0}$ where $M_t:=X_t-t(2p-1)$. It was shown in \texttt{Proposition \ref{sec_probability}.\ref{prop_notable_martingales}} that $\{M_t\}_{t\in\nats_0}$ is a \textit{Martingale}.
      \par We determine $\expect[X_\tau]$ by applying the \textit{Optional Stopping Theorem} to $\{M_t\}_{t\in\nats_0}$.
      \[\begin{array}{rcl}
        0&=&\expect[M_\tau]\\
        &=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)-\expect[\tau](2p-1)
      \end{array}\]
      By rearranging we obtain that
      \[\begin{array}{rrcl}
        &0&=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)-\expect[\tau](2p-1)\\
        \implies&\expect[\tau](2p-1)&=&G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)\\
        \implies&\expect[\tau]&=&\frac{G\prob(X_\tau=G)+(-C)\prob(X_\tau=-C)}{2p-1}
      \end{array}\]
    \end{itemize}
    \proved
  \end{proof}

\subsection{Brownian Motion}

  \begin{definition}{Continuous Random Walk $\{S_t^n\}$}\label{def_continuous_random_walk}
    Let $\{S_t\}_{t\in\nats_0}$ be the discrete-time random walk where $S_t:=\sum_{i=1}^tY_i$ where $Y_i\sim\text{Normal}(0,1)$.
    \par Define $\{S_t^n\}_{t\in[0,1]}$ to be the continuous time-random walk defined by (\ref{eqn_continuous_random_walk}) and using linear interpolation.
    \begin{equation}\label{eqn_continuous_random_walk}
      S_t^n:=\frac1{\sqrt{n}}S_{(t\cdot n)}=\frac1{\sqrt{n}}\sum_{i=1}^{(t\cdot n)}Y_i\text{ with }Y_i\overset{iid}{\sim} N(0,1)
    \end{equation}
  \end{definition}

  \begin{theorem}{Properties of $\{S_t^n\}$}
    Here are some propoerties of $\{S_t^n\}_{t\in[0,1]}$ defined in \textbf{Definition \ref{sec_probability}.\ref{def_continuous_random_walk}}.
    \begin{enumerate}
      \item $S_0^{n}=S_0/\sqrt{n}=0$.
      \item Taking $t=j/n$ and $u=k/n$ gives
      \[ S_{t+u}^{n}-S_t^n=\frac1{\sqrt{n}}(S_{j+k}-S_j)=\frac1{\sqrt{n}}(Y_{j+1}+\dots+Y_{j+k}) \]
      As the $X$s are independent, this shows that the change in value of a given period is independent of both the start and end points.
      \item Taking $t=j/n$ and $u=k/n$, for large $n$. Consider this expression for the change in value over a time period
      \[ S_{t+u}^n-S_t^n=\frac{X_{j+1}+\dots+X_{j+k}}{\sqrt{n}}=\frac{\sqrt{k}}{\sqrt{n}}\left(\sum_{i=j+1}^{j+k}\frac{X_i}{\sqrt{k}}\right) \]
      By the \textit{Central Limit Theorem} this tends to $\text{Normal}\left(0,k/n\right)=\text{Normal}\left(0,u\right)$.
      \item $S_t^n(\omega)$ is continuous as a function of $t$, for all $n$ and all $\omega\in\Omega$.
      \item As $n\to\infty$, $S_t^n$ tends to a process $W_t$ known as \textit{Brownian Motion}.
    \end{enumerate}
  \end{theorem}

  \begin{definition}{Brownian Motion $\{W_t\}$}\label{def_brownian_motion}
    Let $W:=\{W_t\}_{t\geq0}$ be an \textit{Adapted Stochastic Process} wrt \textit{Filtration} $\{\mathcal{F}_t\}_{t\geq0}$.
    \par $W$ is a standard one-dimensional \textit{Brownian Motion} if
    \begin{enumerate}
      \item $W_0=0$. (Almost surely)
      \item $W$ has independent increments.
      \[ \forall\ u,t\geq0,\ W_{t+u}-W_t\text{ is independent of }\mathcal{F}_t \]
      \item $W$ has stationary Gaussian increments.
      \[ \forall\ u,t\geq0,\ (W_{t+u}-W_t)\sim\text{Normal}(0,u) \]
      \item $W$ has continuous paths. ($W_t(\omega)$ is a continuous function of $t$ for all $\omega\in\Omega$.)
    \end{enumerate}
  \end{definition}

  \begin{remark}{Differentiating Brownian Motion}
    Brownian Motion is \underline{not} differentiable.
  \end{remark}

  \begin{proposition}{General Properties of Brownian Motion}\label{pro_properties_of_standard_brownian_motion}
    Let $W$ be standard Brownian Motion, as defined in \textbf{Defintion \ref{sec_probability}.\ref{def_brownian_motion}}. Then
    \begin{enumerate}
      \item $\expect[W_t]=0,\ \var(W_t)=t\ \forall\ t$.
      \item $\forall\ s,t\ \cov(W_s,W_t)=\min\{s,t\}$.
      \item $-W_t$ is a \textit{Standard Brownian Motion}.
      \item For fixed $t$, $X_s:=W_{s+t}-W_t$ is a \textit{Standard Brownian Motion}.
      \item For any $\alpha$, $y_s:=\frac1{\sqrt\alpha}W_{\alpha s}$ is a \textit{Standard Brownian Motion}.
    \end{enumerate}
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{pro_properties_of_standard_brownian_motion} i)-v)}}
    \begin{enumerate}
      \item Follows from properties i) \& iii) of \texttt{Definition \ref{sec_probability}.\ref{def_brownian_motion}}.
      \item By the previous result we can conclude that
      \[\begin{array}{rcl}
        \cov(W_s,W_t)&=&\expect[W_s\cdot W_t]\\
        &=&\expect[W_s\cdot(W_t-W_s)]+\expect[W_s^2]\\
        &=&\expect[W_s\cdot(W_t-W_s)]+\underbrace{\var(W_s)}_{=s}\\
        &=&\underbrace{\expect[W_s]}_{=0}\expect[W_t-W_s]+s\\
        &=&s
      \end{array}\]
      \item $\expect[-W_t]=-\expect[W_t]=0$ and increments occur in the $t$-direction, not the $X$-direction, so the distribution of $W_{t+u}-W_t$ is unaffected.
      \item In the case $t=0$ we find that $X_0=W_t-W_t=0$. The other properties in \texttt{Defintion \ref{sec_probability}.\ref{def_brownian_motion}} are shift-invariant and therefore follow as well.
      \item The main part to check here is propert iii) of \texttt{Defintion \ref{sec_probability}.\ref{def_brownian_motion}}. Indeed
      \[\begin{array}{rcl}
        Y_{t+s}-Y_t&=&\underbrace{(W_{\alpha(t+s)}-W_{\alpha t})}_{\sim\text{Nor}(0,\alpha s)}/\sqrt{\alpha}\\
        &\sim&\text{Normal}(0,s)
      \end{array}\]
    \end{enumerate}
    \proved
  \end{proof}

  \begin{definition}{Geometric Brownian Motion}
    Let $\{W_t\}_{t\geq0}$ be \textit{Standard Brownian Motion}.
    \par \textit{Geometric Brownian Motion} $\{\tilde{Z}\}_{t\geq0}$ with volatility $\sigma>0$ and drift $a\in\reals$ is defined as
    \[ \tilde{Z}_t=\exp\left\{\sigma W_t+at\right\} \]
  \end{definition}

  \begin{proposition}{Martingales and Brownian Motion}\label{pro_martingales_and_brownian_motion}
    Let $\{W_t\}_{t\geq0}$ be \textit{Standard Brownian Motion} wrt \textit{Filtration} $\{\mathcal{F}_t\}_{t\geq0}$. Then
    \begin{enumerate}
      \item $\{W_t\}_{t\geq0}$ is a \textit{Martingale}.
      \item $\{W_t^2-t\}_{t\geq0}$ is a \textit{Martingale}.
      \item The \textit{Geometric Brownian Motion} with volatility $\sigma>0$ and drift $a\in\reals$ is a \textit{Martingale} \underline{iff} $a=-\frac12\sigma^2$.
    \end{enumerate}
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_probability}.\ref{pro_martingales_and_brownian_motion} i)-iii)}}
    \begin{enumerate}
      \item We can write $W_t=(W_t-W_s)+W_s$. As $(W_t-W_s)$ is independent of filtration $\mathcal{F}_s$ and has zero mean, we can conclude that
      \[ \expect[W_t|\mathcal{F}_s]=\expect[W_t-W_s|\mathcal{F}_s]+\expect[W_s|\mathcal{F}_s]=\underbrace{\expect[W_t-W_s]}_{=0}+W_s=W_s \]
      \item Similarly, we can write
      \[ W_t^2=(W_t-W_s)^2+2W_s(W_t-W_s)+W_s^2 \]
      Then
      \[\begin{array}{rcl}
        \expect[W_t^2-t|\mathcal{F}_s]&=&\left\{\expect[(W_t-W_s)^2|\mathcal{F}_s]+2W_s\expect[W_t-W_s|\mathcal{F}_s]+W_s^2\right\}-t\\
        &=&\var(W_t-W_s)+0+W_s^2-t\\
        &=&t-s+W_s^2-t\\
        &=&W_s^2-s
      \end{array}\]
      \item We find that
      \[\begin{array}{rcl}
        \expect[\tilde{Z}_t|\mathcal{F}_s]&=&\expect[\exp\{\sigma W_t+at\}|\mathcal{F}_s]\\
        &=&\exp\{at\}\expect[\exp\{\sigma(W_t-W_s+W_s)\}|\mathcal{F}_s]\\
        &=&\exp\{\sigma W_s+at\}\cdot\expect[\exp\{\sigma\overbrace{(W_t-W_s)}^{:=N}\}|\mathcal{F}_s]\\
        &=&\exp\{\sigma W_s+at\}\expect[\exp\{\sigma N\}|\mathcal{F}_s]\\
        &=&\exp\{\sigma W_s+at\}\expect[\exp\{\sigma N\}]
      \end{array}\]
      where $N\sim\text{Normal}(0,t-s)$. The MGF of $N$ is $\expect[e^{\sigma N}]=e^{(t-s)\sigma^2/2}$, therefore
      \[\begin{array}{rcl}
        \expect[\tilde{Z}_t|\mathcal{F}_s]&=&\exp\{\sigma W_s+at\}\expect[\exp\{\sigma N\}]\\
        &=&\tilde{Z}_se^{a(t-s)}e^{(t-s)\sigma^2/2}\\
        &=&\tilde{Z}_s\exp\left\{(t-s)\left(a+\frac{\sigma^2}2\right)\right\}
      \end{array}\]
      We conclude that $\tilde{Z}_t$ is a \textit{Martingale} \underline{iff} $a=-\sigma^2$\footnote{As we require $\expect[\tilde{Z}_t|\mathcal{F}_s]=\tilde{Z}_s$ which only occurs \underline{iff} $a+\frac{\sigma^2}2=0$.}.
    \end{enumerate}
    \proved
  \end{proof}

\section{Financial Terminology}\label{sec_financial_terminology}

  \begin{definition}{Underlying Asset}
    The \textit{Underlying Asset} is a real financial asset or security which a contract can be based on. (e.g. Oil, interest rate, shares).
  \end{definition}

  \begin{definition}{Dividend}
    A \textit{Dividend} is a one-off payment provided to the holder of an \textit{Underlying Asset} at a certain time. Whether an \textit{Underlying Asset} pays a \textit{Dividend}, and the value of the \textit{Dividend}, will affect the value of the \textit{Underlying Asset}.
    \par A \textit{Dividend} is generally used by companies to distribute yearly profits to its shareholders.
  \end{definition}

  \begin{definition}{Long Selling}
    \textit{Long Selling} is the practice of buying an asset (or security) and then selling it at some point in the future.
    \par In \textit{Long Selling} your profit/loss is $P_{\text{sell}}-P_{\text{buy}}$, thus you hope the price of the asset \underline{increases} in the period between you buying and selling it.
  \end{definition}

  \begin{definition}{Short Selling}
    \textit{Short Selling} is the practice of borrowing an asset (or security), immediately selling it\footnote{Receiving payment at this point.} and at some point in the future buying an equivalent asset in order to reimburse your lender.
    \par In \textit{Short Selling} your profit/loss if $P_{\text{sell}}-P_{\text{buy}}$, thus you hope the price of the asset \underline{decreases} in the period between you selling and having to reimburse your lender.
  \end{definition}

  \begin{remark}{Short Selling \& Dividends}
    If the asset you borrowed in \textit{Short Selling} pays a \textit{Dividend} during the time you have borrowed the asset, then you must pay this \textit{Dividend} to the lender.\footnote{As you have already sold the asset, then this expense will come out of your own pocket.}
  \end{remark}

  \begin{definition}{Arbitrage Opportunity}
    An \textit{Arbitrage Opportunity} occurs when it is possible to make a profit without being exposed to the risk of incurring a loss.\footnote{Someone who loos for \textit{Arbitrage Opportunities} is called an \textit{Arbitrageur}.}
    \par Generally \textit{Arbitrage Opportunities} occur by being able to buy and sell the same asset in different markets, as each market may have a different price.
  \end{definition}

  \begin{theorem}{No-Arbitrage Principle}
    \begin{quote}
      ``\textit{Arbitrage Opportunities} do not exist (for long) in real life markets.''
    \end{quote}
    As when the opportunities arise, the market activity cause by agents exploiting the opportunity would raise the cost of buying and thus remove the opportunity due to the \textit{Law of Supply-and-Demand}.
  \end{theorem}

  \begin{remark}{Value of Money}
    IRL the value of money is not constant due to inflation, interest rates \& exchange rates. We generally want to normalise the returns of our portfolio wrt the change in value of money in order to determine the ``real returns''.
  \end{remark}

  \begin{definition}{Portfolio}
    TODO
    % Replicating Portfolio
  \end{definition}

\subsection{Derivatives}

  \begin{definition}{Derivative Securities}
    A \textit{Deriviative Security} is a contract which has an expiry date $T$ and pays out different amounts depending upon the value of some \textit{Underlying Asset} in the time-period $[0,T]$.
  \end{definition}

  \begin{remark}{Valuing Contracts}
    When valuing contracts we assume that arbitrage does not exist. This means we can derive a single price\footnote{Known as the \textit{Fair Price}.} for a contract, as any other price would create an \textit{Arbitrage Opportunity}.
  \end{remark}

  \begin{theorem}{Equivalent Contract Valuations over Time}\label{the_equivalent_contract_valuations_over_time}
    If two combinations of financial derivatives both have the same value $V_T=W_T$ at time $t=T$. Then their prices will be the same at all $t<T$
    \[ \text{if }V_T=W_t\text{ then }V_t=W_t\ \forall\ t<T \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_equivalent_contract_valuations_over_time}} }
    \textit{We assume the ``No-Arbitrage Principle'' holds throughout this proof.}
    \par Let $V_t,W_t$ represent the fair price for two different combinations of financial derivatives at time $t$ and that $V_T=W_T$. Suppose there is a risk-free profit of $r$.
    \par Assume WLOG that $V_t>W_t$. Then an arbitrage opportunity exists and can be exploited by doing the following:
    \begin{itemize}
      \item At $t=0$
      \begin{enumerate}
        \item Sell/short the first combination, receiving £$V_t$.
        \item Buy the second combination, costing £$W_t$.
        \item Invest the difference (£$V_t-W_t>0$).
      \end{enumerate}
      \item At $t=T$
      \begin{enumerate}
        \item Sell the first combination, receiving £$V_T=W_T$
        \item Buy the second combination, costing £$W_T=V_T$.
      \end{enumerate}
    \end{itemize}
    Following this will result in a ``riskless'' profit of $(V_t-W_t)e^{r(T-t)}>0$.
  \end{proof}

  \begin{definition}{Forward Contract}
    A \textit{Forward Contract} is a type of \textit{Derivative Security}. In a \textit{Forward Contract} two parties agree to an exchange on a predetermined future date for a predetermined amount, and are both \underline{obliged} to fulfil this exchange.
    \par All \textit{Forward Contracts} have the following components
    \begin{itemize}
      \item \textit{Delivery Date} $T$.
      \item \textit{Delivery Price} $K$.
    \end{itemize}
  \end{definition}

  \begin{remark}{Positions in a Forward Contract}
    In a \textit{Forward Contract} agents can take two positions
    \begin{itemize}
      \item \textit{Long Position} - Agree to buy the underlying asset for $\pounds K$ on date $T$. Makes a profit if the market-value of the underlying asset is \underline{greater} than $K$ in time-period $T$.
      \item \textit{Short Position} - Agree to sell the underlying asset for $\pounds K$ on date $T$. Makes a profit if the market-value of the underlying asset is \underline{less} than $K$ in time-period $T$.
    \end{itemize}
  \end{remark}

  \begin{remark}{Utility of Forwards Contracts}
    \textit{Forward Contracts} allow you to agree terms of a purchase/sale some time in advance of actually transacting. This means business have greater certainty about their future cash-flows.\footnote{e.g. Farmers may agree to a price for their whole harvest a year in advance. Thus their next years income is completely known.}
  \end{remark}

  \begin{theorem}{Fair Delivery Price of a Forward Contract}\label{the_fair_price_of_a_forward_contract}
    Consider a \textit{Forward Contract} with delivery date $T$, where the underlying asset has value $S_0$ at time $t=0$ and pays a dividend $D$ at time $t_0\in(0,T)$. Suppose there is a risk-free bank account with a constant interest rate $r$ during the interval $[0,T]$.\footnote{This means $B_t=e^{rt}$.}
    \par Then
    \begin{itemize}
      \item If $D=0$ (ie no dividend is payed) then the fair \textit{Delivery Price} for this contract is
      \[ K=S_0e^{rT} \]
      \item If $D>0$ then the fair \textit{Delivery Price} for this contract is
      \[ K=(S_0-I)e^{rT}\text{ where }I:=De^{-rt_0} \]
    \end{itemize}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_fair_price_of_a_forward_contract}}}
    \textit{We use the ``No-Arbitrage Principle'' to prove that these $K$s are the fair prices under each scenario.}
    \par \textit{Case 1} - Suppose, for the sake-of-contradiction, that $K>(S_0-I)e^{rT}$ with $I:=De^{-rt_0}$. Then an arbitrage opportunity exists and can be exploited by doing the following:
    \begin{itemize}
      \item At $t=0$
      \begin{enumerate}
        \item Borrow £$S_0$ from the bank, at an interest rate of $r$.
        \item Buy the underlying asset.
        \item Taking a short position in the forward contract (receiving $K>(S_0-I)e^{rT}$).
      \end{enumerate}
      \item At $t=t_0$
      \begin{enumerate}
        \item We will receive a dividend payment £$D$ which we shall use to partially repay our loan. This leaves an outstanding balance of $S_0e^{rt_0}-D$.
      \end{enumerate}
      \item At $t=T$
      \begin{enumerate}
        \item Sell the asset for $K$ using the forward contract.
        \item Repay the outstanding balance on the loan ($(S_0e^{rt_0}-D)e^{r(T-t_0)}$).
      \end{enumerate}
    \end{itemize}
    \par Doing all this will lead to a ``riskless'' profit of
    \[ K-(S_0e^{rt_0}-D)e^{r(T-t_0)}=K-(S_0-I)e^{rT}>0\text{ by def. }K \]
    This means that this definition of $K$ cannot be the fair-price, thus $K\leq(S_0-I)e^{rT}$.
    \par \textit{Case 2} - Suppose, for the sake-of-contradiction, that $K<(S_0-I)e^{rT}$ with $I:=De^{-rt_0}$. Then an arbitrage opportunity exists and can be exploited by doing the following:
    \begin{itemize}
      \item At $t=0$
      \begin{enumerate}
        \item Short sell the underlying asset. (Receiving £$S_0$).
        \item Invest this revenue, receiving an interest rate of $r$.
        \item Take a long position on the forward contract.
      \end{enumerate}
      \item At $t=t_0$
      \begin{enumerate}
        \item Pay the dividend £$D$ to our lender, from our bank account.
      \end{enumerate}
      \item At $t=T$
      \begin{enumerate}
        \item Buy the asset for $K$ using the forward contract.
      \end{enumerate}
    \end{itemize}
    \par Doing all this will lead to a ``riskless'' profit of
    \[ (S_0e^{rt_0}-D)e^{r(T-t_0)}-K=(S_0-I)e^{rT}-K>0\text{ by def. }K \]
    This means that this definition of $K$ cannot be the fair-price, thus $K\geq(S_0-I)e^{rT}$.
    \par Thus, by combining these two inequalities, the fair price for this \textit{Forward Contract} is
    \[ K=(S_0-I)e^{rT} \]
  \end{proof}

  \begin{definition}{Options Contract}
    An \textit{Options Contract} is a type of \textit{Derivative Security}. In an \textit{Options Contract} two parties agree to an exchange on (or before) a predetermined future date for a predetermined amount, but the holder is \underline{not obliged} to fulfil this exchange.
    \par All \textit{Options Contracts} have the following components
    \begin{itemize}
      \item \textit{Delivery Date} $T$.
      \item \textit{Strike Price} $K$.
    \end{itemize}
    There are two classes of \textit{Options Contract}
    \begin{itemize}
      \item \textit{Call Option} - The holder has the right to buy.
      \item \textit{Put Option} - The holder has the right to sell.
    \end{itemize}
  \end{definition}

  \begin{definition}{European \& American Options}
    There are two categories of \textit{Options Contract} which determine when the contract can be exercised
    \begin{itemize}
      \item \textit{European Option} - The holder can only execute on the delivery date $t=T$.
      \item \textit{American Option} - The holder can execute on \underline{any} date before the delivery date $T$.
    \end{itemize}
  \end{definition}

  \begin{definition}{Positions in an Options Contract}
    In \textit{Options Contracts} agents can take one of two positions. The position they take determines their rights \& potential cash-flows.
    \begin{itemize}
      \item \textit{Holder} - Decides whether to execute the contract of not. Will pay the \textit{Writer} a fee for creating the contract.
      \par The \textit{Holder's} only expense is the fee they pay the \textit{Writer} and they may make an income if they execute the contract.
      \item \textit{Write} - Must complete the transaction if the \textit{Holder} wishes to. Receives a fee from the \textit{Holder}.
      \par The \textit{Writer's} only income is the fee they receive from the \textit{Holder} and they may incur a loss if the contract is executed.
    \end{itemize}
  \end{definition}

  \begin{remark}{When are options executed?}
    Whether the holder should execute their option depends on the market price $S_T$ at time $T$, the strike price $K$ and the class of contract. Assuming (justifiably) that the holder will only execute the option if it will make them money, the holder should do the following
    \begin{itemize}
      \item For a \textit{Call Option} the holder should execute if $S_T>K$. As they can immediately sell their newly bought asset for a profit of $S_T-K-F$ where $F$ is the fee payed to the writer.
      \item For a \textit{Put Option} the holder should execute if $S_T<K$. As they can buy the asset from the market and sell it to the writer of their option for a profit of $S_T-K-F$ where $F$ is the fee payed to the writer.
    \end{itemize}
  \end{remark}

  \begin{theorem}{Put-Call Parity\footnote{This is an application of \texttt{Theorem \ref{sec_financial_terminology}.\ref{the_equivalent_contract_valuations_over_time}} to European Put \& Call Options.}}\label{the_put_call_parity}
    Consider a \textit{European Put Option} and a \textit{European Call Option} where both have the same: underlying asset, strike price $K$ and expiry date $T$. Let $S_t$ be the value of the underlying asset at time point $t$ and assume there is a ``risk-free'' interest rate of $r$ available.
    \par Then, if \underline{no} \textit{Arbitrage Opportunities} exist then the following hold
    \[ S_t+P_t-C_t=Ke^{-r(T-t)}\ \forall\ t\in[0,T] \]
    where $P_t,C_t$ are the prices of the put \& call options at time $t$ respectively, and $Ke^{-r(T-t)}$ is the discounted value of our bank account.
  \end{theorem}

  \begin{theorem}{Lower-Bound for a European Call Option}\label{the_lower_bound_for_a_european_call_option}
     Let $S_t$ be the value of an underlying asset at time $t$.
     \par For a \textit{European Call Option} with strike price $K$ and delivery date $T$ we can determine the following lower bound on its price $C_t$
    \[\begin{array}{rcl}
      C_t&\geq&\{S_t-Ke^{-r(T-t)}\}_+
    \end{array}\]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_lower_bound_for_a_european_call_option}} }
    By \textit{Put-Call Parity} (\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_put_call_parity}}) we have that
    \[\begin{array}{rrcl}
      &S_t+P_t-C_t&=&Ke^{-r(T-t)}\\
      \implies&C_t&=&S_t+P_t-Ke^{-r(T-t)}
    \end{array}\]
    Since \textit{Put Options} cannot have a negative price, $P_t\geq0$, we have that
    \[ C_t\geq S_t+P_t-Ke^{-r(T-t)} \]
    Further, since \textit{Call Options} cannot have a negative price, $C_t\geq0$, we have that
    \[ C_t\geq \big\{S_t+P_t-Ke^{-r(T-t)}\big\}_+ \]
  \end{proof}

  \begin{theorem}{Value of American Call Options w/o Dividends}\label{the_value_of_america_call_options_wo_dividends}
    Consider an \textit{American} \& a \textit{European Call Option}, for the same underlying asset, with the same strike price and expiry date.
    \par Then, if the underlying asset does \underline{not} pay a \textit{Dividend}
    \[ C_A=C_E\footnotemark \]
    \footnotetext{This shows that if an underlying asset does not pay a dividend then it is suboptimal to exercise an \textit{American Call Option} early.}
    where $C_A,C_E$ are the price of the American \& European call options, respectively.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_value_of_america_call_options_wo_dividends}}}
    If the \textit{American Call Option} is executed early at time-point $t<T$ then it generates an income of $S_t-K$.
    \par However, \texttt{Theorem \ref{sec_financial_terminology}.\ref{the_lower_bound_for_a_european_call_option}} shows that selling a \textit{Call Option} generates
    \[ \{S_t-Ke^{-r(T_t)}\}_+\geq S_t-Ke^{-r(T-t)}>S_t-K \]
    This shows that it is sub-optimal to exercise the call at any time $t<T$.
  \end{proof}

\section{Discrete-Time}\label{sec_discrete_time_models}

\subsection{Processes of Financial Models}\label{sec_processes_of_models}

  \begin{remark}{Time-Span $T$}
    Below I generically define several processes which are commonly defined for different financial models. Different models use different time-spans $T$ at which trades can occur:
    \begin{itemize}
      \item Single-Period Model - $T=\{0,1\}$.
      \item Multi-Period Model - $T=\{0,1,\dots,T\}$.
      \item Continuous - $T=[0,T]$.
    \end{itemize}
  \end{remark}

  \begin{definition}{Bank Account Process, $B$}\label{def_bank_account_process}
    A \textit{Bank Account Process} $B$ models how much an initial deposit of one unit, at time $t=0$, into a ``risk-free'' bank account, with interest rate $r$, would be worth at each time-point $t$.
    \[\begin{array}{rrcl}
      &B&=&\{B_t:t\in T\}\\
      \text{where}&B_0&=&1\\
      \text{and}&B_t(\omega)&\geq&0\ \forall\ \omega\in\Omega
    \end{array}\]
    It is generally assumed that you can borrow money from these accounts, paying the same interest rate $r$.
  \end{definition}

  \begin{proposition}{Value of Bank Account Process $B$}
    \par Suppose our ``Risk-Free'' Bank Account pays a constant interest rate of $r$ in each time-period, then after $t$ time-periods our initial deposit is worth
    \begin{itemize}
      \item \textit{Single-Period Model} $B_1=B_0(1+r)$.\footnote{Must be that $t=1$ in a \textit{Single-Period Model}.}
      \item \textit{Multi-Period Model} $B_t=B_0(1+r)^t$.
      \item \textit{Continuous Time Model} $B_t=B_0e^{rt}$.
    \end{itemize}
  \end{proposition}

  \begin{definition}{Price-Process $S$}\label{def_price_process}
    A \textit{Price Process} $S$ models the price of each security at each time-point
    \[ S:=\{S(t):t\in T\}\text{ where }S(t)=(S_1(t),\dots,S_N(t)) \]
    where $S_n(t)$ is the price of the $n^{th}$ stock at time $t$ and there are $N$ different stock available.
    \par The values of $S(t)$ only become known in time-period $t$.
  \end{definition}

  \begin{definition}{Discounted Price-Process $S^*$}\label{def_discounted_price_process}
    A \textit{Discounted Price-Process} $S^*$ is the price of each security at each time-point $t$, \underline{but} normalised by the \textit{Bank Process} $B_t$.
    \[ S^*:=\{S^*(t):t\in T\}\text{ where }S^*(t)=(S_1^*(t),\dots,S_N^*(t))\text{ and }S_n^*(t):=\frac{S_n(t)}{B_t} \]
  \end{definition}

  \begin{definition}{Trading Strategy $H$}
    A \textit{Trading Strategy} $H$ describes the changes in an investors portfolio over given time-periods.
    \[ H(t):=\big(H_0(t),H_1(t),\dots,H_N(t)\big)\text{ for }t\in T \]
    where $H_0(t),\dots,H_N(t)$ are predictable stochastic processes with $H_n(t)$ denoting the number of units of stock $n$ the investor carries from period $t-1$ to period $t$. Stock $n=0$ is the bank account.
  \end{definition}

  \begin{definition}{Self-Financing Trading Strategy}
    A \textit{Trading Strategy} $H$ is to be \textit{Self-Financing} if no money is introduced, or removed, between time-periods.
    \[ \forall\ t\in T,\quad V_t=H_0(t+1)B_t+\sum_{n=1}^NH_n(t+1)S_n(t) \]
  \end{definition}

  \begin{theorem}{Self-Financing and Value Process}\label{the_self_financing_and_value_process}
    A \textit{Trading Strategy} $H$ is self-financing \underline{iff} $\forall\ t\in(T\setminus\{0\}),\ V_t^*=V_0^*+G_t^*$
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_self_financing_and_value_process}}}\label{proof_self_financing_and_value_process}
    For all $t=1,\dots,T$ it holds that
    \[ G_t^*=G_{t-1}^*+\sum_{n=1}^NH_n(t)\Delta S_n^*(t) \]
    For convenience we define $G_0^*=0$.
    \par I prove the statement in both directions
    \begin{itemize}
      \item[$\Longrightarrow$] Assume that $H$ is \textit{Self-Financing}.
      \par By the definitions of \textit{Self-Financing}, \textit{Discounted Processes} and the above result, we can show the following for all $t=1,\dots,T$
      \[\begin{array}{rcl}
        V_t^*-G_t^*&=&H_0(t)+\left(\sum_{n=1}^NH_n(t)S_n^*(t)\right)-\left(\sum_{n=1}^NH_n(t)\Delta S_n^*(t)\right)-G_{t-1}^*\\
        &=&H_0(t)+\left(\sum_{n=1}^NH_n(t)(S_n^*(t)-\Delta S_n^*(t))\right)-G_{t-1}^*\\
        &=&H_0(t)+\left(\sum_{n=1}^NH_n(t)S_n^*(t-1)\right)-G_{t-1}^*\\
        &=&V_{t-1}^*-G_{t-1}^*
      \end{array}\]
      By recursion we find that $V_t^*-G_t^*=V_0^*$.

      \item[$\Longleftarrow$] Assume that $V_t^*=V_0^*+G_t^*$ for all $t=1,\dots,T$.
      \par Then, for all $t=1,\dots,T_1$ we have the following
      \[\begin{array}{rcl}
        V_t^*-V_{t+1}^*&=&V_0^*+G_t^*-(V_0^*+G_{t+1}^*)\\
        &=&G_t^*-G_{t-1}^*
      \end{array}\]
      Therefore, by the definitions of discounted process and the result at the start of this proof
      \[\begin{array}{rcl}
        V_t^*&=&V_{t+1}^*-(G_{t+1}^*-G_t^*)\\
        &=&H_0(t+1)+\sum_{n=1}^NH_n(t+1)S_n^*(t+1)-\sum_{n=1}^NH_n(t+1)\Delta S_n^*(t+1)\\
        &=&H_0(t+1)+\sum_{n=1}^NH_n(t+1)
      \end{array}\]
      Thus $H$ is \textit{Self-Financing}.
    \end{itemize}
    \proved
  \end{proof}

  \begin{definition}{Value-Process $V$}\label{def_value_process}
    A \textit{Value Process} $V$ models the total value of a \textit{Trading Strategy} $H$ at each time-point $t$
    \[ V:=\{V_t:t\in T\}\text{ where }V_t:=H_0(t)B_t+\sum_{n=1}^NH_n(t)S_n(t) \]
  \end{definition}

  \begin{definition}{Discounted Value-Process $V^*$}\label{def_discounted_value_process}
    A \textit{Discounted Value-Process} $V^*$ models the total value of a \textit{Trading Strategy} $H$ at each time-point $t$ \underline{but} normalised by the \textit{Bank Process} $B$.
    \[ V^*:=\{V_t^*:t\in T\}\text{ where }V_t^*:=\frac{V_t}{B_t}=H_0+\sum_{n=1}^NH_n\underbrace{\frac{S_n(t)}{B_t}}_{=S_n^*(t)} \]
  \end{definition}

  \begin{definition}{Gains-Process $G$}\label{def_gains_process}
    A \textit{Gains Process} $G$ models the total profit/loss made by a \textit{Trading Strategy} $H$ up to time-period $t$.
    \[\everymath={\displaystyle}\begin{array}{rrcll}
      &G&:=&\{G_t:t\in T\setminus\{0\}\}\\
      \text{where}&G_t&:=&\left(\sum_{u=1}^tH_0(u)B_t\right)+\sum_{n=1}^N\sum_{u=1}^tH_n(u)\Delta S_n^*(u)&\text{Discrete}\\
      \text{or}&G_t&:=&\int_0^tH_0(u)dB_u+\sum_{n=1}^N\int_0^tH_n(u)dS_n(u)&\text{Continuous}
    \end{array}\]
  \end{definition}

  \begin{definition}{Discounted Gains-Process $G^*$}\label{def_discounted_gains_process}
    A \textit{Discounted Gains Process} $G^*$ models the total discounted profit/loss made by a \textit{Trading Strategy} $H$ up to time-period $t$.
    \[\everymath={\displaystyle}\begin{array}{rrcll}
      &G^*&:=&\{G_t^*:t\in T\setminus\{0\}\}\\
      \text{where}&G_t^*&:=&\frac{G_t}{B_t}=\sum_{n=1}^N\sum_{u=1}^tH_n(u)\Delta S_n^*(u)&\text{Discrete}\\
      \text{and}&\Delta S_n(u)&:=&S_n(t)-S_n(t-1)\\
      \text{or}&G_t^*&:=&\sum_{n=1}^N\int_0^tH_n(u)dS_n^*(u)&\text{Continuous}
    \end{array}\]
  \end{definition}

\subsection{Single-Period Model}

  \begin{definition}{Single-Period Model}
    The \textit{Single-Period Model} is a model for a financial market where actions can only occur on two dates. It has the following components
    \begin{itemize}
      \item \textit{Initial Date} $t=0$.
      \item \textit{Terminal Date} $t=1$.
      \item Trading is only allowed to occur on the \textit{Initial \& Terminal Dates}.
      \item A finite \textit{Sample Space} $\Omega:=\{\omega_1,\dots,\omega_K\}$ with $K<\infty$.
      \par Each event $\omega_1,\dots,\omega_K$ corresponds to some state of the world.
      \item A \textit{Probability Measure} $\prob$ on the \textit{Sample Space} $\Omega$ with $\prob(\{\omega_i\})>0\ \forall\ i\in[1,K]$.
    \end{itemize}
  \end{definition}

  \begin{definition}{Arbitrage Opportunity - Single-Period Model}
    Consider a \textit{Trading Strategy} $H=(H_0,H_1)$ for the \textit{Single-Period Model}.
    \par $H$ exploits an \textit{Arbitrage Opportunity} if it has the following three properties
    \begin{enumerate}
      \item $V_0=0$.
      \item $V_1(\omega)\geq0\ \forall\ \omega\in\Omega$.
      \item $\prob(V_1(\omega)\geq0)>0\ \forall\ \omega\in\Omega$.\footnote{Equivalently $\expect[V_1]>0$}
    \end{enumerate}
  \end{definition}

  \begin{theorem}{Arbitrage Opportunities \& Gains Process}\label{the_arbitrage_opportunities_and_gains_processes}
    There exists an \textit{Arbitrage Opportunity} in a market \underline{iff} there exists a \textit{Trading Strategy} $H$ st\footnote{This means $H$ never loses money, and it is expected to make money.}
    \[ G^*\geq0\quad\text{and}\quad\expect[G^*]>0 \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_arbitrage_opportunities_and_gains_processes}}}
    \begin{itemize}
      \item[$\Rightarrow$] Let $H$ be a \textit{Trading Strategy} which exploits an \textit{Arbitrage Opportunity}.
      \par By the definition of an \textit{Arbitrage Opportunity} $G^*=V_1^*-V_0^*$ and $B_t>0\ \forall\ t,\omega$, this means that $G^*\geq0$ and thus
      \[ \expect[G^*]=\expect[V_1^*]>0 \]
      \item[$\Leftarrow$] Let $H$ be a \textit{Trading Strategy} which satisfies $G^*\geq0$ and $\expect[G^*]>0$.
      \par Define $\hat{H}:=(\hat{H_0},H_1,\dots,H_N)$ where $\hat{H}_0:=-\sum_{i=1}^NH_iS_i^*(0)$\footnote{This ensures $V_0$, a requirement for $H$ to exploit an \textit{Arbitrage Opportunity}.}.
      \par Under $\hat{H}_0$ we have that $V_0^*=0$ and $V_1^*=V_0^*+G^*=G^*$.
      \par Hence, $V_1^*\geq0$ and $\expect[V_1^*]=\expect[G^*]>0$, meaning $\hat{H}$ exploits an \textit{Arbitrage Opportunity}.
    \end{itemize}
    As the result holds in both directions, we can say it holds \underline{iff}.
  \end{proof}

\subsubsection{Risk-Neutral Probability Measures $\Q$}

  \begin{remark}{Risk-Neutral Probability Measure vs Martingale Measure}
    A risk-neutral probability measure (\textbf{Definition \ref{sec_discrete_time_models}.\ref{def_risk_neutral_probability_measure}}) is the single-period version of a martingale measure (\textbf{Definition \ref{sec_discrete_time_models}.\ref{def_martingale_measure}}).
  \end{remark}

  \begin{definition}{Risk-Neutral Probability Measure $\Q$}\label{def_risk_neutral_probability_measure}
    A \textit{Probabiltiy Measure} $\Q$ on \textit{Sample Space} $\Omega$ is said to be a \textit{Risk-Neutral Probability Measure} if the following hold
    \begin{enumerate}
      \item $\Q(\{\omega\})>0\ \forall\ \omega\in\Omega$.
      \item $\expect_\Q[S_i*(1)]=S_i^*(0)\ \forall\ i\in[1,N]$
    \end{enumerate}
  \end{definition}

  \begin{theorem}{Separating Hyperplane Theorem\footnote{This theorem is used to prove \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_no_arbitrage_theorem}}. The proof of this theorem is beyond the scope of this course.}}\label{the_separating_hyperplane_theorem}
    Let $\mathbb{W}$ be a linear subspace of $\reals^K$ and $\mathbb{K}$ be a compact convex subset in $\reals^K$ which is disjoint from $\mathbb{W}$.
    \par We can separate $\mathbb{W}$ and $\mathbb{K}$ strictly by using a hyperplane containing $\mathbb{W}$\footnote{ie $\exists\ v\in\reals^K$ which is \textit{Orthogonal} to $\mathbb{W}$\footnotemark{$u^Tv=0\ \forall\ u\in \mathbb{W}$}.} st
    \[ u^Tv>0\ \forall\ u\in\mathbb{K} \]
  \end{theorem}

  \begin{theorem}{No-Arbitrage Principle}\label{the_no_arbitrage_theorem}
    No \textit{Arbitrage Opportunities} exist in a single-period model \underline{iff} there exists a \textit{Risk-Neural Probability Measure} $\Q$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_no_arbitrage_theorem}}}
    \par Consider the three following sets
    \begin{enumerate}
      \item $\mathbb{W}=\left\{X\in\reals^K:X=G^*\text{ for some Trading Strategy }H\right\}$.
      \par This is the set of possible \textit{Gains} in our market for \textit{Trading Strategies} which have zero initial investment. $\mathbb{W}$ is a linear subspace of $\reals^K$\footnote{Proved by showing it is complete under: addition, and scalar multiplication.}.
      \item $\mathbb{A}=\left\{X\in\reals^K:X\geq0,X\neq0\right\}$\footnote{$\mathbb{A}$ is not compact, so can not be used for $\mathbb{K}$ in \textit{Separating Hyperplane Theorem}}.
      \par There exists an arbitrage opportunity \underline{iff} $\mathbb{W}\cap\mathbb{A}\neq\emptyset$.
      \item $\mathbb{A}^+=\left\{X\in\reals^N:X\geq0,X\neq0,\sum_{i=1}^KX_i=1\right\}$.
      \par $\mathbb{A}^+$ is a convex and compact subset of $\reals^K$.
    \end{enumerate}
    \begin{itemize}
      \item[$\Rightarrow$] Assume that there are no \textit{Arbitrage Opportunities}, then $\mathbb{W}\cap\mathbb{A}\neq\emptyset$. \par By the \textit{Separating Hyperplane Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_separating_hyperplane_theorem}}) $\exists\ Y\in\reals^K$ which is \textit{orthogonal} to $\mathbb{W}$ st
      \[ X^TY>0\ \forall\ X\in\mathbb{A}^+ \]
      For each $k\in\{1,\dots,K\}$ the $k^\text{th}$ unit vector $e_k$ is an element of $\mathbb{A}^+$. Therefore,
      \[ Y_k:=e_k^TY>0\ \forall\ k\in\{1,\dots,K\} \]
      meaning all entries of $Y$ are strictly positive.
      \par Define a probability measure $\Q$ by setting
      \[ \Q(\{\omega_k\})=\frac{Y(\omega_k)}{Y(\omega_1)+\dots+Y(\omega_k)} \]
      Furthermore, $\Delta S_n^*\in\mathbb{W}\ \forall\ n$ because $\Delta S_n^*:=S_n^*(1)-S_n^*(0)$ is the discounted wealth for the portfolio $H:=e_n$ which consists of one unit of the $n^\text{th}$ asset only.
      \par Since $Y$ is orthogonal to $\mathbb{W}$ we can conclude that
      \[ \expect_\Q[\Delta S_n^*]=\sum_{k=1}^K\Delta S_n^*(\omega_k)\Q(\{\omega_k\})=0\ \forall\ n \]
      In other words
      \[ \expect_\Q[S_n^*(1)]=S_n^*(0)\ \forall\ n \]
      Thus $\Q$ is a \textit{Risk-Neutral Probability Measure}.

      \item[$\Leftarrow$] Let $\Q$ be a \textit{Risk-Neutral Probability Measure}.
      \par Then for an arbitrary \textit{Trading Strategy} $H$ we have that
      \[ \expect_\Q[G^*]=\expect_\Q\left[\sum_{n=1}^NH_n\Delta S_n^*\right]=\sum_{n=1}^NH_n\expect_\Q[\Delta S_n^*]=0 \]
      and, in particular
      \[ \sum_{k=1}^KG^*(\omega_k)\Q(\{\omega_k\})=0 \]
      which shows that either $G^*(\omega_k<0)$ for some $k$ or $G^*=0$, but then $\expect_\Q[G^*]=0$.
      \par Hence, by \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_arbitrage_opportunities_and_gains_processes}}, there cannot be any arbitrage opportunities.
    \end{itemize}
    The result holds in both directions.\proved
  \end{proof}

\subsection{Multi-Period Model}

  \begin{definition}{Multi-Period Model}
    The \textit{Single-Period Model} is a model for a financial market where actions can only occur on multiple dates. This provides a more realistic model than the \textit{Single-Period Mdeol}. It has the following components
    \begin{itemize}
      \item \textit{Initial Date} $t=0$.
      \item \textit{Terminal Date} $t=T\in\nats$.
      \item Trading can occur at any times $t\in\{0,1,\dots,T\}$
      \item A finite \textit{Sample Space} $\Omega=\{\omega_1,\dots,\omega_K\}$ with $K<\infty$. Each event $\omega_1,\dots,\omega_K$ corresponds to a state of the world.
      \item A \textit{Probability Space} $\prob$ on $\Omega$ with $\prob(\omega)>0\ \forall\ \omega\in\Omega$.
    \end{itemize}
  \end{definition}

  \begin{definition}{Arbitrage Opportunity - Multi-Period Model}
    An \textit{Arbitrage Opportunity} exists in a multi-period model if there exists a \textit{Trading Strategy} $H$ with the following properties
    \begin{enumerate}
      \item $V_0=0$.
      \item $V_T\geq0$.
      \item $\expect[V_T]>0$.
      \item $H$ is \textit{Self-Financing}.
    \end{enumerate}
  \end{definition}

  \begin{proposition}{Arbitrage Opportunities for Single \& Multi-Period Models}\label{prop_arbitrage_opportunities_for_single_and_multi_period_models}
    If a multi-period model has \underline{no} arbitrage opportunities, then no arbitrage opportunities exist for any of the underlying single-period models.
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_discrete_time_models}.\ref{prop_arbitrage_opportunities_for_single_and_multi_period_models}}}
    For each $t<T$ and for each $A\in\mathcal{P}_t$ there is one underlying single-period model where
    \begin{itemize}
      \item \textit{Initial Time Discounted Price} is $S_n^*(t,\omega)$ for an arbitrary $\omega\in A$ since $S_n^*(t,\omega)$ are constant on $A$.
      \item \textit{Sample Space} contains one state for each cell $A'\in\mathcal{P}_{t+1}$ st $A'\subset A$.
      \item \textit{Terminal Time Discounted Price} is $S_n^*(t+1,\omega)$ for each $n=1,\dots,N$ for some $\omega\in A$.
    \end{itemize}
    If any underlying single-period model has an arbitrage opportunity in the single-period sense, then the multi-period model must have an arbitrage opportunity in the multi-period sense.
    \par To see this, suppose there exists an \textit{Arbitrage Opportunity} $\hat{H}$ for the single period model corresponding to some $A\in\mathcal{P}_t$ for $t<T$. This means that the discounted gain (\ref{eqn_proof_discounted_gain}) is \textit{non-negative} and \underline{not} identical to zero on the event $A$.
    \begin{equation}\label{eqn_proof_discounted_gain}
      \hat{H}_1\Delta S_n^*(t+1)+\dots+\hat{H}_N\Delta S_N^*(t+1)
    \end{equation}
    We now construct a multi-period \textit{Trading Strategy} $H$ which is an \textit{Arbitrage Opportunity}.
    \[ H_n(s,\omega)=\begin{cases}
      0&\text{if }s\leq t\text{ or }\omega\not\in A\\
      \hat{H}_n&\text{if }s=t+1,\ \omega\in A\text{, and }n=1,\dots,N\\
      -\sum_{i=1}^N\hat{H}_iS_i^*(t)&\text{if }s=t+1,\ \omega\in A\text{ and }n=0\\
      \sum_{i=1}^N\hat{H}_1\Delta S_1^*(t+1)&\text{if }s>t+1,\ \omega\in A\text{ and }n=0\\
      0&\text{if }s>t+1,\ \text{ and }n=0\\
    \end{cases} \]
    This strategy starts with zero money and does nothing unless the event $A$ occurs at time $t$, in which case at time $t$ the position $\hat{H}_n$ is taken in the $n^{th}$ risky security while the position in the bank account is used to self-finance.
    \par Subsequently, no position is taken in any of the risky securities, and non-zero value of the portfolio is reflected by a position in the bank account.
    \par THis \textit{Trading Strategy} $H$ is an \textit{Arbitrage Opportunity} in the multi-period model.\proved
  \end{proof}

  \begin{theorem}{Arbitrage Opportunity \& Gains Process}\label{the_arbitrage_opportunity_and_gains_process_multi}
    A \textit{Self-Financing Trading Strategy} $H$ is an \textit{Arbitrage Opportunity} \underline{iff} the following three properties hold
    \begin{enumerate}
      \item $G_T^*\geq0$.
      \item $\expect[G_T^*]>0$.
      \item $V_0=0$.
    \end{enumerate}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_arbitrage_opportunity_and_gains_process_multi}} }

  \end{proof}

\subsubsection{Martingale Measure $\Q$}

  \begin{remark}{Risk-Neutral Probability Measure vs Martingale Measure}
    A martingale measure (\textbf{Definition \ref{sec_discrete_time_models}.\ref{def_martingale_measure}}) is the multi-period version of the risk-neutral probability measure (\textbf{Definition \ref{sec_discrete_time_models}.\ref{def_risk_neutral_probability_measure}}).
  \end{remark}

  \begin{definition}{Martingale Measure}\label{def_martingale_measure}
    A \textit{Martingale Measure} $\Q$ is a probability measure with the following properties:
    \begin{enumerate}
      \item $\forall\ \omega\in\Omega,\ \Q(\{\omega\})>0$.
      \item The \textit{Discounted Price Process} $S^*$ is a \textit{Martingale} under $\Q$
      \[ \forall\ t,s\geq0,\ \expect_\Q\left[\frac{S_n(t+s)}{B_{t+s}}\bigg|F_t\right]=S_n(t) \]
    \end{enumerate}
  \end{definition}

  \begin{theorem}{No-Arbitrage Principle}\label{the_no_arbitrage_principle_multi}
    No \textit{Arbitrage Opportunities} exist in a multi-period model \underline{iff} there exists a \textit{Martingale Measure} $\Q$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_no_arbitrage_principle_multi}}}
    \begin{itemize}
      \item[$\Longleftarrow$] We first show that there can be \underline{no} \textit{Arbitrage Opportunities} provided the existence of a \textit{Martingale Measure} $\Q$.
      \par Suppose $H$ is any \textit{Self-Finacing Trading Strategy} with
      \[ V_T^*\geq0\text{ and }\expect[V_T^*]>0 \]
      This implies
      \[ \expect_\Q[V_T^*]>0 \]
      Since $V^*$ is a \textit{Martingale} under $\Q$ by \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_finance_processes_martingales}}, it follows that
      \[ V_0^*=\expect_\Q[V_T^*]>0 \]
      Hence $H$ cannot be an \textit{Arbitrage Opportunity}, nor can any other trading strategies be \textit{Arbitrage Opportunities} due to $H$ being chosen arbitrarily.

      \item[$\Longrightarrow$\footnote{This could be shown using a version of the \textit{Separating Hyperplane Theorem}, but it is easier to use results from the single-period model.}] Using \texttt{Proposition \ref{sec_discrete_time_models}.\ref{prop_arbitrage_opportunities_for_single_and_multi_period_models}}, we have that for each $t<T$ and each $A\in\mathcal{P}_t$ there is a \textit{risk-neutral probability measure} $\Q(t,A)$ for the underlying single-period model.
      \par This probability measure gives positive mass to each cell $A'\in\mathcal{P}_{t+1}$ st it sums to 1 over all such cells and it satisfies
      \[ \expect_{\Q(t,A)}[\Delta S_n^*(t+1)]=0\text{ for }n=1,\dots,N \]
      Notice that $\Q(t,A)$ puts probability on each branch in the information tree which emerges from the node corresponding to $(t,A)$.
      \par We can calculate a \textit{Martingale Measure} $\Q$ for the multi-period model from these probabilities by setting $\Q(\{\omega\})$ equal to the product of the conditional probabilities along the path from the node at $t=0$ to the node at $(T,\omega)$.
      \par Then
      \begin{itemize}
        \item $\sum_{\omega\in\Omega}\Q(\{\omega\})=1$.
        \item $\Q(\{\omega\})>0$ for every $\omega\in\Omega$ because all the conditional risk neutral probabilities are strictly positive.
        \item And, $\expect_\Q[S_n^*(t+1)|\mathcal{F}_t]=S_n^*(t)$ for all $t$ and $n$.
      \end{itemize}
      Thus $\Q$ is indeed a \textit{Martingale Measure}.\proved
    \end{itemize}
  \end{proof}

  \begin{theorem}{Finance Processes which are Martingales}\label{the_finance_processes_martingales}
    Consider a self-financing trading strategy $H$ and a martingale measure $\Q$.
    \par The following are martingales under $\Q$:
    \begin{enumerate}
      \item Discounted value process $V^*$.
      \item Discounted gains process $G^*$.
    \end{enumerate}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_finance_processes_martingales}}}
    \everymath={\displaystyle}
    We have to show that $\expect_\Q\left[V_{t+1}^*|\mathcal{F}_t\right]=V_t^*\ \forall\ t>0$.
    \par This is equivalent to showing that $\expect_\Q[G_{t+1}^*|\mathcal{F}_t]=G_t^*$ using \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_self_financing_and_value_process}}.
    \par Using the expression for $G_{t+1}^*-G_t^*$ derived in \texttt{Proof \ref{sec_discrete_time_models}.\ref{proof_self_financing_and_value_process}} we can conclude that
    \[\begin{array}{rcl}
      \expect_\Q\left[G_{t+1}^*-G_t^*|\mathcal{F}_t\right]&=&\expect_\Q\left[\sum_{n=1}^NH_n(t+1)\Delta S_n^*(t+1)\bigg|\mathcal{F}_t\right]\\
      &=&\sum_{n=1}^N\expect_\Q\big[\underbrace{H_n(t+1)}_{\in\mathcal{F}_t\footnotemark}\Delta S_n^*(t+1)|\mathcal{F}_t\big]\\
      &=&\sum_{n=1}^NH_n(t+1)\expect_\Q\left[\Delta S_n^*(t+1)|\mathcal{F}_t\right]
    \end{array}\]
    \footnotetext{This is due to $H_n(t+1)$ being the strategy we are building for time-step $t+1$ and thus we use all the information available in time-step $t$.}
    The last result is due to $H_n$ being a \textit{Trading Strategy} and thus \textit{Predictable}.
    \par Furthermore, $\expect_\Q\left[\Delta S_n^*(t+1)|\mathcal{F}_t\right]=$ for all $t>0$ since $S_n^*$ is a under $\Q$.
    \par Hence $G_t^*,V_t^*$ are \textit{Martingales}.\proved
  \end{proof}

\subsection{American Claims}

  \begin{definition}{American Claim $Y_\tau$}
    Let $\{Y_t\}_{t\in T}$ be a payoff process and $\tau$ be a stopping time representing the exercise date of some ``exercise strategy''.
    \par $Y_\tau$ is called an \textit{American Claim} wrt $\{Y_t\}$ and $\tau$.
  \end{definition}

  \begin{definition}{Attainable American Claim}
    An \textit{American Claim} $Y_\tau$ is ``\textit{attainable}'' if
    \begin{center}
      $\exists$ self-financing trading strategy $H$ st $V_\tau=Y_\tau$ when using $H$.
    \end{center}
  \end{definition}

  \begin{theorem}{Complete Markets and American Claims}\label{the_complete_markets_and_american_claims}
    If a financial market is \textit{Complete} then \underline{every} \textit{American Claim} is \textit{Attainable}.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_complete_markets_and_american_claims}}}
    Let $\{Y_t\}_{t\in T}$ be a payoff-process and $\tau$ be an exercise strategy.
    \par  We have to find a self-financing trading strategy $H$ st $V_\tau=Y_\tau$.
    \par Consider the \textit{European Claim} $X=Y_\tau(B_T/B_\tau)$ which corresponds to someone exercising the \textit{American Claim} $Y$ at time-point $t=\tau$ and then earning interest from a bank-account until time-point $T$. Since the model is complete, there must be a replicating trading strategy $H$ st $V_T=X=Y_\tau(B_T/B_\tau)$.
    \par This portfolio which starts at time $\tau$ with the amount of $Y_\tau$ all of which is put into and kept in the bank account until time $T$, has the same value at time $T$ as $H$.
    \par We conclude that $V_\tau=Y_\tau$.\proved
  \end{proof}

  \begin{definition}{Snell Envelope}
    Let $\{X_t\}_{t\in T}$ be a stochastic process adapted to some filtration $\mathcal{F}_t$.
    \par The process $\{Z_t\}_{t\in T}$, defined below, is called the \textit{Snell Envelope} of $X$.
    \[ Z_t=\begin{cases}
      X_T&\text{if }t=T\\
      \max\{X_t,\expect[Z_{t+1}|\mathcal{F}_t]\}&\text{if }t<T
    \end{cases} \]
  \end{definition}

  \begin{theorem}{Snell Envelope is the Smallest Super-Martingale}\label{the_snell_envelope_super_martingale}
    The \textit{Snell Envelope} $\{Z_t\}$ of $X$ is the smallest \textit{Super-Martingale} which dominates $X$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_snell_envelope_super_martingale}}}
    First, $Z_t\geq\expect[Z_{t+1}|\mathcal{F}_t]$ and $Z_t\geq X_t$, so $\{Z_t\}$ is a super-martingale and dominates $X$.
    \par Next, let $\{U_t\}_{t\in T}$ be any other super-martingale which dominates $X$. Since, by definition, $Z_T=X_T$ and $U$ dominates $X$ we must have $U_T\geq Z_T$. Assume inductively that $U_t\geq Z_t$. Then
    \[\begin{array}{rcl}
      U_{t-1}&\geq&\expect[U_t|\mathcal{F}_{t-1}]\text{ since }U_t\text{ is a supermartingale}\\
      &\geq&\expect[Z_t|\mathcal{F}_{t-1}]
    \end{array}\]
    and $U$ dominates $X$
    \[ U_{t-1}\geq X_{t-1} \]
    Combining
    \[ U_{t-1}\geq\max\{X_{t-1}\expect[Z_t|\mathcal{F}_{t-1}] \]
    By repeating this argument we get $U_t\geq Z_t\ \forall\ t$.\proved
  \end{proof}

  \begin{theorem}{Optimal Stopping Theorem}\label{the_optimal_stopping_theorem}
    \textit{This is \underline{NOT} the ``\underline{Optional} Stopping Theorem'' (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_optional_stopping_theorem_martingale}})}.
    \par Let $\{X_t\}_{t\in T}$ be a stochastic process adapted to some \textit{Filtration} $\mathcal{F}_t$ and $Z_t$ be the \textit{Snell Envelope} of $\{X_t\}_{t\in T}$.
    \par For any $t=0,\dots,T$ we define a stopping time by $\tau(t)=\min_{s\geq t}\{Z_s=X_s\}$, then the optimal stopping rule is
    \begin{equation}\label{eq_optimal_stopping_rule}
      Z_t=\expect[X_{\tau(t)}|\mathcal{F}_t]=\max_t\left\{\expect[X_{\tau}|\mathcal{F}_t]:\text{ all stopping times }t\leq\tau\leq T\right\}\text{ for all }t=0,\dots,T
    \end{equation}
    In particular
    \[ Z_0=\expect[X_{\tau(0)}]=\max_t\left\{\expect[X_{\tau)}|\mathcal{F}_t]:\text{ all stopping times }\tau\leq T\right\} \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_optimal_stopping_theorem}}}
    \textit{This proof is a backwards induction through time}.
    \par \underline{Base Case}
    \par Note first that  \texttt{Eq. \ref{eq_optimal_stopping_rule}} is clearly true for $t=T$ because, by definition of the \textit{Snell Envelope}, $Z_T=X_T$ and therefore the stopping time $\tau(T)$ stops at $T$.
    \par \underline{Inducitve Step}
    \par Now assume that \texttt{Eq. \ref{eq_optimal_stopping_rule}} is satisfied for some $t$, we now need to show it holds for $t-1$. Let $\tau$ be an arbitrary stopping time between $t-1$ and $T$.
    \par Define another stopping time $\tau'=\max\{\tau,t\}$\footnote{This is similar to $\tau$ but can never take the value $t-1$.}. Then, since $\tau\geq t\implies\ \tau'=\tau$
    \[\begin{array}{rcl}
      \expect[X_\tau|\mathcal{F}_{t-1}]&=&\expect[\indexed\{\tau=t-1\}X_{t-1}+\indexed\{\tau>t-1\}X_\tau|\mathcal{F}_{t-1}]\\
      &=&\expect[\indexed\{\tau=t-1\}X_{t-1}+\indexed\{\tau>t-1\}X_{\tau'}|\mathcal{F}_{t-1}]\\
      &=&\indexed\{\tau=t-1\}X_{t-1}+\indexed\{\tau>t-1\}\expect[X_{\tau'}|\mathcal{F}_{t-1}]\\
      &=&\indexed\{\tau=t-1\}X_{t-1}+\indexed\{\tau>t-1\}\expect[\expect[X_{\tau'}|\mathcal{F}_t]|\mathcal{F}_{t-1}]\text{ by Tower Law}
    \end{array}\]
    Since $\tau'$ is a stopping time st $\tau'\in[t,T]$, we find that $\expect[X_{\tau'}|\mathcal{F}_t]\leq Z_t$ because we have assumed \texttt{Eq. \ref{eq_optimal_stopping_rule}} holds for $t$.
    \par Using the definition of $Z_{t-1}$ we see that
    \[\begin{array}{rcl}
      \expect[X_\tau|\mathcal{F}_{t-1}]&\leq&\indexed\{\tau=t-1\}X_{t-1}+\indexed\{\tau>t-1\}\expect[Z_t|\mathcal{F}_{t-1}]\\
      &\leq&Z_{t-1}\text{by def. Snell Envelope}
    \end{array}\]
    In the special case where $\tau=\tau(t-1)$ we find that $\tau=(t-1)$ stops in $t-1$ \underline{iff} $Z_{t-1}=X_{t-1}$, otherwise $Z_{t-1}>X_{t-1}$\footnote{As $\{Z_t\}$ dominates $\{X_t\}$.} and $\tau(t-1)=\tau(t)$. Hence
    \[\begin{array}{rcl}
      \expect[X_{\tau(t-1)}|\mathcal{F}_{t-1}]&=&\indexed\{Z_{t-1}=X_{t-1}\}X_{t-1}+\indexed\{Z_{t-1}>X_{t-1}\}\expect[\expect[X_{\tau(t)}|\mathcal{F}_t]|\mathcal{F}_{t-1}]\\
      &=&\indexed\{Z_{t-1}=X_{t-1}\}X_{t-1}+\indexed\{Z_{t-1}>X_{t-1}\}\expect[Z_t|\mathcal{F}_{t-1}]\\
      &=&Z_{t-1}\text{ by def. Snell Envelope}
    \end{array}\]
  \end{proof}

  \begin{proposition}{Snell Envelope as Discounted Value Process}\label{prop_snell_envelope_as_discounted_value_process}
    Consider a financial market with a \textit{Martingale Measure} $\Q$ and an attainable \textit{American Payoff Process} $\{Y_t\}$.
    \par Then the \textit{Snell Envelope} $\{Z_t\}_t$ of the discounted payoff process $\{Y_t/B_t\}_t$ is the discounted value process for $Y$.
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_discrete_time_models}.\ref{prop_snell_envelope_as_discounted_value_process}}}
    % Prop 3.22
    \textit{This proof uses the Optimal Stopping Theorem (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_optimal_stopping_theorem}})}.
    \par Let $p$ denote the time $t$ price of the American claim wrt the payoff process $(Y_t/B_t)$.
    \par Suppose, first, that $p<Z_t$ then:
    \begin{itemize}
      \item We buy the option for $p$.
      \item If $\tau(t)=t$\footnote{This is unlikely as the arbitrage opportunity is obvious.} then $Z_t=Y_t/B_t$ and so we can exercise the option immediately for $(Y_t/B_t)>p$ to make a riskless profit.
      \item If $\tau(t)>t$ we undertake the negative of the trading strategy that replicates $Y_{\tau(t)}/B_{\tau(t)}$, as we want to short sell. The price of the replicating strategy is $\expect_Q[Y_{\tau(t)}/B_{\tau(t)}|\mathcal{F}_t]$ by the \textit{Risk-Netural Valuation Principle} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_risk_neutral_valuation_principle}}), but by the \textit{Optimal Stopping Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_optimal_stopping_theorem}}) this is equal to $Z_t$ and so we can invest the different $Z_t-p$ in the bank account.
      \item Later at time $\tau(t)$ we exercise the option and liquidate the replicating portfolio at the same time. The amount we collect from the option seller is equal to our liability on the portfolio\footnote{Meaning the cash flow at this time-period is net 0}. Meanwhile, we have $(Z_t-p)\cdot(B_{\tau(t)}/B_t)>0$ in the bank account.
    \end{itemize}
    This shows that we make a riskless profit in any case.

    \par Now consider the case where $p>Z_t$ then
    \begin{itemize}
      \item We sell the option for $p$.
    \end{itemize}
    Consider in detail the case where $\tau(t)>t$. Then
    \begin{itemize}
      \item We undertake the trading strategy that replicates $Y_{\tau(t)}/B_{\tau(t)}$. Again we find by using \textit{Risk-Netural Valuation Principle} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_risk_neutral_valuation_principle}}) and the \textit{Optimal Stopping Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_optimal_stopping_theorem}}) that the price of building up the portfolio is
      \[ Z_t=\expect_\Q[Y_{\tau(t)/B_{\tau(t)}}|\mathcal{F}_t] \]
      \item Therefore there is a profit of $p-Z_t$ which we put in the bank account.
    \end{itemize}
    How we proceed will depend on when the buyer exercises the option.
    \begin{enumerate}
      \item If the buyer exercises the option at time-point $s\leq\tau(t)$ then
      \begin{itemize}
        \item We pay the buyer the payoff $Y_s/B_s$.
        \item We liquidate our portfolio and using risk-neutral valuation the value of our portfolio at time-point $s$ is
        \[ \expect_\Q[Y_{\tau(t)}/B_{\tau(t)}|\mathcal{F}_s] \]
        Since $s\in[t,\tau(t)]$ we see from the definition of $\tau(t)$ that $\tau(t)=\tau(s)$.
        \par Using this and the \textit{Optimal Stopping Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_optimal_stopping_theorem}}) that the value of our portfolio at time $s$ is
        \[ \expect_\Q[Y_{\tau(t)}/B_{\tau(t)}|\mathcal{F}_s]=\expect_\Q[Y_{\tau(s)}/B_{\tau(s)}|\mathcal{F}_s]=Z_s\geq (Y_s/B_s) \]
        \item Therefore all transaction at time-point $s$ will only add to our portfolio and our total profit is strictly positive.
      \end{itemize}
      \item If the buyer does not exercise by time $s=\tau(t)$ where $\tau(t)<T$ then:
      \begin{itemize}
        \item We repeat the process, undertaking the trading strategy that replicates $Y_{\tau(s+1)}/B_{\tau(s+1)}$.
        \item The value of the portfolio to be built up is equal to
        \[ \expect_\Q[Y_{\tau(s+1)}/B_{\tau(s+1)}|\mathcal{F}_s]\leq\expect_\Q[Y_{\tau(s)}/B_{\tau(s)}|\mathcal{F}_s]=Z_s \]
        Therefore the change of the portfolio will only pay us some money which we put in the bank account.
        \item As before, if the option buyer exercises at some time $u\leq\tau(s+1)$ then the value of the portfolio will be enough to cover the payoff $Y_u$.
      \end{itemize}
      \item If the buyer has not exercised by time $\tau(s+1)$ then we repeat this process again, and so forth. There will always be enough money in the portfolio to cover the payoff. Our overall profit will be at least $p-Z_t>0$/
    \end{enumerate}
    Finally, we consider the case where $\tau(t)$. Then the optimal strategy would be to exercise the option immediately.
    \begin{itemize}
      \item If the buyer indeed exercises at time $t$, then we pay them $(Y_t/B_t)=Z_t<p$ and make a riskless-profit.
      \item If note, then we proceed as in the previous case where the buyer does not exercise by the optimal stopping time and undertake the trading strategy which replicates $(Y_{\tau(t+1)}/B_{\tau(t+1)})$ and so forth making again profit of at least $p-Z_t$.
    \end{itemize}
    \proved
  \end{proof}

\subsection{Contingent Claims $X$}

  \begin{definition}{Contingent Claim $X$}
    A \textit{Contingent Claim} $X\in\reals^N$ is the final payoff of a model with $N-1$ risky securities.
  \end{definition}

  \begin{definition}{Attainable Contingent Claim $X$}
    A \textit{Contingent Claim} $X$ is said to be ``\textit{attainable}'' if
    \begin{center}
      $\exists$ (self-financing, admissible\footnote{Depends on model}) trading strategy $H$ st $\forall\ \omega\in\Omega,\ V_T(\omega)=X(\omega)$ when using $H$.
    \end{center}
    If such a strategy $H$ exists, it is called a \textit{Replicating Portfolio} and is said to ``\textit{generate}'' $X$.
  \end{definition}

  \begin{remark}{Computing a Replicating Portfolio $H$}
    Our approach depends on what information we are provided.
    \begin{itemize}
      \item If we known the contingent claim $X$ \underline{and} the \textit{Value Process} $V$ for the replicating portfolio, we need to solve for the trading strategy $H$ using the linear equations in the definition of the value process (keeping in mind that $H$ is \textit{Predictable}).
      \[ V_t(\omega_i)=H_0(t)B_t+\sum_{n=1}^NH_n(t)S_n(t)(\omega_i)\ \forall\ \omega_i\in\Omega \]

      \item If we \underline{only} know the \textit{Contingent Claim} $X$ we need to work backwards in time, deriving $V$ and $H$ simultaneously.
      \par Since $V_T=X$ we must first solve the following for $H(T)$.
      \[ X(\omega_i)=H_0(T)B)T+\sum_{n=1}^NH_n(T)S_n(T)(\omega_i) \]
      Since $H$ is self-financing, we can calculate $V_{T-1}$.
      \[ V_{T-1}=H_0(T)B_{T-1}+\sum_{n=1}^NH_n(T)S_n(T-1)(\omega_i) \]
      Therefore, our next step is to solve the following for $H(T_1)$.
      \[ V_{T-1}=H_0(T_1)B_{T-1}+\sum_{n=1}^NH_n(T-1)S_n(T-1)(\omega_i) \]
      We can now continue by calculating $V_{T-2}$ etc. until we end up with $V_0$.
    \end{itemize}
  \end{remark}

  \begin{remark}{Determining whether a Contingent Claim $X$ is Attainable}
    Consider a \textit{Single-Period Model} with $K-1$ securities, which can be described the following matrix $A$, and a \textit{Contingent Claim} $X\in\reals^K$. Then
    \begin{quote}
      $X$ is \textit{Attainable} iff $\exists$ a trading strategy $H\in\reals^K$ st $AH=X$ where
      \[ A:=\begin{pmatrix}
          B_1(\omega_1)&S_1(1)(\omega_1)&\dots&S_N(1)(\omega_1)\\
          B_1(\omega_2)&S_1(1)(\omega_2)&\dots&S_N(1)(\omega_2)\\
          \vdots&\vdots&\ddots&\vdots\\
          B_1(\omega_K)&S_1(1)(\omega_K)&\dots&S_N(1)(\omega_K)
      \end{pmatrix} \]
    \end{quote}
  \end{remark}

  \begin{theorem}{Fair Price of a Contingent Claim}\label{the_fair_price_of_a_contingent_claim}
    Let $X$ be an \textit{Attainable Contingent Claim} and $H$ be a \textit{Replicating Portfolio} which generates $X$.
    \begin{quote}
      \text{The value of portfolio $H$ at time $t=0$ ($V_0$) is the ``fair-price'' of the contingent claim $X$.}
    \end{quote}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_fair_price_of_a_contingent_claim}}}
    Let $X$ be an \textit{Attainable Contingent Claim} and $H$ be a \textit{Replicating Portfolio} which generates $X$.
    \par Let $p$ be the fair price for $X$ and assume, for the sake of contradiction, that $p$ does \underline{not} equal the value of $H$ at time $t=0$. This means we assuming that $p\neq V_0$.
    \par We have two cases
    \begin{itemize}
      \item[Case 1] - $p>V_0$.
      \par In this case, an \textit{arbitrage opportunity} exists and can be exploited by doing the following
      \begin{itemize}
        \item At $t=0$ - Short the \textit{Contingent Claim} for $p$; buy portfolio $H$ for $V_0$; and invest the difference $p-V_0>0$.
        \item At $t=1$ - Our portfolio has the same value as $X$ so we sell $H$ to fulfil our short position on the contingent claim.
      \end{itemize}
      Our profit in this scenario is $(p-V_0)B_1=(p-V_0)(1+r)>0$.
      \item[Case 2] - $p<V_0$.
      \par In this case, an \textit{arbitrage opportunity} exists and can be exploited by doing the following
      \begin{itemize}
        \item At $t=0$ - Buy the \textit{Contingent Claim} for $p$; buy portfolio $-H$\footnote{Note this is equivalent to shorting portfolio $H$} for $-V_0$; and invest the difference $V_0-p>0$.
        \item At $t=1$ - Our portfolio has value $-X$ so we sell our \textit{Contingent Claim} for $X$ to cover the portfolio, fulfilling any short positions.
      \end{itemize}
      Our profit in this scenario is $(V_0-p)B_1=(V_0-p)(1+r)>0$.
    \end{itemize}
    Hence, in all scenarios where $p\neq V_0$ an arbitrage opportunity exists.
    This means $p\neq V_0$ cannot be the fair price for $X$ and thus $p=V_0$ is the fair price.\proved
  \end{proof}

  \begin{theorem}{Risk-Neutral Valuation Principle}\label{the_risk_neutral_valuation_principle}
    The \textit{Risk-Neutral Valuation Principle} gives the fair-price of an attainable contingent claim $X$ at each time-period for models where \underline{no} arbitrage opportunities exist. The principle is different under different models
    \begin{itemize}
      \item[Single-Period] The fair-price is $p=\expect_\Q[X/B_1]$ where $\Q$ is a risk-neutral probability measure.
      \item[Multi-Period] The fair-price at time $t$ is the time $t$ value $V_t$ of the portfolio which replicates $X$. Moreover,
      \[ V_t^*=\expect_\Q[X/B_T|\mathcal{F}_t] \]
      where $\Q$ is a martingale measure.
      \item[Continuous] The fair-price at time $t$ is the time $t$ value $V_t$ of the portfolio which replicates $X$. Moreover,
      \[ V_t^*=\expect_\Q[X/B_T|\mathcal{F}_t] \]
      where $\Q$ is an equivalent-martingale measure. At time $t=0$, the value is
      \[ \pi_0=V_0=\expect_\Q[X/B_T] \]
    \end{itemize}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_risk_neutral_valuation_principle}} - Single-Period Models}\label{prf_risk_neutral_valuation_principle_single_period}
    \par Consider a \textit{Single-Period Model} with \underline{no} arbitrage opportunities and let $X$ be an \textit{Attainable Contingent Claim} under this model.
    \par Here we derive the fair-price for $X$ and show that time price is unique.
    \par Suppose there exists two trading strategies $H,\hat{H}$ st $V_1=\hat{V}_1=X$ but $\hat{V}_0\neq V_0$.
    \par Let $\Q$ be a \textit{Risk-Neutral Probability Measure} under this model. Then, by the \textit{No-Arbitrage Principle} (\texttt{Theorem \ref{sec_financial_terminology}.\ref{the_no_arbitrage_theorem}}), we have that for any trading strategy $H$ $\expect_\Q[G^*]=0$. Thus we can deduce that
    \[\begin{array}{rcl}
      V_0&=&V_0^*\\
      &=&\expect_\Q[V_0^*]\\
      &=&\expect_\Q[V_1^*-G^*]\\
      &=&\expect_\Q[V_1^*]-\expect_\Q[G^*]\\
      &=&\expect_\Q[V_1^*]-0\\
      &=&\expect_\Q[V_1/B_1]
    \end{array}\]
    This shows that any trading strategy $H$ with $V_1=X$ (ie is worth $X$ at time $t=1$), has the following value at time $t=0$
    \[ V_0=\expect_\Q[V_1/B_1]=\expect_\Q[X/B_1] \]
    This holds for all \textit{Risk-Neutral Probability Measures} $\Q$, so the fair-price for $X$ at time $t=0$ is constant between different \textit{Risk-Neutral Probability Measures}. Further, all trading strategies with the same value at time $t=1$ have the same value at time $t=0$ (and we have a formula for this value).\proved
  \end{proof}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_risk_neutral_valuation_principle}} - Multi-Period Models}\label{prf_risk_neutral_valuation_principle_multi_period}
    Let $P_t$ denote the actual price of the \textit{Contingent Claim} at time point $t$.
    \par By \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_equivalent_contract_valuations_over_time}}, $P_t=V_t$ is the only possibility to avoid arbitrage opportunities.
    \par Now, let $\Q$ be an arbitrary \textit{Martingale Measure} then for every $t<T$ we have that
    \[ V_t^*:=\expect_\Q[V_t^*|\mathcal{F}_t] \]
    as $V_t^*$ is a \textit{Martingale} by \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_finance_processes_martingales}}.
    \par Moreover, since $V_T^*$ is the discounted value of the portfolio which replicated $X$ we have that
    \[ \expect_\Q[V_T^*|\mathcal{F}_t]=\expect_\Q[X/B_T|\mathcal{F}_t] \]
    Thus $V_t^*=\expect_\Q[X/B_T|\mathcal{F}_t]$ independent of the choice of \textit{Martingale Measure} $\Q$.\proved
  \end{proof}

\subsection{Complete Markets}

  \begin{definition}{Complete \& Incomplete Markets}
    A model of a market is said to be \textit{Complete} if each \textit{Contingent Claim} $X$ there exists a \textit{Trading Strategy} $H$ which generates $X$.
    \par Otherwise, the model is said to be \underline{in}\textit{complete}.
  \end{definition}

  \begin{remark}{Checking if a Market is Complete}
    We can check whether the model of a market is \textit{Complete} by defining the following matrix $A$, and if $A$ spans the same space as \textit{Contigent Claims}\footnote{This is done by determining whether $\text{rank}(A)=\text{dim}(X)$.} then the market \underline{is} \textit{Complete}.
    \[ A=\begin{pmatrix}
        B_1(\omega_1)&S_1(1)(\omega_1)&\dots&S_N(1)(\omega_1)\\
        B_1(\omega_2)&S_1(1)(\omega_2)&\dots&S_N(1)(\omega_2)\\
        \vdots&\vdots&\ddots&\vdots\\
        B_1(\omega_K)&S_1(1)(\omega_K)&\dots&S_N(1)(\omega_K)
    \end{pmatrix} \]
  \end{remark}

  \begin{theorem}{Complete Markets and $\Q$}\label{the_complete_markets_and_risk_neutral_probability_measure}
    Consider a model with \underline{no} \textit{Arbitrage Opportunities}, then
    \begin{quote}
      The model is \textit{Complete} \underline{iff} $\exists$ a \underline{unique} \textit{Risk-Neutral Probability Measure} (or \textit{Martingale Measure}) $\Q$.
    \end{quote}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_complete_markets_and_risk_neutral_probability_measure}} - Single-Period Model}
    \everymath={\displaystyle}
    Consider a \textit{Single-Period Model} with \underline{no} \textit{Arbitrage Opportunities} and let $\mathbb{M}$ denote the set of all \textit{Risk-Neutral Probability Measures} for this model.
    \par Since there are \underline{no} arbitrage opportunities then $\mathbb{M}\neq\emptyset$.
    \par As this theorem is ``iff'' I shall prove it in both directions separately
    \begin{itemize}
      \item[$\Longrightarrow$] Assume, for the sake of contraction, that the model \underline{is} \textit{Complete} but $\mathbb{M}=\{\Q,\hat\Q\}$  (ie contains two distinct elements).
      \par Then $\exists\ \omega_k\in\Omega$ st $\Q(\omega_k)\neq\hat\Q(\omega_k)$. Consider the following \textit{Contingent Claim} $X$
      \[\begin{array}{rcl}
      X(\omega)&=&\begin{cases} B_1(\omega)&\text{if }\omega=\omega_k\\0&\text{otherwise}\end{cases}\\
      &=&B_1\indexed\{\omega=\omega_k\}
      \end{array}\]
      Then
      \[\begin{array}{rcl}
        \expect_\Q[V_0]=\expect_\Q[X/B_1]&=&\expect_\Q[\indexed\{\omega=\omega_k\}]\\
        &=&\Q(\{\omega_k\}))\\
        &\neq&\Q(\{\omega_k\})\text{ by def. }X\\
        &=&\expect_{\hat\Q}[\indexed\{\omega=\omega_k\}]\\
        &=&\expect_{\hat\Q}[X/B_1]=\expect_{\hat\Q}[V_0]\\
        \implies\ \expect_\Q[V_0]&\neq&\expect_{\hat\Q}[V_0]
      \end{array}\]
      This contradicts \texttt{Proof \ref{sec_discrete_time_models}.\ref{prf_risk_neutral_valuation_principle_single_period}}  when we showed that if $X$ is attainable then $\expect_\Q[V_0]$ is the same for all $\Q\in\mathbb{M}$.
      \par Thus, if the model is \textit{Complete} then it has a unique \textit{Risk-Neutral Probability Measure}.
      \item[$\Longleftarrow$] Assume, for the sake of contradiction, that the model has a unique \textit{Risk-Neutral Probability Measure} $\hat\Q$ but there exists a \textit{Contingent Claim} $X$ which is \underline{not} \textit{Attainable}.
      \par Then, there does not exist a trading strategy $H$ which solves $AH=X$.
      \par By the \textit{Separating Hyperplane Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_separating_hyperplane_theorem}}) it follows that
      \[ \exists\ \pi\in\reals^K\text{ st }\pi^TA=0\footnotemark\text{ and }\pi^TX>0 \]
      \footnotetext{ie $\pi$ is orthogonal to $A$.}
      Let $\lambda>0$ be small enough that
      \[ \Q(\{\omega_j\}):=\hat\Q(\{\omega_j\})+\lambda\pi_j\cdot B_1(\omega_j)>0\quad\forall\ j\in[1,K] \]
      As $A$ is defined st all the terms in its first column are $B_1$ and $\pi^TA=0$, the $\Q$ defined above is a probability measure.
      \par Moreover, for any \textit{Discounted Price Process} $s^*=(S_1^*,\dots,S_N^*)$ and any $n\in[1,N]$ we have
      \[\begin{array}{rcl}
        \expect_\Q[S_n^*(1)]&=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\Q(\{\omega_j\})\\
        &=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\left(\hat\Q(\{\omega_j\})+\lambda\pi_jB_1(\omega_j)\right)\\
        &=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\hat\Q(\{\omega_j\})+\underbrace{\lambda\sum_{j=1}^K\pi_jS_n(1)(\omega_j)}_{=0}\\
        &=&\sum_{j=1}^K\frac{S_n(1)(\omega_j)}{B_1(\omega_j)}\cdot\hat\Q(\{\omega_j\})\\
        &=&\sum_{j=1}^KS_n^*(1)(\omega_j)\hat\Q(\{\omega_j\})\\
        &=&\expect_{\hat\Q}[S_n^*(1)]\\
        &=&S_n^*[0]\footnotemark
      \end{array}\]
      \footnotetext{As $\hat\Q$ is a \textit{Risk-Neutral Probability Measure}.}
      This shows that $\Q$ is a \textit{Risk-Neutral Probability Measure} and so $\Q\in\mathbb{M}$, a contradiction to the uniqueness of $\hat\Q$.
      \par If there is a unique \textit{Risk-Neutral Probability Measure} for a model, then all \textit{Contingent Claims} are attainable under the model.
    \end{itemize}
    This has proved the theorem in both directions.\proved
  \end{proof}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_complete_markets_and_risk_neutral_probability_measure}} - Multi-Period Model}
    \begin{itemize}
      \item If the multi-period model is complete, for any claim $X$ we can work backwards in time to compute the trading strategy that generates $X$. Hence, for each underlying single-period model the matrix $A$ must have independent columns and the model is complete.
      \item Conversely, if every underlying single-period model is complete then the computational procedure for the multi-period model succeeds.
    \end{itemize}
    Therefore, completeness of the multi-period model is equivalent to completeness of all underlying single-period models.
    \par In particular the multi-period model is complete \underline{iff} each underlying model has a unique risk-neutral probability measure.
    \par On the other hand, uniqueness of the martingale measure $\Q$ is equivalent to uniqueness of the risk-neutral probability measures of the underlying single-period models.
    \par Obviously, the existence of several risk-neutral probability measures for a single-period model leads to several multi-period martingale measures.
    \par However, assume there are two multi-period martingale measures. Then the conditional probability must be different for at least one specific single-period model.\proved
  \end{proof}

\subsection{Cox-Ross-Rubinstein Model}

  \begin{definition}{Cox-Ross-Rubinstein Model}
    The \textit{Cox-Ross-Rubinstein Model} is the special case of a multi-period model, defined by the following properties.
    \begin{enumerate}
      \item Risk-free constant interest rate $r$.
      \item A single risk security.
      \item Only two events can occur:
      \begin{enumerate}
        \item The price increases by a factor of $u$ with probability $p$. \text{($S_{t+1}=uS_t$ with $u>1$).}
        \item The price decreases by a factor of $d$ with probability $1-p$. \text{($S_{t+1}=dS_t$ with $d<1$).}
      \end{enumerate}
      \item Price process $S_t:=S_0u^{N_t}d^{t-N_t}$ where $S_0$ is the initial price and $\{N_t\}_{t\in\nats}$ is a random walk process with parameter $p$
    \end{enumerate}
    Note $S_0,p,u,d\in\reals^{\geq0}$ and $0<d<1<u$.
  \end{definition}

  \begin{theorem}{Arbitrage in Cox-Ross-Rubinstein Model}\label{the_arbitrage_in_cox_ross_rubinstein_model}
    The \textit{Cox-Ross-Rubinstein Model} has no arbitrage opportunities \underline{iff} $d<1+r<u$.
  \end{theorem}

  \begin{remark}{Cox-Ross-Rubinstein Model without Arbitrage Opportunities}
    If the Cox-Ross-Rubinstein Model has no arbitrage opportunities then the model is complete and the unique \textit{Martingale Measure} $\Q$ is defined by
    \[ \Q(\{\omega\})=q^n(1-q)^{T-n}\text{ where }q=\frac{1+r-d}{u-d} \]
    where $\omega\in\Omega$ is a state which corresponds to $n$ up-steps and $(T-n)$ down-steps.
    \par In particular, adding all contributions from states with exactly $n$ up-steps and $(T-n)$ down-steps we get
    \[ \Q\left(S_t=S_0u^nd^{T-n}\right)={t \choose n}q^n(1-q)^{t-n}\text{ for }n=0,\dots,t \]
    Moreover, if $X$ is a \textit{Contingent Claim} of the form $X=g(S_T)$ for some real-valued function $g$, then the time $t=0$ value of $X$ is given by
    \[ V_0=\frac1{(1+r)^T}\sum_{n=0}^T{T\choose n}q^n(1-q)^{T-n}g(S_0u^nd^{T-n}) \]
    More generally, the value of contingent claim $X$ at time-point $t$ is
    \[ \Pi_t=\frac1{(1+r)^{T-t}}\sum_{n=0}^{T-t}{T-t\choose n}q^n(1-q)^{T-t-n}g(S_tU^nd^{T-t-n}) \]
  \end{remark}

  \begin{proof}{\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_arbitrage_in_cox_ross_rubinstein_model}}}
    The \textit{No-Arbitrage Theorem} (\texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_no_arbitrage_theorem}}) shows the \textit{Cox-Ross-Rubinstein Model} is free of arbitrage \underline{iff} there is a \textit{Martingale Measure} $\Q$ with
    \[ S_t=\frac1{1+r}\expect_\Q[S_{t+1}|\mathcal{F}_t]\ \forall\ t<T \]
    Let $q:=\Q(X_{t+1}=1)=\Q(S_{t+1}/S_t=u)$ which means that $\Q(S_{t+1}/S_t=d)=1-q$.
    \par $S_t$ is known at time-point $t$, so we can put it inside the conditional expectation wrt $\mathcal{F}_t$ in the expression for $S_t$ above. This means we can divide by $S_t$ and get
    \[ 1=\frac1{1+r}\expect_\Q\left[S_{t+1}/S_t|\mathcal{F}_t\right]=\frac1{1+r}\big(uq+d(1-q)\big) \]
    By rearranging, we see the \textit{No-Arbitrage Principle} is satisfied \underline{iff} $qu+(1-q)d=1+r$. Thus
    \[ q=\frac{1+r-d}{u-d} \]
    By its definition, $\Q$ must be positive everywhere meaning $q\in(0,1)$. Equivalently $d<1+r<u$ must be satisfied.
    \par We can now state the form of the \textit{Martingale Measure} $\Q$ by multiplying the conditional probabilities along the paths that lead to each state $\omega_i$. This is made easier since the \textit{Cox-Ross-Rubinstein Model} assumes that the probability of each movement is constant at all time-period.
    \par By the uniqueness of $q$ we can determine that the \textit{Cox-Ross-Rubinstein Model} is complete.
    \par The expression for $\Q\left(S_t=S_0u^nd^{T-n}\right)$ is straightforward.
    \par The time $t=0$ value of the contingent claim $X$ is calculated as the expectation wrt $\Q$.
    \par We think of $\Pi(t)$ as a time-shifted version of the formula for the time $t=0$ price\footnote{Effectively assume that the model starts at time $t$ and runs for $T-t$ steps.}, replacing $T$ by $(T-t)$ and $S_0$ by $S_t$.\proved
  \end{proof}

  \begin{proposition}{Value of European Call Option in Cox-Ross-Rubinstein Model}\label{prop_european_call_crr_model}
    Consider a \textit{Cox-Ross-Rubinstein Model} with $T$ periods, starting price $S_0$, interest rate $r$ and parameters $d,u$.
    \par Then the time $t$ price of a \textit{European Call Option} with exercise price $K$ is
    \[ \Pi_K(t)=\frac1{(1+r)^{T-t}}\sum_{n=0}^{T-t}{{(T-t)}\choose n}q^n(1-q)^{T-t-n}\left\{S_0u^nd^{T-t-n}-K\right\}_+ \]
    where $q=\frac{1+r-d}{u-d}$ as usual.
  \end{proposition}

\subsubsection{Black-Scholes Formula}

  \begin{theorem}{Black-Scholes Formula}\label{the_black_scholes_formula}
    Consider a \textit{European Call Option} with exercise price $K$ and matures at time $U$.
    \par Let $\Pi_K^{(t)}(0)$ denote its fair-price in a \textit{Cox-Ross-Rubinstein Model} with $T+1$ time-points $\left\{0,\frac{U}T,\dots,U\right\}$, constant interest rate $r_T=e^{-\frac{rU}T}-1$ and $u_T=e^{\sigma\sqrt{U/T}}=\frac1{d_T}$. Then
    \[ \lim_{T\to\infty}\Pi_K^{(T)}(0)=\Pi_K^{BS}(0) \]
    where
    \[\begin{array}{rrcl}
      &\Pi_K^{BS}(0)&=&S_0\Phi\big(d_1(S_0,U)\big)-Ke^{-rU}\big(d_2(S_0,U)\big)\\
      \text{with}\\
      &d_1(s,u)&=&\dfrac{\ln(s/K)+\left(r+(\sigma^2/2)\right)U}{\sigma\sqrt{U}}\\
      &d_2(s,u)&=&\dfrac{\ln(s/K)+\left(r-(\sigma^2/2)\right)U}{\sigma\sqrt{U}}
    \end{array}\]
    $\Phi$ is the CDF of the standard Normal distribution.
  \end{theorem}

  \begin{proof}{\texttt{Theorem  \ref{sec_discrete_time_models}.\ref{the_black_scholes_formula}}}
    \everymath={\displaystyle}
    Let $\alpha_T:=\min\left\{n:S_0u_T^nd_T^{T-n}>l\right\}$. This allows us to consider only terms in \texttt{Proposition \ref{sec_discrete_time_models}.\ref{prop_european_call_crr_model}} which are positive.
    \par We rewrite the time $t=0$ price $\Pi_K^{(T)}(0)$ in the $T^{th}$ \textit{Cox--Ross-Rubinstein Model} as
    \[\begin{array}{rcll}
      \Pi_K^{(T)}(0)&=&(1+r_T)^{-T}\sum_{n=\alpha_T}^T{T \choose n}q_T^n(1-q_T)^{T-n}(S_0u_T^nd_T^{T-n}-K)\\
      &=&S_0\left(\sum_{n=\alpha_T}^T{T\choose n}\left(\frac{q_Tu_T}{1+r_T}\right)^n\left(\frac{(1-q_T)d_T}{1+r_T}\right)^{T-n}\right)\\
      &-&(1+r_T)^{-T}K\left(\sum_{n=\alpha_T}^T{T\choose n}q_T^n(1-q_T)^{T-n}\right)&\quad[1]
    \end{array}\]
    We can identify terms involved in the second sum as the density of a $\text{Bin}(T,q_T)$ distribution.
    \par For notational ease we define
    \[ \hat{q}_T=\frac{q_Tu_T}{1+r_T} \]
    This $\hat{q}_T$ is a probability\footnote{ie $\hat{q}_T\in(0,1)$} because
    \[\begin{array}{rcl}
      0<\hat{q}_T\\
      &=&\frac{q_Tu_T}{1+r_T}\\
      &=&\frac{\left(\frac{1+r_T-d_T}{u_T-d_T}\right)\cdot u_T}{q+r_T}\\
      &=&\frac{u_T-\frac{d_Tu_T}{1+r_T}}{u_T-d_T}\\
      &<&\frac{u_T-\frac{d_Tu_T}{u_T}}{u_T-d_T}\text{ since }u_T>1+r_T\\
      &=&1
    \end{array}\]
    Moreover, we see from the definition of $q_T$ that
    \[\begin{array}{rcl}
      1-\hat{q}_T&=&\frac{1+r_T-q_Tu_T}{1+r_T}\\
      &=&\frac{1+r_T-(1+r_T-d_T)-q_Td_T}{1+r_T}\\
      &=&\frac{(1-q_T)d_T}{1+r_T}
    \end{array}\]
    Thus we identify the first sum in $[1]$ as the density of $Bin(T,\hat{q}_T)$ distribution.
    \par Now, let $Y_T\sim\text{Bin}(T,q_T)$ and $\hat{Y}_T\sim\text{Bin}(T,\hat{q}_T)$. We can rewrite $[1]$ as
    \[ \Pi_K^{(T)}(0)=S_0\prob\left(\hat{Y}>d_T-1\right)-K(1+r_T)^{-T}\prob(Y_T>d_T-1) \]
    Thus we need to show that
    \begin{enumerate}
      \item $\lim_{T\to\infty}\prob\left(\hat{Y}_T>\alpha_T-1\right)=\Phi\left(d_1(S_0,U)\right)$.\proof{This result is not proved in detail}
      \item $\lim_{T\to\infty}\prob\left(Y_T>\alpha_T-1\right)=\Phi\left(d_2(S_0,U)\right)$.
    \end{enumerate}
    Consider ii) first
    \[ \prob(Y_T>\alpha_T-1)=\prob\left(\frac{Y_T-Tq_t}{\sqrt{Tq_T(1-q_T)}}>\frac{d_T-1-Tq_T}{\sqrt{Tq_T(1-q_T)}}\right) \]
    We want to use \texttt{Theorem \ref{sec_probability}.\ref{the_binomial_distribution_and_standard_normal}} and therefore determine the convergence of the term $\frac{\alpha_T-1-Tq_T}{\sqrt{Tq_T(1-q_T)}}$.
    \par Note that we defined
    \[ u_T:=\exp\{\sigma\sqrt{U/T}\}=1/d_T\quad\text{and}\quad r_T=\exp\{rU/T\}-1 \]
    \par Using a \textit{Taylor Decomposition} we see that
    \[\begin{array}{rcl}
      q_T&=&\frac{1+r_T-d_T}{u_T-d_T}\\
      &=&\frac{\exp\{rU/T\}-e^{-\sqrt{U/T}}}{e^{\sigma\sqrt{U/T}}-e^{-\sigma\sqrt{U/T}}}\\
      &=&\frac{\{1+(rU/T)+o(1/T)\}  +\{-1\sigma\sqrt{U/T}-\frac12\sigma^2(U/T)-o(1/T)\}}{\{1+(\sigma\sqrt{U/T})+\frac12\sigma^2(U/T)+o(1/T)\}+\{-1+\sigma\sqrt{U/T}-\frac12\sigma^2(U/T)-o(1/T)\}}\\
      &=&\frac{(rU/T)+\sigma\sqrt{U/T}-\frac12\sigma^2(U/T)+o(1/T)}{2\sigma\sqrt{U/T}+o(1/T)}\\
      &=&\frac12\left\{\frac{r(U/T)}{\sigma\sqrt{U/T}}+\frac{\sigma\sqrt{U/T}}{\sigma\sqrt{U/T}}-\frac{(1/2)\sigma^2(U/T)}{\sigma\sqrt{U/T}}\right\}+o(1/\sqrt{T})\\
      &=&\frac12\left(\left(\frac{r}\sigma-\frac\sigma2\right)\sqrt{U/T}+1\right)+o(1/\sqrt{T})
    \end{array}\]
    Thus we obtain the limiting relations
    \[ \lim_{T\to\infty}q_T=\frac12\text{ and }\lim_{T\to\infty}(1-2q_T)\sqrt{UT}=-U\left(\frac{r}{\sigma}-\frac\sigma2\right) \]
    Finally, we see from the definition of $\alpha_T$ that for some $|\gamma_T|<1$
    \[\begin{array}{rcl}
      \alpha_T&=&\frac{\ln(K/S_0d_T^T)}{\ln(u_T/d_T)}+\gamma_T\\
      &=&\frac{\ln(k/S_0)-T\ln(d_T)}{\ln(u_T^2)}+\gamma_T\\
      &=&\frac{\ln(K/S_0)+T\sigma\sqrt{U/T}}{2\sigma\sqrt{U/T}}+\gamma_T
    \end{array}\]
    Hence
    \[\begin{array}{rl}
      &\lim_{T\to\infty}\frac{\alpha_T-1-Tq_T}{\sqrt{Tq_T(1-q_T)}}\\
      =&\lim_{T\to\infty}\frac{\left(\frac{\ln(K/S_0)+T\sigma\sqrt{U/T}}{2\sigma\sqrt{U/T}}+\gamma_T\right)-1-Tq_T}{\sqrt{Tq_T(1-q_T)}}\\
      =&\lim_{T\to\infty}\frac{\ln(K/S_0)+\sigma\sqrt{U_T}(1-2q_T)}{2\sigma\sqrt{Uq_T(1-q_T)}}\footnotemark\\
      =&\frac{\ln(K/S_0)-(r-\sigma^2/2)U}{\sigma\sqrt{U}}\\
      =&-d_2(S_0,U)
    \end{array}\]
    \footnotetext{$\gamma_T$ disappears due to taking the limit.}
    By \texttt{Theorem \ref{sec_probability}.\ref{the_binomial_distribution_and_standard_normal}} we conclude that
    \[ \lim_{T\to\infty}\prob(Y_T>\alpha_T-1)=1-\Phi(-d_2(S_0,U))=\Phi(d_2(S_0,u)) \]
    This proves result ii).
    \par To prove result i) a very similar argument is used.
    \par Using the limiting relations
    \[ \lim_{T\to\infty}\hat{q}_T=\frac12\text{ and }\lim_{T\to\infty}(1-2\hat{q}_T)\sqrt{UT}=-U\left(\frac{r}\sigma+\frac\sigma2\right) \]
    we can conlude that
    \[ \lim_{T\to\infty}\frac{\alpha_T-1-T\hat{q}_T}{\sqrt{T\hat{q}_T(1-\hat{q}_T)}}=\frac{\ln(k/S_0)0(r+\sigma^2/2)U}{\sigma\sqrt{U}=-d_1(S_0,U)} \]
    Hence
    \[ \lim_{T\to\infty}\prob(\hat{Y}_T>\alpha_T-1)=1-\Phi(-d_1(S_0,U))=\Phi(d_1(S_0,U)) \]
    \proved
  \end{proof}

\section{Continuous-Time}\label{sec_continuous_time_models}

\subsection{Stochastic Integration}

  \begin{definition}{Stochastic Integral $\{I_t\}_t$}
    Let $\{X_t\}_{t\in[0,T]}$ be a simple stochastic process (\textbf{Definition \ref{sec_probability}.\ref{def_simple_stochastic_process}}) and $\{W_t\}_{t\in[0,T]}$ be standard Brownian motion.
    \par The \textit{Stochastic Integral} $I_t$ wrt $\{X_t\}_t$ is defined as
    \[\everymath={\displaystyle}\begin{array}{rcl}
      I_t(X)&:=&\int_0^tX_tdW\\
      &=&\sum_{k=0}^{n-1}\xi_k\cdot\left(W_{\min(t,t_{k+1})}-W_{\min(t,t_k)}\right)
    \end{array}\]
  \end{definition}

  \begin{remark}{Stochastic Integrals are Stochastic Processes}

  \end{remark}

  \begin{remark}{Expanding a Stochastic Integral}
    If $t\in[t_k,t_{k+1}]$ for some $k\in[0,n-1]$ then
    \[ I_t(X)=\left\{\sum_{i=0}^{k-1}\xi_i\cdot(W_{t_{i+1}}-W_{t_i})\right\}+\xi_k\cdot(W_t-W_{t-k}) \]
  \end{remark}

  \begin{example}{Stochastic Integrals}
    Consider the simple stochastic process $\{X_t\}_{t\in[0,T]}$
    \begin{enumerate}
      \item Suppose each $X_t=c$. This is arguably the simplest random process possible and means $n=1$ in the partition. Then
      \[ I_t(X)=cW_t \]
      \item Suppose each $X_t=Y$ where $Y$ is some random variable. This means $n=1$ in the partition and
      \[ I_t(X)=YW_t \]
      \item Suppose $X_t=c$ for $t\leq1/2$ and $X_t=d$ for $t>1/2$. Then
      \[ I_t(X)=\begin{cases}cW_t&\text{if }t<1/2\\cW_{1/2}+d(W_t-W_{1/2})&\text{if }t\geq1/2\end{cases} \]
    \end{enumerate}
  \end{example}

  \begin{theorem}{Properties of Simple Stochastic Processes}\label{the_properties_of_simple_stochastic_processes}
    Let $X:=\{X_t\}_{t\in[0,T]}$ be a \textit{Simple Stochastic Process}. Then
    \begin{enumerate}
      \item $\expect[I_t(X)]=0$.
      \item The \textit{Stochastic Process} satisfies It\^o's isometry.
      \[ \expect\left[(I_t(X))^2\right]=\int_0^t\expect[X_s^2ds] \]
      \item $I_t(X)$ is a continuous \textit{Martingale} wrt the \textit{Natural Brownian Motion Filtration} $\mathcal{F}_t$ for all $0\leq s\leq t\leq T$.
      \[ \expect\left[I_t(X)|\mathcal{F}_s\right]=I_s(X) \]
      \item \textit{Linearity} - $I_t(aX+bY)=aI_t(X)+bI_t(Y)$ where $Y$ is another \textit{Simple Stochastic Process} and $a,b\in\reals$.
      \item The stochastic process $I_t(X)$ has continuous sample paths.
    \end{enumerate}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_properties_of_simple_stochastic_processes}}}
    \everymath={\displaystyle}
    \begin{enumerate}
      \item Note that since $\xi_i$ is $\mathcal{F}_{t_i}$ measurable, then $\xi_i$ \& $(W_{t_{i+1}}-W_{t_i})$ are independent for all $i$. Also $\expect[W_{t_{i+1}}-W_{t_i}]=0$, thus
      \[ \expect[\xi_i(W_{t_{i+1}}-W_{t_i})]=\expect[\xi_i]\expect[W_{t_{i+1}}-W_{t_i}]=0 \]
      Meaning
      \[ \expect[I_t(X)]=0 \]

      \item Consider a partition of $[0,t]$ st $0=t_0<\dots<t_k=t$. Then
      \[ \expect[(I_t(X))^2]=\sum_{i=0}^{k-1}\sum_{j=0}^{k-1}\expect\left[\xi_i(W_{t_{i+1}}-W_{t_i})\xi_j(W_{t_{j+1}}-W_{t_j})\right] \]
      If $i>j$ then $(W_{t_{i+1}}-W_{t_i})$ is independent of all the other factors and has expectation 0
      \[\begin{array}{rl}
        \expect\left[\xi_i(W_{t_{i+1}}-W_{t_i})\xi_j(W_{t_{j+1}}-W_{t_j})\right]\\
        =&\underbrace{\expect[\underbrace{W_{t_{i+1}}-W_{t_i}}_{\sim N(0,t_{i+1}-t_i)}]}_{=0}\expect[\xi_i\xi_j(W_{t_{j+1}}-W_{t_j})]
      \end{array}\]
      So all terms with $i>j$ and, similarly $i<j$, disappear and we conclude that
      \[\begin{array}{rcl}
        \expect[I_t(X)^2]&=&\sum_{i=0}^{k-1}\expect[\xi_i(W_{t_{i+1}}-W_{t_i})\xi_i(W_{t_{i+1}}-W_{t_i})]\\
        &=&\sum_{i=0}^{k-1}\expect[\xi_i^2]\expect[(W_{t_{i+1}}-W_{t_i})^2]\\
        &=&\sum_{i=0}^{k-1}\expect[\xi_i^2](t_{i+1}-t_i)
      \end{array}\]
      The last step comes from considering the variance of $(W_{t_{i+1}}-W_{t_i})$.
      \par The RHS is the usual Riemann Integral $\int_0^Tf(s)ds$ of the step function $f(x)=\expect[X_s^2]$ which coincides with $\expect[\xi^2]$ for $s\in[t_i,t_{i+1}]$.

      \item Adaptedness of $I(X)$ follows since at time $t$ all $\xi_i$ and $(W_{t_{i+1}}-W_{t_i})$ contributing to $I_t(X)$ are functions of \textit{Brownian Motion} up to time $t$.
      \par The condition $\expect\left[\left|I_t(X)\right|\right]$ follows from the isometry property ii).
      \par It remains to show that $\expect\left[I_t(X)|\mathcal{F}_s\right]$ for all $s<t$.
      \par First, assume that $s<t$ and $s,t\in[t_k,t_{k+1}]$. Notice that
      \[\begin{array}{rcl}
        I_t(X)&=&I_{t_k}(X)+\xi_k(W_t-W_{t_k})\\
        I_s(X)&=&I_{t_k}(X)+\xi_k(W_s-W_{t_k})
      \end{array}\]
      Hence $I_t(X)=I_s(X)+\xi_k(W_t-W_s)$ where $I_s(X)$ and $\xi_k$ are known at time $s$, and $(W_t-W_s)$ is independent of $\mathcal{F}_s$ and has mean zero. Hence
      \[ \expect\left[I_t(X)|\mathcal{F}_s\right]=I_s(X)+\xi_k\underbrace{\expect\left[W_t-W_s\right]}_{=0}=I_s(X) \]
      The case where $s<t_k<t$ can be handled analogously.

      \item Assume that the simple process $X$ is defined using the partition
      \[ 0=t_0<t_1<\dots<t_n=T \]
      and $Y$ uses the partition
      \[ 0=s_0<s_1<\dots<s_m=T \]
      Note that these partitions can be different lengths and take different values.
      \par Consider the joint-partition
      \[ 0=u_0<u_1<\dots<u_l=T \]
      which combines all the points from the other partitions, ensuring the correct ordering of values. The values of $I_t(X)$ and $I_t(Y)$ wrt the finer partition $\{u_0,\dots,u_l\}$ remain the same.
      \par Linearity follows from the linearity of the underlying sums.

      \item This follows from the definition of $I_t(X)$ since
      \[ I_t(X)=I_{t_{k-1}}(X)+\xi_k(W_t-W_{t_{k-1}})\ \forall\ t\in[t_{k-1},t_k] \]
      The only unfixed term in this expression is the \textit{Brownian Motion} $W_t$. We know that \textit{Brownian Motion} has continuous sample paths, thus $I_t(X)$ has continuous sample paths.
    \end{enumerate}
  \end{proof}

  \begin{definition}{It\^o Stochastic Integral $I_t(X)$}
    Let $\{X_t\}_{t\in[0,T]}$ be a \textit{Stochastic Process} which is adapted to \textit{Brownian Motion}\footnote{$X_t$ is a function of $W_s$ for $s\leq t$ which satisfies that $\int_0^T\expect[X_t^2]<\infty$}.
    \par \textit{It\^o's Stochastic Integral}. The \textit{It\^o Integral} $\{I_t(X)\}_t$ of $X$ wrt $W$ is denoted as
    \[ I_t(X)=\int_0^tX_sdW_s \]
  \end{definition}

  \begin{remark}{Rule of Thumb for It\^o Stochastic Integral}
    The \textit{It\^o Stochastic Integral} $\{I_t(X)\}_{t\in[0,T]}$ constitute a \textit{Stochastic Process}. For a given partition $0=t_0<t_1<\dots<t_n=T$ and $t\in[t_k,t_{k+1}]$ the random variable $I_t(X)$ is approximately
    \[ I_t(X)\approx\sum_{i=0}^{k-1}\left\{X_{t_i}(W_{t_{i-1}}-W_{t_i})\right\}+X_{t_k}(W_t-W_{t_k}) \]
    This approximation is closer to the value of $I_t(X)$ the denser the partition is in $[0,T]$.
  \end{remark}

  \begin{theorem}{Properties of It\^o Stochastic Integral\footnote{The proof for these properties is not covered in this course.}}\label{the_properties_of_ito_stochastic_integral}
    \textit{Proofs are out of scope of this course!}
    Let $\{X_t\}_{t\in[0,T]}$ be a \textit{Stochastic Process} which is adapted to \textit{Brownian Motion}. Then
    \begin{enumerate}
      \item $\expect[I_t(X)]=0$.
      \item $I_t(X)$ satisfies the It\^o Isometry Property (\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_properties_of_simple_stochastic_processes}}).
      \item $I_t(X)$ is a \textit{Martingale} wrt the \textit{Natural Brownian Filtration}.
      \item $I_t(X)$ is \textit{Linear}.
      \item $I_t(X)$ has continuous sample paths.
    \end{enumerate}
  \end{theorem}

\subsection{It\^o's Lemma}

  \begin{definition}{It\^o Process}
    Let $\{X_t\}_{t\in[0,T]}$ be a stochastic process. $\{X_t\}$ is an \textit{It\^o Process} when $X_t$ takes the form (\ref{eqn_ito_process}).
    \begin{equation}\label{eqn_ito_process}
      X_t=X_0+\int_0^tb_udu+\int_0^t\sigma_udW_u
    \end{equation}
    where both $b,\sigma$ are functions which are adapted to Brownian motion.
    \par Process $\{X_t\}$ has a stochastic differential
    \[ dX_t=b_td_t+\sigma_tdW_t \]
  \end{definition}

  \begin{theorem}{It\^o's Lemma - Special Case}\label{the_ito_v1}
    \textit{This is a special case of It\^o's Lemma.}
    \par Let $f(x)$ be a twice continuously differentiable function. Then for any $t>0$
    \[ f(W_t)-f(W_0)=\underbrace{\int_0^tf'(W_u)dW_u}_\text{Standard Integral}+\underbrace{\frac12\int_0^tf''(W_u)du}_\text{Stochastic Integral} \]
    or in differential form
    \[ df(W_t)=f'(W_t)dW_t+\underbrace{\frac12f''(W_t)dt}_\text{It\^o's Correction Term} \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v1}}}
    Consider a partition $\{t_0,\dots,t_n\}$ of $[0,t]$ with $0=t_0<\dots<t_n=t$.
    \par By Taylor's formula we obtain
    \[\begin{array}{rcl}
      f(W_t)-f(W_0)&=&\sum_{i=0}^{n-1}f(W_{t_{i+1}})-f(W_{t_i})\\
      &=&\sum_{i=0}^{n-1}f'(W_{t_i})(W_{t_{i+1}}-w_{t_i})\\
      &+&\frac12\sum_{i=0}^{n-1}f''(W_{t_i}+\theta_i(W_{t_{i+1}}-W_{t_i}))(W_{t_{i+1}}-w_{t_i})^2\text{ with }\theta_i\in(0,1)
    \end{array}\]
    The first sum is an approximating sequence of a stochastic integral. Indeed, we find
    \[ \sum_{i=0}^{n-1}f'(W_{t_i})(W_{t_{i+1}}-W_{t_i})\overset{n\to\infty}\longrightarrow\int_0^tf'(W_u)dW_u \]
    We also know that
    \[ \lim_{n\to\infty}\sum_{i=0}^{n-1}(W_{t_{i+1}}-W_{t_i})^2=t \]
    and with a little more effort we can prove that\footnote{Proof is beyond scope of course. Won't be asked to reproduce this step.}
    \[ \lim_{n\to\infty}\sum_{i=0}^{n-1}f''(W_{t_i}+\theta_i(W_{t_{i+1}}-W_{t_i}))(W_{t_{i+1}}-W_{t_i})^2=\int_0^tf''(W_u)du \]
    \proved
  \end{proof}

  \begin{theorem}{It\^o's Lemma - More General Case}\label{the_ito_v2}
    \textit{This is a more general case of It\^o's Lemma than \texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v1}}, but not as general as \texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v3}}.}
    \par Let $f(t,x)$ be a function which is continuously differentiable once in its first argument (the time parameter $t$) and twice in its second argument $x$. Then

    \[ f(t,W_t)-f(0,W_0)=\int_0^tf_t(u,W_u)+\frac12 f_{xx}(u,W_u)du +\int_0^tf_x(u,W_i)dW_u\]
    where $f_t:=\frac{\partial f}{\partial t},\ f_{xx}:=\frac{\partial^2 f}{\partial x^2}$ and $f_x:=\frac{\partial f}{\partial x}$.
    \par Or, in differentiable form
    \[ df(t,W_t)=(f_t(t,W_t)+\frac12f_{xx}(t,W_t))dt+f_x(t,W_t)dW_t \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v2}}}
    By the Taylor expansion of a smooth function of several variables we get for $t$ close to $t_0$ that
    \[\begin{array}{rcl}
      f(t,W_t)&=&f(t_0,W_{t_0})+(t-t_0)f_t(t_0,W_{t_0})+(W_t-W_{t_0})f_x(t_0,W_{t_0})\\
      &+&\frac12(t-t_0)^2f_{tt}(t_0,W_{t_0})+\frac12(W_t-W_{t_0})^2f_{xx}(t_0,W_{t_0})\\
      &+&(t-T_0)(W_t-W_{t_0})f_{tx}(t_0,W_{t_0})+\text{Higher order terms}
    \end{array}\]
    This can be written symbolically as
    \[ df=f_tdt+fxdW+\frac12f_{tt}(dt)^2+f_{tx}dtdW+\frac12f_{xx}(dW)^2+\dots \]
    Note that $(dt)^2=0$. Now using the formal multiplication rules
    \[ dt\cdot dt=0\quad dt\cdot dW=0\quad dW\cdot dW=dt \]
    We get
    \[ df=f_td_t+f_xdW+\frac12f_{xx}dt=(f_t+\frac12f_{xx})df+f_xdW \]
    \proved
  \end{proof}

  \begin{theorem}{It\^o's Lemma - Most General}\label{the_ito_v3}
    Let $X$ be an \textit{It\^o Process} and $f(t,x)$ be a function  whose second order partial derivatives are continuous. Then for any $t>0$
    \[ f(t,X_t)-f(0,X_0)=\int_0^tf_t(u,X_u)+b_uf_x(u,X_u)+\frac12\sigma^2_uf_{xx}(u,X_u)du+\int_0^t\sigma_uf_x(u,X_u)dW_u \]
    Or in differential form
    \[ df=\left(f_t+b_tf_X+\frac12\sigma_t^2f_{xx}\right)dt+\sigma_tf_xdW_t \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v3}}}
    We proceed as in the preceding version of It\^o's formula and consider a Taylor expansion of $f(t,X_t)$ which is in differential notation
    \[ df=f_tdt+f_xdX+\frac12f_{tt}(dt)^2+f_{tx}dtdx+\frac12f_{xx}(dX)^2+\text{High order terms} \]
    Now we substitute $dX=bdt+\sigma dW$ and obtain
    \[\begin{array}{rcl}
      df&=&f_tdt+f_x(bd_t+\sigma dW)+\frac12f_{tt}(dt)^2+f_{tx}dt(bdt+\sigma dW)+\frac12f_{xx}(bd_t+\sigma dW)+\text{High order terms}
    \end{array}\]
    Again, neglecting all $(ft)^2)$ and $dtdW$ terms as well as the high order terms we obtain
    \[\begin{array}{rcl}
      df&=&f_td_t+f_x(bd_t+\sigma dW)+\frac12f_{xx}(\sigma dW)^2\\
      &=&(f_t+f_xb+\frac12\sigma^2f_{xx})dt+f_x\sigma dW
    \end{array}\]
    \proved
  \end{proof}

  \begin{theorem}{Product Rule for Stochastic Calculus}\label{the_product_rule_stochastic_calculus}
    \textit{We can derive the produce rule for stochastic calculus from \texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v3}}.}
    \par Suppose two process $X_t,Y_t$ are adapated to the same Brownian motion
    \[\begin{array}{rcl}
      dX_t&=&\sigma_tdW_t+\mu_tdt\\
      dY_t&=&\rho_tdW_t+\nu_tdt
    \end{array}\]
    Then
    \[ d(X_tY_t)=X_tdY_t+Y_tdX_t+\sigma_t\rho_tdt \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_product_rule_stochastic_calculus}}}
    Since $d(X_t+Y_t)=(\sigma_t+\rho_t)dW_t+(\mu_t+\sigma_t)dt$, using \texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_ito_v3}} applied to $f(t,x)=x^2$ we obtain that
    \[\begin{array}{rcl}
      d(X_t^2)&=&(2\mu_tX_t+\sigma_t^2)dt+2\sigma_tX_tdW_t\\
      d(Y_t^2)&=&(2u\nu_tY_t+\rho_t^2)dt+2\rho_tY_tdW_t\\
      d((X_t+Y_t)^2)&=&(2(\mu_t+\nu_t)(X_t+Y_t)+(\sigma_t+\rho_t)^2)dt\\
      &+&2(\sigma_t+\rho_t)(X_t+Y_t)dW_t
    \end{array}\]
    Subtracting, the result follows since
    \[\begin{array}{rcl}
      2d(X_tY_t)=d((X_t+Y_t)^2-X_t^2-Y_t^2)\\
      &=&2(\mu_tY_t+\nu_tX_t)dt+2\sigma_t\rho_tdt+2(\sigma_tY_t+\rho_tX_t)dW_t\\
      &=&2Y_tdX_t+2X_tdY_t+2\sigma_t\rho_tdt
    \end{array}\]
    \proved
  \end{proof}

\subsection{Continuous-Time Model}

  \begin{definition}{Continuous-Time Financial Model}
    The \textit{Continuous-Time Financial Model} has the following components
    \begin{itemize}
      \item Initial date $t=0$.
      \item Terminal date $t=T\in\nats$.
      \item Trading interval $[0,T]$ with trading allowed at any time-point $t\in[0,T]$.
      \item A probability space $(\Omega,\mathcal{F},\prob)$.
      \item Price, Value, Gains and Bank Account Process from \textbf{Section \ref{sec_processes_of_models}} over continuous time-interval $[0,T]$.
    \end{itemize}
  \end{definition}

  \begin{remark}{Discounted Gains process in Multi-Period vs continuous Model}
    In the multi-period model the discounted gains process is always a martingale. This is not the case for the continuous model. Rather,  we restrict ourselves to the subclass of \textit{Admissible Trading Strategies} (\textbf{Definition \ref{sec_continuous_time_models}.\ref{def_admissible_trading_strategies}}).
  \end{remark}

  \begin{definition}{Equivalent Martingale Measure}
    An \textit{Equivalent Martingale Measure} is a probability measure $\Q$ st
    \begin{enumerate}
      \item $\Q$ is equivalent to $\prob$.
      \[ \prob(A)=0\text{ \underline{iff} }\Q(A)=0 \]
      \item The discounted price process $S_n^*$ is a martingale under $\Q$ for all $n=1,\dots,N$.
    \end{enumerate}
  \end{definition}

  \begin{definition}{Admissible Trading Strategy}\label{def_admissible_trading_strategies}
    A self-financing trading strategy $H$ is called \textit{Admissible} wrt to an \textit{Equivalent Martingale Measure} $\Q$ if the discounted gains process $G^*(t)$ is a martingale under $\Q$.
  \end{definition}

  \begin{theorem}{Conditions for discount value process to be a Martingale}\label{the_5_11}
    For each \textit{Admissible Trading Strategy} $H$ and each equivalent martingale measure $\Q$, the discounted value process $V^*(t)$ is a Martingale wrt $\Q$.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_5_11}} }
    Immediate from \textbf{Theorem \ref{sec_discrete_time_models}.\ref{the_self_financing_and_value_process}}.
  \end{proof}

  \begin{definition}{Arbitrage Opportunity - Continuous-Time Model}
    Let $H$ be a trading strategy for a continuous-time financial model. $H$ exploits an \textit{Arbitrage Opportunity} if it has the following properties
    \begin{enumerate}
      \item $V_0=0$.
      \item $V_T\geq0$.
      \item $\expect[V_T]>0$ and
      \item $H$ is self-financing.
    \end{enumerate}
  \end{definition}

  \begin{theorem}{No-Admissible Arbitrage Theorem}\label{the_5_12}
    Assume there exists an equivalent Martingale Measure $\Q$ for the market model.
    \par Then the market model contains no \textit{Admissible Arbitrage Opportunities}.
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_5_12}}}
    Assume that $H$ is an admissible arbitrage opportunity. Then
    \[ V_0^*=0,\ V_T^*\geq0\text{ and }\expect\left[V_T^*\right]>0 \]
    Since $\Q$ is equivalent to $\prob$, we also have $\expect_\Q[V_T^*]>0$.
    \par On the other hand $V_T^*$ is a martingale measure, using \texttt{Theorem \ref{sec_financial_market_models_in_continuous_time}.\ref{the_5_11}}.
    \par That is
    \[ \expect_\Q[V_t^*|\mathcal{F}_u]=V_u^*\text{ for all }u\leq t\leq T \]
    This implies
    \[ \expect_\Q[V_T^*]=V_0^*=0 \]
    This is a contradiction. Thus there cannot be an admissible arbitrage opportunity.\proved
  \end{proof}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_risk_neutral_valuation_principle}} - Continuous Time}
    Let $H$ be an arbitrary replicating portfolio for $X$ and $P_t$ be the time $t$ price of claim $X$.
    \par If $P_t$ does not match the value of the strategy $H$ at time $t$, then there exists arbitrage opportunities as described in the proof of the Risk-neutral valuation principle.
    \par Moreover, by \texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_5_11}} the discounted value process $V_t^*$ is a martingale under $\Q$ and thus
    \[ V_t^*=\expect_\Q[V_T^*|\mathcal{F}_t]=\expect_\Q\left[V_T/B_T|\mathcal{F}_t\right]=\expect_\Q\left[X/B_T|\mathcal{F}_t\right] \]
    Note that the last expression is independent of the particular replicating strategy.\proved
  \end{proof}

\subsection{The Black-Scholes Model}

  \begin{definition}{Black-Scholes Model}
    The \textit{Black-Scholes Model} is a continuous-time financial market model with two assets:
    \begin{itemize}
      \item A riskless bond with a constant interest rate $r$ and corresponding bank account process
      \[ B_t=e^{rt} \]
      \item A risky asset with price process $\{S_t\}_{t\in[0<T]}$ modelled as \textit{Geometric Brownian Motion}
      \[ S_t=S_0e^{\sigma W_t+t\cdot\left(\mu-\frac{\sigma^2}2\right)} \]
      where $W_t$ is Brownian motion, $\mu$ is drift and $\sigma$ is volatility.
    \end{itemize}
    Brownian motion has the characteristic randomness of share prices and Geometric Brownian motion ensures prices do not become negative.
  \end{definition}

  \begin{remark}{Assumptions of Black-Scholes Framework}
    In the \textit{Black-Scholes Framework} the following assumptions are made
    \begin{enumerate}
      \item No arbitrage opportunities exist. This is a standard assumption as when an arbitrage opportunity exists then it will disappear quickly due to arbitrageurs.
      \item No transactions costs. (Relaxable).
      \item Unlimited short-selling is available, at not cost.
      \item Constant risk-free interest rate. (Relaxable).
      \item The underlying price follows a geometric Brownian motion. In reality, prices can jump which does not fit with geometric Brownian motion. Some extensions of the Black-Scholes model account have jump components.
      \item Constant volatility. In reality, volatility is not known nor constant.
    \end{enumerate}
  \end{remark}

  \begin{remark}{Estimating Volatility}
    Estimating the volatility $\sigma$ is hard. There are two approaches:
    \begin{enumerate}
      \item \textit{Statistical Approach}. Estimate volatility $\sigma$ by looking at historical prices $S$ and deduce the historical volatility. This is naturally a poor approach as there is no reason for the volatility over the past to be a good estimator of future volatility. Also, how far back do you want to consider.
      \item \textit{Market-Based Approach}. Extract information of volatility from traded instruments. Volatility obtained in this way is the market view of the volatility, called ``Implied Volatility''. The Black-Scholes formula is numerically inverted to find the implied volatility of a quoted price.
    \end{enumerate}
    Moreover, the Black-Scholes model assumes volatility to be constant but in practice there is a ``Volatility Smile''\footnote{Volatility actually depends on strike price, typically in the shape of a smile.}.
  \end{remark}

  \begin{proposition}{Differential Equations of Black-Scholes Model}\label{prop_diff_equations_of_black_scholes_model}
    In the \textit{Black-Scholes Model} the following differential equations hold
    \begin{itemize}
      \item Of the bond price $dB_t=rB_tdt$.
      \item Of the price process $dS_t=\mu S_tdt+\sigma S_tdW_t$ (A stochastic differential equation).
    \end{itemize}
  \end{proposition}

  \begin{proof}{\ref{sec_continuous_time_models}.\ref{prop_diff_equations_of_black_scholes_model}}
    (First part proved in \textbf{Example 4.5} of long notes).
    \par The function $f(t,W_t)=S_0\cdot\exp\left\{t\cdot\left(\mu-\frac{\sigma^2}2\right)+\sigma W_t\right\}$ has the following partial derivatives
    \[ f_t(t,W_t)=(\mu-\frac{\sigma^2}2)S_t\quad f_X(t,W_t)=\sigma S_t\quad f_{XX}(t,W_t)=\sigma^2S_t \]
    We can now apply It\^0's Lemma to obtain
    \[\begin{array}{rcl}
      dS_t&=&(f_t(t,W_t)+f_{XX}(t,W_t)/2)dt+f_X(t,W_t)dW_t\\
      &=&\left((\mu-\sigma^2/2)+\sigma^2/2\right)S_td_t+\sigma S_tdW_t\\
      &=&\mu S_td_t+\sigma S_tdW_t
    \end{array}\]
  \end{proof}

\subsubsection{Equivalent Martingale Measures for Black-Scholes Model}

  \begin{theorem}{Girsanov's Theorem for Black-Scholes Model\footnote{This is a special case of Girsanov's theorem}}\label{the_girsanov_theorem}
    Let $\{W_t\}_{t\geq0}$ be standard Brownian motion, $\{X_t\}_{t\geq0}$ be Brownian motion with drift $b$ and volatility $\sigma$ (ie $X_t=\sigma W_t+bt$), $a\in\reals$ and $T>0$.
    \par Define the \textit{Girsanov Density} $L_T$ as
    \[ L_T=\exp\left\{\frac{a-b}{\sigma^2}X_T-\frac{a^2-b^2}{2\sigma^2}T\right\} \]
    Setting
    \[ \Q(A)=\expect[L_T\indexed\{A\}]\text{ for all }A\in\mathcal{F}_T \]
    we can define a probability measure $\Q$ st
    \begin{itemize}
      \item $\Q$ is equivalent to $\prob$; and,
      \item $\{X_t\}_{t\geq0}$ is Brownian motion with drift $a$ and volatility $\sigma$ under $\Q$.
    \end{itemize}
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_girsanov_theorem}}}
    \textit{This is just a sketch proof}.
    \par Write $X_T=\sigma W_T+bT$ and obtain
    \[\begin{array}{rcl}
      \Q(A)&=&\expect\left[\indexed\{A\}\cdot\exp\left\{\frac{a-b}\sigma W_T+\frac{a-b}{\sigma^2}bT-\frac{a^2-b^2}{2\sigma^2}T\right\}\right]\\
      &=&\expect\left[\indexed\{A\}\cdot\exp\left\{\frac{a-b}\sigma W_T+\frac{T}{2\sigma^2}(a-b)\left(2b-(a+b)\right)\right\}\right]\\
      &=&\expect\left[\indexed\{A\}\cdot\exp\left\{\frac{a-b}\sigma W_T+\frac{T}{2\sigma^2}(a-b)\left(-(a-b)\right)\right\}\right]\\
      &=&\expect\left[\indexed\{A\}\cdot\exp\left\{\theta W_T+T\theta^2/2\right\}\right]
    \end{array}\]
    where $\theta:=(a-b)/\sigma$.
    \par Since $W_T$ is distribution $\mathcal{N}(0,T)$ we obtain in particular for $A=\Omega$ that
    \[\everymath={\displaystyle}\begin{array}{rcl}
      \Q(\Omega)&=&\int_{-\infty}^\infty\exp\left\{\theta z-T\theta^2/2\right\}\frac1{\sqrt{2\pi T}}\exp\left\{-\frac{z^2}{2T}\right\}dz\\
      &=&\int_{-\infty}^\infty\frac1{\sqrt{2\pi T}}\exp\left\{-\frac{z^2-2T\theta z+T^2\theta^2}{2T}\right\}dz\\
      &=&\int_{-\infty}^\infty\frac1{\sqrt{2\pi T}}\exp\left\{-\frac{(z-T\theta)^2}{2T}\right\}dz\\
      &=&\int_{-\infty}^\infty g(z)dz
    \end{array}\]
    We identify the intergrand $g(z)$ as the density of a $\mathcal{N}(T\theta,T)$ distribution.
    \par Therefore
    \[ \Q(\Omega)=\int_{-\infty}^\infty g(z)dz=1 \]
    Hence $\Q$ is a probability measure.
    \par Since $L_T>0$, $\Q$ is equivalent to $\prob$.
    \par Similarly we obtain for every $s\in\reals$ that
    \[\everymath={\displaystyle}\begin{array}{rcl}
      \Q(X_T\leq s)&=&\Q\left(W_T\leq \frac{s-bT}\sigma\right)\\
      &=&\int_{-\infty}^{\frac{s-bT}\sigma}g(z)dz\\
      &=&\int_{-\infty}^sg\left(\frac{u-bT}\sigma\right)du
    \end{array}\]
    using the transformation $z=\frac{u-bT}\sigma$.
    We can rewrite the integrand as
    \[\everymath={\displaystyle}\begin{array}{rcl}
      \frac1\sigma g\left(\frac{u-bT}\sigma\right)&=&\frac1{\sigma{2\pi T\sigma^2}}\exp\left\{-\frac{\left(\frac{u-bT}\sigma-T\theta\right)^2}{2T}\right\}\\
      &=&\frac1{\sigma{2\pi T\sigma^2}}\exp\left\{-\frac{(u-T(b+\theta^2\sigma))^2}{2T\sigma^2}\right\}\\
    \end{array}\]
    Note that $\theta:=(a-b)/\sigma\implies b+\theta\sigma=a$. Therefore $X_T$ is, under $\Q$, normally distributed with mean $aT$ and variance $T\sigma^2$.
    \par It remains to show that for $t<T$ the distribution of $X_t$ is again a normal distribution with mean $at$ and variance $t\sigma^2$ and that the increments of $X_t$ are independent.\footnote{Not covered in notes, may be out of scope of course.}\proved
  \end{proof}

  \begin{proposition}{Equivalent Martingale Measure for Black-Scholes Model}\label{prop_equivalent_martingale_measure_for_bs_model}
    An equivalent martingale measure $\Q$ is defined by setting
    \[ \Q(A)=\expect[L_T\indexed\{A\}] \]
    where
    \[ L_T=\exp\left\{\frac{r-\mu}\sigma W_T-\frac{(r-\mu)^2}{2\sigma^2}T\right\} \]
  \end{proposition}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{prop_equivalent_martingale_measure_for_bs_model}}}
    The discounted price process in the \textit{Black-Scholes model} is given by
    \[ S_t^*=e^{-rt}S_t=S_0e^{\sigma W_t+\left(\mu-r-\frac{\sigma^2}2\right)}=S_0e^{X_t} \]
    where $X_t$ is a Brownian motion with volatility $\sigma$ and drift $\left(\mu-r-\frac{\sigma^2}2\right)$.
    \par Writing
    \[\everymath={\displaystyle}\begin{array}{rcl}
      L_T&=&\exp\left\{\frac{r-\mu}{\sigma^2}\left(X_T-T(\mu-r-\frac{\sigma^2}2)\right)-\frac{(r-\mu)^2}{2\sigma^2}T\right\}\\
      &=&\exp\left\{\frac{r-\mu}{\sigma^2}X_T-\frac{(r-\mu)(\mu-r-\frac{\sigma^2}2)T}{\sigma^2}-\frac{(r-\mu)^2}{2\sigma^2}T\right\}\\
      &=&\exp\left\{\frac{r-\mu}{\sigma^2}X_T-\frac{-2(r-\mu)^2-(r-\mu)\sigma^2}{2\sigma^2}T-\frac{(r-\mu)^2}{2\sigma^2}T\right\}\\
      &=&\exp\left\{\frac{r-\mu}{\sigma^2}X_T-\frac{-(r-\mu)^2-(r-\mu)\sigma^2}{2\sigma^2}T\right\}
    \end{array}\]
    and applying \textit{Girsanov's Theorem} (\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_girsanov_theorem}}) with $a=-\sigma^2/2$ and $b=\mu-r-\frac{\sigma^2}2$, we see that $X_T$ is, under $\Q$, a Brownian motion with volatility $\sigma$ and drift $-\sigma^2/2$
    \par Using \texttt{Proposition \ref{sec_probability}.\ref{pro_martingales_and_brownian_motion}} we see that $S_t^*$ is a martingale under $\Q$. \proved
  \end{proof}

  \begin{remark}{Price Process under $\prob$ and $\Q$}
    Under $\prob$, the stock price process is given by
    \[ S_t=S_0\exp\left\{\sigma W_t+(\mu-\frac{\sigma^2}2)t\right\} \]
    Under $\Q$, the stock price process is given by
    \[ S_t=S_0\exp\left\{\sigma\bar{W}_t+(r-\frac{\sigma^2}2)t\right\} \]
    where
    \[ \bar{W}_t=W_t-\frac{r-\mu}\sigma t \]
    Note that $\bar{W}$ is a standard Brownian motion wrt $\Q$. This show that computations using the risk-neutral measure can be made by replacing the trend $\mu$ with the constant interest rate $r$.
  \end{remark}

\subsubsection{Pricing a Black-Scholes Model}

  \begin{proposition}{Price of Black-Scholes Model}\label{prop_price_of_black_scholes_continuous}
    Consider the Black-Scholes model and a contingent claim $X$. The price of $X$ at time $t$ is given by
    \[ P_t=e^{-r(T-t)}\expect_\Q[X|\mathcal{F}_t] \]
    where $\expect_\Q$ is given via the Girsanov density (\textit{Theorem \ref{sec_financial_market_models_in_continuous_time}.\ref{the_girsanov_theorem}})
  \end{proposition}

  \begin{theorem}{Technical Lemma before Black-Scholes Formula}\label{the_technical_lemma_for_BS}
    For $Z\sim\mathcal{N}(a,\gamma^2)$ and any $b,c>0$
    \[ \expect[\{be^Z-c\}_+]=be^{a+\frac{\gamma^2}2}\Phi\left(\frac1\gamma\left(\ln(b/c)+a+\gamma^2\right)\right)-c\Phi\left(\frac1\gamma\left(\ln(b/c)+a\right)\right) \]
  \end{theorem}

  \begin{proof}{\texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_technical_lemma_for_BS}}}
    Recall that for a random variable $X$ with a standard normal distribution
    \[ \prob(X>x)=1-\Phi(x)=\Phi(-x)\ \forall\ x\in\reals \]
    Therefore we can calculate $\expect\left[\{be^Z-c\}_+\right]$ as follows
    \[\everymath={\displaystyle}\begin{array}{rcl}
      \expect\left[\{be^Z-c\}_+\right]&=&\int_{-\infty}^\infty\{be^x-c\}_+\frac1{\sqrt{2\pi\gamma^2}}e^{-\frac{(x-a)^2}{2\gamma^2}}dx\\
      &=&\int_{\ln(c/b)}^\infty(be^x-c)\frac1{\sqrt{2\pi\gamma^2}}e^{-\frac{(x-a)^2}{2\gamma^2}}dx\\
      &=&b\int_{\ln(c/b)}^\infty\frac1{\sqrt{2\pi\gamma^2}}e^{-\frac{2x\gamma^2+(x-a)^2}{2\gamma^2}}dx-c\underbrace{\int_{\ln(c/b)}^\infty\frac1{\sqrt{2\pi\gamma^2}}e^{-\frac{(x-a)^2}{2\gamma^2}}dx}_{=\prob(Z>\ln(c/b))}\\
      &=&be^{\frac{2a\gamma^2+\gamma^4}{2\gamma^2}}\underbrace{\int_{\ln(c/b)}^\infty\frac1{\sqrt{2\pi\gamma^2}}e^{-\frac{(x-a-\gamma^2)^2}{2\gamma^2}}dx}_{=\prob(Z+\gamma^2>\ln(c/b))}-c\prob(Z>\ln(c/b))\\
      &=&be^{a+\frac{\gamma^2}2}\prob(Z+\gamma^2>\ln(c/b))-c\prob(Z>\ln(c/b))\\
      &=&be^{a+\frac{\gamma^2}2}\prob\left(\frac{Z-a}\gamma>\frac1\gamma\left(\ln(c/b)-\gamma^2-a\right)\right)-c\prob\left(\frac{Z-a}\gamma>\frac1\gamma\left(\ln(c/b)-a\right)\right)\\
      &=&be^{a+\frac{\gamma^2}2}\Phi\left(\frac1\gamma\left(\ln(c/b)-\gamma^2-a\right)\right)-c\Phi\left(\frac1\gamma\left(\ln(c/b)-a\right)\right)\\
    \end{array}\]
    \proved
  \end{proof}

  \begin{proposition}{Black-Scholes Formula - Continuous Time}\label{prop_bs_formula_continuous}
    \textit{This is the same as the Black-Scholes Formula in \texttt{Theorem \ref{sec_discrete_time_models}.\ref{the_black_scholes_formula}}.}
    \par Consider a European call option with exercise price $K$ maturing at time $T$ which corresponds to the claim $X=\{S_T-K\}_+$. Then the Black-Scholes price process of that European class is given by
    \[ \Pi_t=S_t\Phi(d_1(S_t,T_t))-Ke^{-r(T-t)}\Phi(d_2(S_t,T-t)) \]
    The functions $d_1(u,v)$ and $d_2(u,v)$ are given by
    \[\everymath={\displaystyle}\begin{array}{rcl}
      d_1(u,v)&=&\frac{\ln(u/K)+\left(r+\frac{\sigma^2}2\right)v}{\sigma\sqrt{v}}\\
      d_2(u,v)&=&\frac{\ln(u/K)+\left(r-\frac{\sigma^2}2\right)v}{\sigma\sqrt{v}}
    \end{array}\]
  \end{proposition}

  \begin{proof}{\texttt{Proposition \ref{sec_continuous_time_models}.\ref{prop_bs_formula_continuous}}.}
    Let $\bar{W}_t$ be a standard Brownian motion under $\Q$. The price $\Pi_t$ is given by
    \[\everymath={\displaystyle}\begin{array}{rcl}
      \Pi_t&=&e^{-r(T-t)}\expect_\Q\left[\{S_T-K\}_+|\mathcal{F}_t\right]\\
      &=&e^{-r(T-t)}\expect_\Q\left[\left\{S_t e^{\sigma(\bar{W}_T-\bar{W}_t)+\left(r-\frac{\sigma^2}2\right)(T-t)}-K\right\}_+\bigg|\mathcal{F}_t\right]\\
      &=&e^{-r(T-t)}\expect_\Q\left[|\{S_te^Z-K\}_+\mathcal{F}_t\right]
    \end{array}\]
    where $Z\sim\mathcal{N}(a,\gamma^2)$ under $\Q$ with mean $a=\left(r-\frac{\sigma^2}2\right)(T-t)$ and standard deviation $\gamma=\sigma\sqrt{T-t}$ and is independent of $\mathcal{F}_t$.
    \par We obtain the Black-Scholes formula by applying \texttt{Theorem \ref{sec_continuous_time_models}.\ref{the_technical_lemma_for_BS}} with $b=S_t,c=K$
    \[\everymath={\displaystyle}\begin{array}{rcl}
      \Pi_t&=&e^{-r(T-t)}S_te^{a+\frac12(\sigma^2(T-t))}\Phi\left(\frac1{\sigma\sqrt{T-t}}\left(\ln(S_t/K)+a+\sigma^2(T-t)\right)\right)\\
      &-&e^{-r(T-t)}K\Phi\left(\frac1{\sigma\sqrt{T-t}}(\ln(S_t/K)+a)\right)
    \end{array}\]
    \proved
  \end{proof}

\subsubsection{Black-Scholes-Merton Equation}

  \begin{remark}{Motivation}
    The risk-neutral pricing principle (\textbf{Theorem \ref{sec_discrete_time_models}.\ref{the_risk_neutral_valuation_principle}}) does not provide an explicitly expression for the replicating portfolio.
  \end{remark}

  \begin{theorem}{Black-Scholes-Mertons Equation}\label{eqn_black_scholes_mertons}
    Let $X=g(S_T)$ be an attainable claim in the Black-Scholes model with drift $\mu$ and volatility $\sigma$.
    \par Assume that the price $\Pi_t$ at time $t$ satisfies $\Pi_t=f(t,S_t)$ for some function $f$ with two continuous derivatives in $x$ and one in $t$.
    \par Then $f(t,x)$ satisfies the \textit{Black-Scholes-Mertons Equation}
    \[ f_t+rS_tf_x+\frac12\sigma^2S_t^2f_{xx}-rf=0,\quad f(T,S_T)=g(S_T) \]
    Further, the replicating strategy is given by
    \[\begin{array}{rcl}
      H_0(t)&=&\frac1{B_t}\left(f(t,S_t)-f_x(t,S_t)S_t\right)\\
      &=&\frac{1}{rB_t}\left(f_t(t,S_t)+\frac12f_{xx}(t,S_t)S_t^2\sigma^2\right)\\
      H_1(t)&=&f_x(t,S_t)
    \end{array}\]
  \end{theorem}

  \begin{proof}{Theorem \ref{sec_continuous_time_models}.\ref{eqn_black_scholes_mertons}}
    The price process $S_t$ of the stock under $\Q$ is
    \[ S_t=S_0\exp\left\{\sigma\bar{W}_t+t\cdot\left(r-\frac{\sigma^2}2\right)\right\} \]
    An application of It\^o's lemma shows that it has dynamics
    \begin{equation}\label{eqn_proof_bsm_dS}
      dS_t=S_t(rdt+\sigma d\bar{W}_t)
    \end{equation}
    Similarly, the discounted price process $S_t^*=S_0\exp\left\{\sigma\bar{W}_t-t(\sigma^2/2)\right\}$ has dynamics
    \begin{equation}\label{eqn_proof_bsm_dSt_star}
      dS_t^*=S_t^*\sigma d\bar{W}_t
    \end{equation}
    Let now $h(t,S_t)=f(t,S_t)/B_t=\exp^{-rt}f(t,S_t)$ be the discounted fair price of the claim $X$ at time $t$.
    \par Since, (\ref{eqn_proof_bsm_dS}) means that $S_t$ is an It\^0 process with $b_t=rS_t$ and $\sigma_t=\sigma S_t$ using It\^o's lemma we find that
    \begin{equation}\label{eqn_proof_bsm_dh}
      dh=\left(h_t+rS_th_x+\frac12\sigma^2S_t^2h_{xx}\right)dt+\sigma S_th_xd\bar{W}_t
    \end{equation}
    We know from the risk-neutral valuation principle that
    \begin{equation}\label{eqn_proof_bsm_ht}
      h_t(t,S_t)=\expect_\Q\left[X/B_T\bigg|\mathcal{F}_t\right]
    \end{equation}
    and in particular that $h$ is a martingale with respect to $\Q$.
    \par Therefore, there is no drift meaning that the $dt$ term in (\ref{eqn_proof_bsm_dh}) is zero
    \[ h_t(t,S_t)+rS_th_x(t,S_t)+\frac12\sigma^2S_t^2h_{xx}(t,S_t)=0 \]
    Moreover, the dynamics of (\ref{eqn_proof_bsm_dh}) reduce to
    \begin{equation}\label{eqn_proof_bsm_dh_2}
      dh(t,S_t)=\sigma S_th_x(t,S_t)d\bar{W}_t
    \end{equation}
    \textit{Black-Scholes-Merton Equation}
    \par The ratio between $h$ and $f$ is a function of $t$, not $x$, and therefore $h_x=f_x/B_t$ and $g_{xx}=f_{xx}/B_t$.
    \par We also know that $h_t=(f_t/B_t)-(rf/B_t)$. Therefore, (\ref{eqn_proof_bsm_ht}) can be rewritten as
    \[\begin{array}{rcl}
      0&=&h_t+rS_th_x+\frac12\sigma^2S_t^2h_{xx}\\
      &=&\frac1{B_t}\left(f_t-rf+rS_tf_x+\frac12\sigma^2S_t^2f_{xx}\right)
    \end{array}\]
    Multiplying by $B_t$ we see that $f$ satisfies the \textit{Black-Scholes-Merten Equation}.\proved
    \par \textit{Replicating Portfolio}.
    \par For all $t$ the value of the replicating portfolio $\left(H_0(t),H_1(t)\right)$ equals the price process $f(t,S_t)$ of the claim $X$ and the replicating strategy must be self-financing.
    \par Therefore, (\ref{eqn_proof_bsm_dSt_star}) implies
    \[\begin{array}{rcl}
      dh(t,S_t)&=&H_1(t)dS_t^*\\
      &=&H_1(t)S_t^*\sigma d\bar{W}_t\\
      &=&H_1(t)\frac{S_t}{B_t}\sigma d\bar{W}_t
    \end{array}\]
    Equating this result to (\ref{eqn_proof_bsm_dh_2}) we get
    \[\begin{array}{rrcl}
      &H_1(t)S_t^*\sigma&=&\sigma S_th_x(t,S_t)\\
      \implies&H_1(t)\left(\frac{S_t}{B_t}\right)&=&S_th_x(t,S_t)\\
      \implies&H_1(t)&=&B_th_x(t,S_t)\\
      &=&f_x(t,S_t)
    \end{array}\]
    Finally, the replicating portfolio has to satisfy
    \[\begin{array}{rcl}
      f(t,S_t)&=&H_0(t)B_t+H_1(t)S_t\\
      &=&H_0(t)B_t+f_x(t,S_t)S_t
    \end{array}\]
    From this we obtain that
    \[ H_0(t)=\frac{f(t,S_t)-f_x(t,S_t)S_t}{B_t} \]
  \end{proof}

  \begin{remark}{Black-Scholes-Merton Equation and Contingency Claims}
    The \textit{Black-Scholes-Merton Equation} is an alternative way of calculating the price of a contingent claim.
    \par The boundary condition has to be chosen according to the contingent claim we want to analyse. In particular, for $f(T,S_T)=\{S_T-k\}^+$ we obtain yet another way of deriving the Black-Scholes formula (See \textbf{Example 5.4} in long notes).
  \end{remark}

\reference

\subsection{Notation}

\subsection{Definitions}

\end{document}
